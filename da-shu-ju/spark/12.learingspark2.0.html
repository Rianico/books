<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <title>12. LearingSpark2.0 | zxk&#39;s book</title>
    <meta name="description" content="">
    <meta name="generator" content="VuePress 1.5.3">
    <link rel="icon" href="/books/Avatar.jpg">
    <meta name="description" content="兴趣使然的备忘库">
    <link rel="preload" href="/books/assets/css/0.styles.253527df.css" as="style"><link rel="preload" href="/books/assets/js/app.a32f3f13.js" as="script"><link rel="preload" href="/books/assets/js/2.f434c5a6.js" as="script"><link rel="preload" href="/books/assets/js/182.069a8f30.js" as="script"><link rel="prefetch" href="/books/assets/js/10.dceff922.js"><link rel="prefetch" href="/books/assets/js/100.e86d25aa.js"><link rel="prefetch" href="/books/assets/js/101.654d6902.js"><link rel="prefetch" href="/books/assets/js/102.6e048095.js"><link rel="prefetch" href="/books/assets/js/103.26ec951e.js"><link rel="prefetch" href="/books/assets/js/104.f413fdc7.js"><link rel="prefetch" href="/books/assets/js/105.0b5517ef.js"><link rel="prefetch" href="/books/assets/js/106.025ff37f.js"><link rel="prefetch" href="/books/assets/js/107.3fd4a2da.js"><link rel="prefetch" href="/books/assets/js/108.c33413cd.js"><link rel="prefetch" href="/books/assets/js/109.69c58c80.js"><link rel="prefetch" href="/books/assets/js/11.f4ff5e98.js"><link rel="prefetch" href="/books/assets/js/110.da669047.js"><link rel="prefetch" href="/books/assets/js/111.27221683.js"><link rel="prefetch" href="/books/assets/js/112.ae80afd9.js"><link rel="prefetch" href="/books/assets/js/113.d17c58d7.js"><link rel="prefetch" href="/books/assets/js/114.26c4f4c1.js"><link rel="prefetch" href="/books/assets/js/115.5491e5a0.js"><link rel="prefetch" href="/books/assets/js/116.a209ce38.js"><link rel="prefetch" href="/books/assets/js/117.c3a25178.js"><link rel="prefetch" href="/books/assets/js/118.b518ee54.js"><link rel="prefetch" href="/books/assets/js/119.e017c898.js"><link rel="prefetch" href="/books/assets/js/12.6dae06d9.js"><link rel="prefetch" href="/books/assets/js/120.1baf3023.js"><link rel="prefetch" href="/books/assets/js/121.71a13847.js"><link rel="prefetch" href="/books/assets/js/122.e058174e.js"><link rel="prefetch" href="/books/assets/js/123.5252e439.js"><link rel="prefetch" href="/books/assets/js/124.e919844e.js"><link rel="prefetch" href="/books/assets/js/125.b4b936d5.js"><link rel="prefetch" href="/books/assets/js/126.0ff2a40d.js"><link rel="prefetch" href="/books/assets/js/127.0e27fcc5.js"><link rel="prefetch" href="/books/assets/js/128.b0d65cea.js"><link rel="prefetch" href="/books/assets/js/129.3f7c4fb2.js"><link rel="prefetch" href="/books/assets/js/13.fd393096.js"><link rel="prefetch" href="/books/assets/js/130.22907055.js"><link rel="prefetch" href="/books/assets/js/131.9b6a7fa1.js"><link rel="prefetch" href="/books/assets/js/132.0141d721.js"><link rel="prefetch" href="/books/assets/js/133.62368e0f.js"><link rel="prefetch" href="/books/assets/js/134.c22be34f.js"><link rel="prefetch" href="/books/assets/js/135.9c30742f.js"><link rel="prefetch" href="/books/assets/js/136.8e29ebad.js"><link rel="prefetch" href="/books/assets/js/137.9bd0b5ba.js"><link rel="prefetch" href="/books/assets/js/138.41a78831.js"><link rel="prefetch" href="/books/assets/js/139.a9376eeb.js"><link rel="prefetch" href="/books/assets/js/14.208ec185.js"><link rel="prefetch" href="/books/assets/js/140.b4f63a2e.js"><link rel="prefetch" href="/books/assets/js/141.6a4888c7.js"><link rel="prefetch" href="/books/assets/js/142.d675963b.js"><link rel="prefetch" href="/books/assets/js/143.501abfa1.js"><link rel="prefetch" href="/books/assets/js/144.fdbc09d5.js"><link rel="prefetch" href="/books/assets/js/145.5bb6218a.js"><link rel="prefetch" href="/books/assets/js/146.b5ba45c3.js"><link rel="prefetch" href="/books/assets/js/147.e0a80eb4.js"><link rel="prefetch" href="/books/assets/js/148.27910016.js"><link rel="prefetch" href="/books/assets/js/149.013194c7.js"><link rel="prefetch" href="/books/assets/js/15.16c314bd.js"><link rel="prefetch" href="/books/assets/js/150.3154742d.js"><link rel="prefetch" href="/books/assets/js/151.78fc6a13.js"><link rel="prefetch" href="/books/assets/js/152.e97f9998.js"><link rel="prefetch" href="/books/assets/js/153.3d92ef79.js"><link rel="prefetch" href="/books/assets/js/154.70c9f7a4.js"><link rel="prefetch" href="/books/assets/js/155.4b924a86.js"><link rel="prefetch" href="/books/assets/js/156.59e71763.js"><link rel="prefetch" href="/books/assets/js/157.8c8cd5ed.js"><link rel="prefetch" href="/books/assets/js/158.739ecc99.js"><link rel="prefetch" href="/books/assets/js/159.5a22b675.js"><link rel="prefetch" href="/books/assets/js/16.d3259c7f.js"><link rel="prefetch" href="/books/assets/js/160.3cc481bb.js"><link rel="prefetch" href="/books/assets/js/161.5cdebd7a.js"><link rel="prefetch" href="/books/assets/js/162.d56ac8d7.js"><link rel="prefetch" href="/books/assets/js/163.a89f22d0.js"><link rel="prefetch" href="/books/assets/js/164.e5e25ddb.js"><link rel="prefetch" href="/books/assets/js/165.406cc447.js"><link rel="prefetch" href="/books/assets/js/166.0f09d541.js"><link rel="prefetch" href="/books/assets/js/167.afee8669.js"><link rel="prefetch" href="/books/assets/js/168.1ae1f6ce.js"><link rel="prefetch" href="/books/assets/js/169.1bfb929c.js"><link rel="prefetch" href="/books/assets/js/17.6ea641b2.js"><link rel="prefetch" href="/books/assets/js/170.0baab93a.js"><link rel="prefetch" href="/books/assets/js/171.65e2e3b6.js"><link rel="prefetch" href="/books/assets/js/172.9a0d4dfd.js"><link rel="prefetch" href="/books/assets/js/173.0690d3f4.js"><link rel="prefetch" href="/books/assets/js/174.52a3d4eb.js"><link rel="prefetch" href="/books/assets/js/175.33e4696f.js"><link rel="prefetch" href="/books/assets/js/176.6c865e6e.js"><link rel="prefetch" href="/books/assets/js/177.1b2a7c93.js"><link rel="prefetch" href="/books/assets/js/178.37c33f6b.js"><link rel="prefetch" href="/books/assets/js/179.ef76c85c.js"><link rel="prefetch" href="/books/assets/js/18.d3146ce7.js"><link rel="prefetch" href="/books/assets/js/180.0e457253.js"><link rel="prefetch" href="/books/assets/js/181.dee67b63.js"><link rel="prefetch" href="/books/assets/js/183.0330f5ce.js"><link rel="prefetch" href="/books/assets/js/184.efd2fde2.js"><link rel="prefetch" href="/books/assets/js/185.7d64b540.js"><link rel="prefetch" href="/books/assets/js/186.82e60409.js"><link rel="prefetch" href="/books/assets/js/187.0d54afe4.js"><link rel="prefetch" href="/books/assets/js/188.81a9510a.js"><link rel="prefetch" href="/books/assets/js/189.279c7f6f.js"><link rel="prefetch" href="/books/assets/js/19.ef650392.js"><link rel="prefetch" href="/books/assets/js/190.e5a7480c.js"><link rel="prefetch" href="/books/assets/js/191.f365d8de.js"><link rel="prefetch" href="/books/assets/js/192.84ea0f67.js"><link rel="prefetch" href="/books/assets/js/193.bb2e01d9.js"><link rel="prefetch" href="/books/assets/js/194.ef6b690e.js"><link rel="prefetch" href="/books/assets/js/195.1ee66346.js"><link rel="prefetch" href="/books/assets/js/196.f34cbe99.js"><link rel="prefetch" href="/books/assets/js/197.cbbdab75.js"><link rel="prefetch" href="/books/assets/js/198.845810f3.js"><link rel="prefetch" href="/books/assets/js/199.5e1147de.js"><link rel="prefetch" href="/books/assets/js/20.21272222.js"><link rel="prefetch" href="/books/assets/js/200.57f5e124.js"><link rel="prefetch" href="/books/assets/js/201.a572c554.js"><link rel="prefetch" href="/books/assets/js/202.5ce9f4a7.js"><link rel="prefetch" href="/books/assets/js/203.bc6f8876.js"><link rel="prefetch" href="/books/assets/js/204.126953e5.js"><link rel="prefetch" href="/books/assets/js/205.9aeca759.js"><link rel="prefetch" href="/books/assets/js/206.ec099168.js"><link rel="prefetch" href="/books/assets/js/207.6e5b496b.js"><link rel="prefetch" href="/books/assets/js/208.6624d24c.js"><link rel="prefetch" href="/books/assets/js/209.3d8ff15b.js"><link rel="prefetch" href="/books/assets/js/21.a956aa7a.js"><link rel="prefetch" href="/books/assets/js/210.6429663d.js"><link rel="prefetch" href="/books/assets/js/211.1d8725a1.js"><link rel="prefetch" href="/books/assets/js/212.d1ff2873.js"><link rel="prefetch" href="/books/assets/js/213.e213f9d1.js"><link rel="prefetch" href="/books/assets/js/214.a9b5c7ec.js"><link rel="prefetch" href="/books/assets/js/215.fd7a5238.js"><link rel="prefetch" href="/books/assets/js/216.96394ddb.js"><link rel="prefetch" href="/books/assets/js/217.3f41d192.js"><link rel="prefetch" href="/books/assets/js/218.622af412.js"><link rel="prefetch" href="/books/assets/js/219.772992ff.js"><link rel="prefetch" href="/books/assets/js/22.fb2ff9d3.js"><link rel="prefetch" href="/books/assets/js/220.99efbde4.js"><link rel="prefetch" href="/books/assets/js/221.9932f6ce.js"><link rel="prefetch" href="/books/assets/js/222.e9c2624f.js"><link rel="prefetch" href="/books/assets/js/223.c87d79a7.js"><link rel="prefetch" href="/books/assets/js/224.6fc0bed5.js"><link rel="prefetch" href="/books/assets/js/225.443418f3.js"><link rel="prefetch" href="/books/assets/js/226.d0e9e921.js"><link rel="prefetch" href="/books/assets/js/227.b29a9627.js"><link rel="prefetch" href="/books/assets/js/228.6b9c5eb3.js"><link rel="prefetch" href="/books/assets/js/229.a2dee41e.js"><link rel="prefetch" href="/books/assets/js/23.77b92b70.js"><link rel="prefetch" href="/books/assets/js/230.b36a47b9.js"><link rel="prefetch" href="/books/assets/js/231.d7a52023.js"><link rel="prefetch" href="/books/assets/js/232.5c445a90.js"><link rel="prefetch" href="/books/assets/js/233.398e8141.js"><link rel="prefetch" href="/books/assets/js/234.86f5ff7b.js"><link rel="prefetch" href="/books/assets/js/235.d8271e43.js"><link rel="prefetch" href="/books/assets/js/236.41b92eb4.js"><link rel="prefetch" href="/books/assets/js/237.4d52bf88.js"><link rel="prefetch" href="/books/assets/js/238.209dd5d8.js"><link rel="prefetch" href="/books/assets/js/239.a977d564.js"><link rel="prefetch" href="/books/assets/js/24.96161161.js"><link rel="prefetch" href="/books/assets/js/240.56008448.js"><link rel="prefetch" href="/books/assets/js/241.95144dec.js"><link rel="prefetch" href="/books/assets/js/242.deacfcf7.js"><link rel="prefetch" href="/books/assets/js/243.6bd3a203.js"><link rel="prefetch" href="/books/assets/js/244.20662085.js"><link rel="prefetch" href="/books/assets/js/245.3079d8db.js"><link rel="prefetch" href="/books/assets/js/246.59cbb76d.js"><link rel="prefetch" href="/books/assets/js/247.dab4d54b.js"><link rel="prefetch" href="/books/assets/js/248.dd78e28c.js"><link rel="prefetch" href="/books/assets/js/249.47cfb0fb.js"><link rel="prefetch" href="/books/assets/js/25.bb622e2d.js"><link rel="prefetch" href="/books/assets/js/250.8b7c06de.js"><link rel="prefetch" href="/books/assets/js/251.90d4bb83.js"><link rel="prefetch" href="/books/assets/js/252.4b70df27.js"><link rel="prefetch" href="/books/assets/js/253.baa34cc9.js"><link rel="prefetch" href="/books/assets/js/254.64c84394.js"><link rel="prefetch" href="/books/assets/js/255.4245dca1.js"><link rel="prefetch" href="/books/assets/js/256.4bd25081.js"><link rel="prefetch" href="/books/assets/js/257.44a180fd.js"><link rel="prefetch" href="/books/assets/js/258.ef8eb1df.js"><link rel="prefetch" href="/books/assets/js/259.ca38bbda.js"><link rel="prefetch" href="/books/assets/js/26.800c4d14.js"><link rel="prefetch" href="/books/assets/js/260.fc42b0a6.js"><link rel="prefetch" href="/books/assets/js/27.be0559b4.js"><link rel="prefetch" href="/books/assets/js/28.cdb01ee8.js"><link rel="prefetch" href="/books/assets/js/29.27c415ce.js"><link rel="prefetch" href="/books/assets/js/3.7dd1ae11.js"><link rel="prefetch" href="/books/assets/js/30.da6f6371.js"><link rel="prefetch" href="/books/assets/js/31.c824c17b.js"><link rel="prefetch" href="/books/assets/js/32.45c04f7c.js"><link rel="prefetch" href="/books/assets/js/33.315cf7d5.js"><link rel="prefetch" href="/books/assets/js/34.b532da2f.js"><link rel="prefetch" href="/books/assets/js/35.0af657d1.js"><link rel="prefetch" href="/books/assets/js/36.2df4655c.js"><link rel="prefetch" href="/books/assets/js/37.a4887720.js"><link rel="prefetch" href="/books/assets/js/38.68a08b9d.js"><link rel="prefetch" href="/books/assets/js/39.bf63d04a.js"><link rel="prefetch" href="/books/assets/js/4.e8102eb5.js"><link rel="prefetch" href="/books/assets/js/40.a3c5cdd1.js"><link rel="prefetch" href="/books/assets/js/41.116ef3fc.js"><link rel="prefetch" href="/books/assets/js/42.f3b8b588.js"><link rel="prefetch" href="/books/assets/js/43.b1d59c70.js"><link rel="prefetch" href="/books/assets/js/44.579ee856.js"><link rel="prefetch" href="/books/assets/js/45.807bba31.js"><link rel="prefetch" href="/books/assets/js/46.db611eda.js"><link rel="prefetch" href="/books/assets/js/47.d4d02273.js"><link rel="prefetch" href="/books/assets/js/48.7f011fb9.js"><link rel="prefetch" href="/books/assets/js/49.3aac265b.js"><link rel="prefetch" href="/books/assets/js/5.638928ae.js"><link rel="prefetch" href="/books/assets/js/50.8b75be66.js"><link rel="prefetch" href="/books/assets/js/51.576e782b.js"><link rel="prefetch" href="/books/assets/js/52.85987e06.js"><link rel="prefetch" href="/books/assets/js/53.6a8c240c.js"><link rel="prefetch" href="/books/assets/js/54.6a97379c.js"><link rel="prefetch" href="/books/assets/js/55.97955477.js"><link rel="prefetch" href="/books/assets/js/56.3d477c83.js"><link rel="prefetch" href="/books/assets/js/57.56aa4dff.js"><link rel="prefetch" href="/books/assets/js/58.833c8652.js"><link rel="prefetch" href="/books/assets/js/59.24ca7ee9.js"><link rel="prefetch" href="/books/assets/js/6.32ee54fa.js"><link rel="prefetch" href="/books/assets/js/60.1fc1c4a2.js"><link rel="prefetch" href="/books/assets/js/61.14b84590.js"><link rel="prefetch" href="/books/assets/js/62.8a2d2de8.js"><link rel="prefetch" href="/books/assets/js/63.0dcfee0b.js"><link rel="prefetch" href="/books/assets/js/64.8c28a59c.js"><link rel="prefetch" href="/books/assets/js/65.6d1ae46c.js"><link rel="prefetch" href="/books/assets/js/66.5a616c98.js"><link rel="prefetch" href="/books/assets/js/67.bead4bdc.js"><link rel="prefetch" href="/books/assets/js/68.1d20f97a.js"><link rel="prefetch" href="/books/assets/js/69.76ec2223.js"><link rel="prefetch" href="/books/assets/js/7.b59836f2.js"><link rel="prefetch" href="/books/assets/js/70.6066afd2.js"><link rel="prefetch" href="/books/assets/js/71.d25994bf.js"><link rel="prefetch" href="/books/assets/js/72.94ab8cdd.js"><link rel="prefetch" href="/books/assets/js/73.6682438b.js"><link rel="prefetch" href="/books/assets/js/74.d8d9aac9.js"><link rel="prefetch" href="/books/assets/js/75.c178891f.js"><link rel="prefetch" href="/books/assets/js/76.2292d907.js"><link rel="prefetch" href="/books/assets/js/77.940c9473.js"><link rel="prefetch" href="/books/assets/js/78.1e9432ad.js"><link rel="prefetch" href="/books/assets/js/79.f548c8c7.js"><link rel="prefetch" href="/books/assets/js/8.c9e4b615.js"><link rel="prefetch" href="/books/assets/js/80.e03d9a9c.js"><link rel="prefetch" href="/books/assets/js/81.222e5797.js"><link rel="prefetch" href="/books/assets/js/82.bea6ed3c.js"><link rel="prefetch" href="/books/assets/js/83.cb05beb1.js"><link rel="prefetch" href="/books/assets/js/84.6e31c3ad.js"><link rel="prefetch" href="/books/assets/js/85.b0ce07ff.js"><link rel="prefetch" href="/books/assets/js/86.ae6fb79f.js"><link rel="prefetch" href="/books/assets/js/87.6863b804.js"><link rel="prefetch" href="/books/assets/js/88.ba149380.js"><link rel="prefetch" href="/books/assets/js/89.343c2068.js"><link rel="prefetch" href="/books/assets/js/9.61e3915f.js"><link rel="prefetch" href="/books/assets/js/90.8f71cab6.js"><link rel="prefetch" href="/books/assets/js/91.6334c0db.js"><link rel="prefetch" href="/books/assets/js/92.8a7e8c1d.js"><link rel="prefetch" href="/books/assets/js/93.bd68832a.js"><link rel="prefetch" href="/books/assets/js/94.4083af3f.js"><link rel="prefetch" href="/books/assets/js/95.775d1cde.js"><link rel="prefetch" href="/books/assets/js/96.e244a8c4.js"><link rel="prefetch" href="/books/assets/js/97.27aa8f2b.js"><link rel="prefetch" href="/books/assets/js/98.9d03fea6.js"><link rel="prefetch" href="/books/assets/js/99.488c24e9.js">
    <link rel="stylesheet" href="/books/assets/css/0.styles.253527df.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="ant-row"><div class="sidebar-button"><i aria-label="icon: bars" class="anticon anticon-bars"><svg viewBox="0 0 1024 1024" focusable="false" data-icon="bars" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M912 192H328c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h584c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 284H328c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h584c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 284H328c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h584c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM104 228a56 56 0 1 0 112 0 56 56 0 1 0-112 0zm0 284a56 56 0 1 0 112 0 56 56 0 1 0-112 0zm0 284a56 56 0 1 0 112 0 56 56 0 1 0-112 0z"></path></svg></i> <span></span></div> <div class="ant-col ant-col-xs-24 ant-col-sm-24 ant-col-md-6 ant-col-lg-5 ant-col-xl-5 ant-col-xxl-4"><a href="/books/" class="router-link-active home-link"><img src="/books/Avatar.jpg" alt="zxk's book" class="logo"> <span class="site-name">zxk's book</span></a> <div class="search-box mobile-search"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div></div> <div class="ant-col ant-col-xs-0 ant-col-sm-0 ant-col-md-18 ant-col-lg-19 ant-col-xl-19 ant-col-xxl-20"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><ul role="menu" id="nav" class="ant-menu ant-menu-horizontal ant-menu-root ant-menu-light"><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>
          大数据
        </span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>
          编程语言
        </span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>
          编程基础
        </span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>
          专栏学习
        </span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>
          Linux
        </span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-item"><a href="/books/ruan-jian/">
          软件
        </a></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="display:none;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li><li role="menuitem" class="ant-menu-item"><a href="/books/" class="router-link-active">
          Home
        </a></li><li role="menuitem" class="ant-menu-submenu ant-menu-submenu-horizontal ant-menu-overflowed-submenu" style="visibility:hidden;position:absolute;"><div aria-haspopup="true" class="ant-menu-submenu-title"><span>···</span><i class="ant-menu-submenu-arrow"></i></div></li></ul> <a href="https://github.com/Rianico/books" target="_blank" rel="noopener noreferrer" class="repo-link"><i aria-label="icon: github" class="anticon anticon-github"><svg viewBox="64 64 896 896" focusable="false" data-icon="github" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M511.6 76.3C264.3 76.2 64 276.4 64 523.5 64 718.9 189.3 885 363.8 946c23.5 5.9 19.9-10.8 19.9-22.2v-77.5c-135.7 15.9-141.2-73.9-150.3-88.9C215 726 171.5 718 184.5 703c30.9-15.9 62.4 4 98.9 57.9 26.4 39.1 77.9 32.5 104 26 5.7-23.5 17.9-44.5 34.7-60.8-140.6-25.2-199.2-111-199.2-213 0-49.5 16.3-95 48.3-131.7-20.4-60.5 1.9-112.3 4.9-120 58.1-5.2 118.5 41.6 123.2 45.3 33-8.9 70.7-13.6 112.9-13.6 42.4 0 80.2 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.3-43.9 2.9 7.7 24.7 58.3 5.5 118 32.4 36.8 48.9 82.7 48.9 132.3 0 102.2-59 188.1-200 212.9a127.5 127.5 0 0 1 38.1 91v112.5c.8 9 0 17.9 15 17.9 177.1-59.7 304.6-227 304.6-424.1 0-247.2-200.4-447.3-447.5-447.3z"></path></svg></i></a></nav></div></div> <!----></header> <aside class="sidebar"><!----> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/books/da-shu-ju/spark/00.-fu-lu.html" title="00. 附录" class="sidebar-link">00. 附录</a></li><li><a href="/books/da-shu-ju/spark/01.spark-shell-bei-yong.html" title="spark-shell 备用" class="sidebar-link">spark-shell 备用</a></li><li><a href="/books/da-shu-ju/spark/02.spark-xiao-fei-kafka-jian-xie-xing-duan-kai-dao-zhi-xiao-fei-huan-man.html" title="Spark 消费 Kafka 间歇性断开导致消费缓慢" class="sidebar-link">Spark 消费 Kafka 间歇性断开导致消费缓慢</a></li><li><a href="/books/da-shu-ju/spark/03.spark-zhi-bucket.html" title="Spark 之 bucket" class="sidebar-link">Spark 之 bucket</a></li><li><a href="/books/da-shu-ju/spark/03.spark-de-shu-ju-yu-fen-bu.html" title="Spark 的数据预分布" class="sidebar-link">Spark 的数据预分布</a></li><li><a href="/books/da-shu-ju/spark/04.spark-zhi-dinghadoop-shi-ji-cao-zuo-yong-hu.html" title="Spark指定Hadoop实际操作用户" class="sidebar-link">Spark指定Hadoop实际操作用户</a></li><li><a href="/books/da-shu-ju/spark/05.spark-jioozie-zaikerberos-huan-jing-xia-cao-zuohive.html" title="Spark+Oozie在Kerberos环境下操作hive" class="sidebar-link">Spark+Oozie在Kerberos环境下操作hive</a></li><li><a href="/books/da-shu-ju/spark/06.spark-2.1-mo-ren-rpc-xian-cheng-shu-guo-duo.html" title="Spark 2.1 默认 rpc 线程数过多" class="sidebar-link">Spark 2.1 默认 rpc 线程数过多</a></li><li><a href="/books/da-shu-ju/spark/07.spark-ying-yong-jian-kong.html" title="Spark 3.0 Monitoring with Prometheus" class="sidebar-link">Spark 3.0 Monitoring with Prometheus</a></li><li><a href="/books/da-shu-ju/spark/08.accumulator.html" title="08.Accumulator" class="sidebar-link">08.Accumulator</a></li><li><a href="/books/da-shu-ju/spark/09.sparkstreaming-shi-xianexactly-once-yu-yi.html" title="09. SparkStreaming 实现 Exactly-Once 语义" class="sidebar-link">09. SparkStreaming 实现 Exactly-Once 语义</a></li><li><a href="/books/da-shu-ju/spark/10.sparkstreaming-zhicheckpoint.html" title="10.SparkStreaming之checkpoint" class="sidebar-link">10.SparkStreaming之checkpoint</a></li><li><a href="/books/da-shu-ju/spark/11.-ji-yi-cisparkstreaming-zuo-ye-you-yukerberos-guo-qi-dao-zhi-qia-si.html" title="11. 记一次SparkStreaming作业由于Kerberos过期导致卡死" class="sidebar-link">11. 记一次SparkStreaming作业由于Kerberos过期导致卡死</a></li><li><a href="/books/da-shu-ju/spark/12.learingspark2.0.html" aria-current="page" title="12. LearingSpark2.0" class="active sidebar-link">12. LearingSpark2.0</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/books/da-shu-ju/spark/12.learingspark2.0.html#the-dataframe-api" title="The Dataframe API" class="sidebar-link">The Dataframe API</a></li><li class="sidebar-sub-header"><a href="/books/da-shu-ju/spark/12.learingspark2.0.html#spark-sql-and-dataframes-introduction-to-built-in-data-sources" title="Spark SQL and DataFrames: Introduction to Built-in Data Sources" class="sidebar-link">Spark SQL and DataFrames: Introduction to Built-in Data Sources</a></li><li class="sidebar-sub-header"><a href="/books/da-shu-ju/spark/12.learingspark2.0.html#spark-sql-and-dataframes-interacting-with-external-data-sources" title="Spark SQL and DataFrames: Interacting with External Data Sources" class="sidebar-link">Spark SQL and DataFrames: Interacting with External Data Sources</a></li><li class="sidebar-sub-header"><a href="/books/da-shu-ju/spark/12.learingspark2.0.html#spark-sql-and-datasets" title="Spark SQL and Datasets" class="sidebar-link">Spark SQL and Datasets</a></li><li class="sidebar-sub-header"><a href="/books/da-shu-ju/spark/12.learingspark2.0.html#optimizing-and-tuning-spark-for-efficiency" title="Optimizing and Tuning Spark for Efficiency" class="sidebar-link">Optimizing and Tuning Spark for Efficiency</a></li></ul></li><li><a href="/books/da-shu-ju/spark/13.spark-jie-xijson.html" title="13. Spark解析json" class="sidebar-link">13. Spark解析json</a></li><li><a href="/books/da-shu-ju/spark/14.datasourcev2.html" title="14. DataSourceV2" class="sidebar-link">14. DataSourceV2</a></li><li><a href="/books/da-shu-ju/spark/15.-bian-yispark-fa-bu-bao.html" title="15. 编译 Spark 发布包" class="sidebar-link">15. 编译 Spark 发布包</a></li><li><a href="/books/da-shu-ju/spark/16.sparkstreaming-backpressure-ji-dong-taiexecutor-diao-zheng.html" title="16. SparkStreaming Backpressure 及动态 Executor 调整" class="sidebar-link">16. SparkStreaming Backpressure 及动态 Executor 调整</a></li></ul></section></li></ul></aside> <main class="page"> <div class="theme-antdocs-content content__default"><h2 id="the-dataframe-api"><a href="#the-dataframe-api" class="header-anchor">#</a> The Dataframe API</h2> <h3 id="常用-api"><a href="#常用-api" class="header-anchor">#</a> 常用 API</h3> <p>Spark 支持以下基本数据类型：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210625220640953.png" alt="image-20210625220640953"></p> <p>除了最后的 <code>DecimalType</code> 之外，其他类型都位于 <code>org.apache.spark.sql.types._</code> 下。</p> <p>Spark 还支持一些复杂格式：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210625220847599.png" alt="image-20210625220847599"></p> <p>在读取外部数据之前，通常建议先自定义好 Schema，有如下好处：</p> <ul><li>不用把数据类型推断的任务交给 Spark</li> <li>防止 Spark 额外创建任务去读取文件的一部分以便推测出 Schema，在大文件场景下开销很高</li> <li>在数据不符合预期 Schema 的时候可以尽早地获取到错误</li></ul> <p>定义 Schema 有两种方式，一种是以 API 编程方式，另一种是使用 DDL 字符描述，如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 编程方式</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types</span><span class="token punctuation">.</span>_
<span class="token keyword">val</span> schema <span class="token operator">=</span> StructType<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>StructField<span class="token punctuation">(</span><span class="token string">&quot;author&quot;</span><span class="token punctuation">,</span> StringType<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">,</span> StructField<span class="token punctuation">(</span><span class="token string">&quot;title&quot;</span><span class="token punctuation">,</span> StringType<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
StructField<span class="token punctuation">(</span><span class="token string">&quot;pages&quot;</span><span class="token punctuation">,</span> IntegerType<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">// DDL 方式</span>
<span class="token keyword">val</span> schema <span class="token operator">=</span> <span class="token string">&quot;author STRING, title STRING, pages INT&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>在 spark-shell 中执行如下代码：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> schema <span class="token operator">=</span> <span class="token string">&quot;Id INT, First STRING, Last STRING, Url STRING, Published STRING, Hits INT, Campaigns ARRAY&lt;STRING&gt;&quot;</span>
<span class="token keyword">val</span> blogDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>schema<span class="token punctuation">(</span>schema<span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;/usr/local/src/LearningSparkV2/chapter3/data/blogs.json&quot;</span><span class="token punctuation">)</span>
blogDF show <span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>添加额外的列：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits</span><span class="token punctuation">.</span>_
blogDF<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;Big Hitters&quot;</span><span class="token punctuation">,</span> $<span class="token string">&quot;Hits&quot;</span> <span class="token operator">&gt;</span> <span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token comment">// 排序</span>
blogDF<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>$<span class="token string">&quot;Id&quot;</span><span class="token punctuation">.</span>desc<span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>关于 Column 类型，更多方法详见 <a href="http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Column.html" target="_blank" rel="noopener noreferrer">Spark 3.1.2 ScalaDoc  - org.apache.spark.sql.Column<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p> <p>Column 对象无法独立存在，每个 Column 都是 Row 对象的一部分。</p> <p>Row 在 Spark 中是一个有序的字段集合，</p> <p>通常可以用 Row 对象来快速构造一个 DataFrame 用于快速测试：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rows <span class="token operator">=</span> Seq<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&quot;Matei Zaharia&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;CA&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">&quot;Reynold Xin&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;CA&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> authorsDF <span class="token operator">=</span> rows<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">&quot;Author&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;State&quot;</span><span class="token punctuation">)</span>
authorsDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><blockquote><p>NOTE：通常来说，我们绝大多数场景下都是通过读取一个大文件来构造 DataFrame 的，预先定义好一个 Schema 再来创建一个 DataFrame 更加高效。</p></blockquote> <h3 id="使用-dataframereader-和-dataframewriter"><a href="#使用-dataframereader-和-dataframewriter" class="header-anchor">#</a> 使用 DataFrameReader 和 DataFrameWriter</h3> <p>Spark 提供了两个接口：DataFrameReader 和 DataFrameWriter，分别用于数据的读取与写入。支持的文件格式有 JSON, CSV, Parquet, Text, Avro, ORC 等。</p> <p>Spark 读取文件如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> fireDF <span class="token operator">=</span> spark<span class="token punctuation">.</span>read
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;header&quot;</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;inferSchema&quot;</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;/usr/local/src/LearningSparkV2/chapter3/data/sf-fire-calls.csv&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>Spark 写入数据时默认格式为 Parquet，默认压缩格式为 snappy。数据的 Schema 会作为 Parquet 元数据的一部分进行存储，因此后续重新读取 Parquet 的时候不需要手动指定 Schema。</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>fire_df<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;parquet&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&quot;/usr/local/src/LearningSparkV2/chapter3/data/&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="transformations"><a href="#transformations" class="header-anchor">#</a> Transformations</h3> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>fireDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;CallType&quot;</span><span class="token punctuation">)</span>
	<span class="token comment">// 过滤</span>
	<span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">&quot;CallType&quot;</span><span class="token punctuation">.</span>isNotNull<span class="token punctuation">)</span>
	<span class="token comment">// 聚合</span>
	<span class="token punctuation">.</span>agg<span class="token punctuation">(</span>countDistinct<span class="token punctuation">(</span><span class="token string">&quot;CallType&quot;</span><span class="token punctuation">)</span> as <span class="token string">&quot;DistinctCallType&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">// 重命名列</span>
<span class="token keyword">val</span> newFireDF <span class="token operator">=</span> fireDF<span class="token punctuation">.</span>withColumnRenamed<span class="token punctuation">(</span><span class="token string">&quot;Delay&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;ResponseDelayedinMins&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// String 格式转时间格式，其他时间函数还有 year()/month()/day() 等</span>
<span class="token keyword">val</span> fireTsDF <span class="token operator">=</span> newFireDF
	<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;IncidentDate&quot;</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;CallDate&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;MM/dd/yyyy&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">&quot;CallDate&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;OnWatchDate&quot;</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;WatchDate&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;MM/dd/yyyy&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">&quot;WatchDate&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;AvailableDtTS&quot;</span><span class="token punctuation">,</span> to_timestamp<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;AvailableDtTm&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;MM/dd/yyyy hh:mm:ss a&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token string">&quot;AvailableDtTm&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// 使用 case when</span>
<span class="token keyword">val</span> df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;inferSchema&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;header&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;/usr/local/src/LearningSparkV2/databricks-datasets/learning-spark-v2/flights/departuredelays.csv&quot;</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;delay&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">&quot;origin&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> col<span class="token punctuation">(</span><span class="token string">&quot;destination&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> when<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;delay&quot;</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">360</span><span class="token punctuation">,</span> <span class="token string">&quot;Long Delyas&quot;</span><span class="token punctuation">)</span> when<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;delay&quot;</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">360</span> <span class="token operator">&amp;&amp;</span> col<span class="token punctuation">(</span><span class="token string">&quot;delay&quot;</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">&quot;Short Delay&quot;</span><span class="token punctuation">)</span> otherwise <span class="token string">&quot;Delays&quot;</span> alias <span class="token string">&quot;Long_Delays&quot;</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">&quot;delay&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;origin&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;destination&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">&quot;Filght_Delays&quot;</span><span class="token punctuation">,</span> when<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">&quot;delay&quot;</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">360</span><span class="token punctuation">,</span> <span class="token string">&quot;Long Delyas&quot;</span><span class="token punctuation">)</span> otherwise<span class="token punctuation">(</span><span class="token string">&quot;Delays&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><h3 id="dataset"><a href="#dataset" class="header-anchor">#</a> DataSet</h3> <p>从概念上来说，可以认为 DataFrame 在 Scala 或 Java 中类似于泛型的集合，即 Dataset[Row]。</p> <p>Dataset 通常都是一组有明确类型 JVM 对象的集合，可以借助编译器实现编译时类型安全检查。</p> <blockquote><p>NOTE：Dataset 只在有编译时类型安全的语言中才有意义，两者其实最大的区别就在于编译时对类型安全检查程度的强弱。</p></blockquote> <p>Row 在 Spark 中可以认为类似于一个泛型对象，只能通过索引访问其中的元素，在编译时并无法确定真正的类型，直到运行时才会尝试将 Row 中的元素转化为其对应类型的对象。</p> <p>相比之下，Dataset 里的类型则可以指定为一个明确的 class 类型，可以映射为一个具体的 JVM 对象。</p> <p>创建 Dataset 方式如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">case</span> <span class="token keyword">class</span> DeviceIoTData <span class="token punctuation">(</span>battery_level<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> c02_level<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> cca2<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> cca3<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> cn<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> device_id<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span>device_name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> humidity<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> ip<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> latitude<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> lcd<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> longitude<span class="token operator">:</span> <span class="token builtin">Double</span><span class="token punctuation">,</span> scale<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> temp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> timestamp<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> ds <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">&quot;xxx&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as<span class="token punctuation">[</span>DeviceIoTData<span class="token punctuation">]</span>
<span class="token keyword">val</span> filterTempDS <span class="token operator">=</span> ds<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token punctuation">{</span>d <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span>d<span class="token punctuation">.</span>temp <span class="token operator">&gt;</span> <span class="token number">30</span> <span class="token operator">&amp;&amp;</span> d<span class="token punctuation">.</span>humidity <span class="token operator">&gt;</span> <span class="token number">70</span><span class="token punctuation">}</span><span class="token punctuation">)</span>                         
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>可以看到，使用了 Dataset 后，我们可以在编程中使用很多 JVM 对象常用的方法。</p> <blockquote><p>NOTE：当我们使用 Dataset 时，底层的 Spark SQL 引擎会负责 JVM 对象的创建、转化、序列化 和反序列化。同时也要注意对外内存管理，这块内存用于协助 Dataset 的编码器。</p></blockquote> <p>SQL、DataFrame、Dataset 三者之间在语法、类型检查的区别如下：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210626230810949.png" alt="image-20210626230810949"></p> <h3 id="spark-sql-和底层引擎"><a href="#spark-sql-和底层引擎" class="header-anchor">#</a> Spark SQL 和底层引擎</h3> <p>Spark 可以让开发者通过 SQL 的方式，使用大量内建的结构化方法，除此之外 Spark SQL 引擎还支持如下：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210626231440893.png" alt="image-20210626231440893"></p> <h2 id="spark-sql-and-dataframes-introduction-to-built-in-data-sources"><a href="#spark-sql-and-dataframes-introduction-to-built-in-data-sources" class="header-anchor">#</a> Spark SQL and DataFrames: Introduction to Built-in Data Sources</h2> <h3 id="sql-表与视图"><a href="#sql-表与视图" class="header-anchor">#</a> SQL 表与视图</h3> <p>Spark 是通过 metadata 与表进行关联的，默认使用 <em>Hive metadata</em>，并在 <code>/user/hive/warehouse</code> 下存储关于表的 metadata，可以通过修改 <code>spark.sql.warehouse.dir</code> 指定本地或者外部存储路径。</p> <h3 id="托管表与非托管表"><a href="#托管表与非托管表" class="header-anchor">#</a> 托管表与非托管表</h3> <p>Spark 可以创建两种类型的表：托管表与非托管表。</p> <ul><li>托管表：Spark 同时管理其元数据与数据存储。当 Spark 删除数据时，外部数据源也会跟着删除实际数据。</li> <li>非托管表：Spark 只接管元数据管理，具体数据则由外部数据源自行管理，删除数据时也只会删除元数据而非实际数据。</li></ul> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 创建托管表</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;CREATE TABLE managed_us_delay_flights_tbl (date STRING, delay INT,   distance INT, origin STRING, destination STRING)&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// 创建非托管表</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;CREATE TABLE us_delay_flights_tbl(date STRING, delay INT,   distance INT, origin STRING, destination STRING)
  USING csv 
  OPTIONS (PATH '/databricks-datasets/learning-spark-v2/flights/departuredelays.csv')&quot;&quot;&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h3 id="创建视图"><a href="#创建视图" class="header-anchor">#</a> 创建视图</h3> <p>Spark 可以基于已存在的表创建视图。视图可以基于集群范围跨 SparkSession 使用，也可以只限制在单个 SparkSession 中使用。</p> <p>视图的生命周期与创建它们的 Spark 应用保持一致。</p> <p>SQL 方式创建视图如下：</p> <div class="language-sql line-numbers-mode"><pre class="language-sql"><code><span class="token comment">-- In SQL</span>
<span class="token keyword">CREATE</span> <span class="token operator">OR</span> <span class="token keyword">REPLACE</span> <span class="token keyword">GLOBAL</span> <span class="token keyword">TEMP</span> <span class="token keyword">VIEW</span> us_origin_airport_SFO_global_tmp_view <span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token keyword">date</span><span class="token punctuation">,</span> delay<span class="token punctuation">,</span> origin<span class="token punctuation">,</span> destination <span class="token keyword">from</span> us_delay_flights_tbl <span class="token keyword">WHERE</span> origin <span class="token operator">=</span> <span class="token string">'SFO'</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token operator">OR</span> <span class="token keyword">REPLACE</span> <span class="token keyword">TEMP</span> <span class="token keyword">VIEW</span> us_origin_airport_JFK_tmp_view <span class="token keyword">AS</span>
<span class="token keyword">SELECT</span> <span class="token keyword">date</span><span class="token punctuation">,</span> delay<span class="token punctuation">,</span> origin<span class="token punctuation">,</span> destination <span class="token keyword">from</span> us_delay_flights_tbl <span class="token keyword">WHERE</span> origin <span class="token operator">=</span> <span class="token string">'JFK'</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>Dataframe 创建视图如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>df_sfo <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'SFO'&quot;</span><span class="token punctuation">)</span>
df_jfk <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'JFK'&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// Create a temporary and global temporary view</span>
df_sfo<span class="token punctuation">.</span>createOrReplaceGlobalTempView<span class="token punctuation">(</span><span class="token string">&quot;us_origin_airport_SFO_global_tmp_view&quot;</span><span class="token punctuation">)</span> df_jfk<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;us_origin_airport_JFK_tmp_view&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>需要注意当访问全局的视图时，需要加上 <code>global_temp</code> 前缀：</p> <div class="language-sql line-numbers-mode"><pre class="language-sql"><code><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> global_temp<span class="token punctuation">.</span>us_origin_airport_SFO_global_tmp_view
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>删除视图：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// API 方式</span>
spark<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>dropGlobalTempView<span class="token punctuation">(</span><span class="token string">&quot;us_origin_airport_SFO_global_tmp_view&quot;</span><span class="token punctuation">)</span> 
spark<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>dropTempView<span class="token punctuation">(</span><span class="token string">&quot;us_origin_airport_JFK_tmp_view&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// SQL 方式</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;DROP VIEW IF EXISTS us_origin_airport_SFO_global_tmp_view&quot;</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;DROP VIEW IF EXISTS us_origin_airport_JFK_tmp_view&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>全局视图的作用主要在于跨 SparkSession 使用（一个 Spark 应用可以有多个 Spark Session），在多个 SparkSession 使用了不同 Hive metastore 的时候很方便。</p> <p>Spark 将表、视图的 metastore 高度抽象为了 Catalog。Spark 提供了以下几个 API，可以方便的查看当前 metastore 与数据库、表、视图之间的关联关系：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>spark<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>listDatabases<span class="token punctuation">(</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>listTables<span class="token punctuation">(</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>listColumns<span class="token punctuation">(</span><span class="token string">&quot;xxx&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>Spark 3.0 开始，允许指定 <em>LZAY</em> 关键字，表示这个表只会在初次使用时才缓存起来：</p> <div class="language-sql line-numbers-mode"><pre class="language-sql"><code>CACHE <span class="token punctuation">[</span>LAZY<span class="token punctuation">]</span> <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span><span class="token keyword">table</span><span class="token operator">-</span>name<span class="token operator">&gt;</span>
UNCACHE <span class="token keyword">TABLE</span> <span class="token operator">&lt;</span><span class="token keyword">table</span><span class="token operator">-</span>name<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="data-sources-for-dataframes-and-sql-tables"><a href="#data-sources-for-dataframes-and-sql-tables" class="header-anchor">#</a> Data Sources for DataFrames and SQL Tables</h3> <p>通过前面可以知道，Spark SQL 对于多种数据源提供了一个统一的接口，同时也通过 API 提供了一组公共方法用于数据源读写数据。</p> <p>Spark 不仅提供了各种内置的数据源，还高度抽象了 <strong>DataFrameReader</strong> 以及 <strong>DataFrameWriter</strong> 用于与各种不同的数据源进行交互。</p> <p>DataFrameReader 是读取数据源并将其转化为 DataFrame 的核心结构，其推荐的调用方式如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>DataFrameReader<span class="token punctuation">.</span>format<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;key&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;value&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>schema<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>当前只能通过 SparkSession 来获得其实例：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>SparkSession<span class="token punctuation">.</span>read 
<span class="token comment">// or</span>
SparkSession<span class="token punctuation">.</span>readStream
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>DataFrame 的各个方法入参如下：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210702225706489.png" alt="image-20210702225706489"></p> <blockquote><p>NOTE：通常在读取一个静态 Parquet 数据源的时候是不需要指定 schema 的，因为 Parquet 的 metadata 通常都包含了 schema。</p></blockquote> <p>DataFrameWriter 正好与 DataFramReader 相反，通常使用方式如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>DataFrameWriter<span class="token punctuation">.</span>format<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>bucketBy<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>save<span class="token punctuation">(</span>path<span class="token punctuation">)</span>

DataFrameWriter<span class="token punctuation">.</span>format<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span>args<span class="token punctuation">)</span>
	<span class="token punctuation">.</span>saveAsTable<span class="token punctuation">(</span>table<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>DataFrameWriter 可以通过 DataFrame 获取：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>DataFrame<span class="token punctuation">.</span>write
<span class="token comment">// or</span>
DataFrame<span class="token punctuation">.</span>writeStream
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>各个方法的配置参数如下（仅列出常用部分）：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210703194418025.png" alt="image-20210703194418025"></p> <h3 id="parquet"><a href="#parquet" class="header-anchor">#</a> Parquet</h3> <p>Parquet 是 Spark 默认的存储格式，存储在结构化目录下，包含了数据文件、metadata、一系列压缩后的文件以及一些状态文件。</p> <p>读取 Parquet 有如下几种方式：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>file <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;/databricks-datasets/learning-spark-v2/flights/summary-data/parquet/2010-summary.parquet/&quot;&quot;&quot;</span>
<span class="token comment">// API 方式</span>
df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;parquet&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span>file<span class="token punctuation">)</span>
<span class="token comment">// 创建临时 view 方式</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl USING parquet OPTIONS (path $file)&quot;</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM us_delay_flights_tbl&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>保存 Parquet 方式如下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// API 方式保存文件</span>
df<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;parquet&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">&quot;overwrite&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;compression&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;snappy&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&quot;/tmp/data/parquet/df_parquet&quot;</span><span class="token punctuation">)</span>

<span class="token comment">// API 方式保存到表</span>
df<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">&quot;overwrite&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>saveAsTable<span class="token punctuation">(</span><span class="token string">&quot;us_delay_flights_tbl&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h2 id="spark-sql-and-dataframes-interacting-with-external-data-sources"><a href="#spark-sql-and-dataframes-interacting-with-external-data-sources" class="header-anchor">#</a> Spark SQL and DataFrames: Interacting with External Data Sources</h2> <p>Spark 可以与外部数据源交互，并提供了很高的灵活性。</p> <h3 id="外部数据源"><a href="#外部数据源" class="header-anchor">#</a> 外部数据源</h3> <p>Spark 可以像 Hive 一样定义一个 udf 函数：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala</span>
<span class="token comment">// Create cubed function </span>
<span class="token keyword">val</span> cubed <span class="token operator">=</span> <span class="token punctuation">(</span>s<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{</span> s<span class="token operator">*</span>s<span class="token operator">*</span>s <span class="token punctuation">}</span>
<span class="token comment">// Register UDF</span>
spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">&quot;cubed&quot;</span><span class="token punctuation">,</span> cubed<span class="token punctuation">)</span>
<span class="token comment">// Create temporary view</span>
spark<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;udf_test&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// Query the cubed UDF</span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT id, cubed(id) AS id_cubed FROM udf_test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span> id<span class="token operator">|</span>id_cubed<span class="token operator">|</span> 
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
<span class="token operator">|</span>  <span class="token number">1</span><span class="token operator">|</span>       <span class="token number">1</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">2</span><span class="token operator">|</span>       <span class="token number">8</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">3</span><span class="token operator">|</span>      <span class="token number">27</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">4</span><span class="token operator">|</span>      <span class="token number">64</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">5</span><span class="token operator">|</span>     <span class="token number">125</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">6</span><span class="token operator">|</span>     <span class="token number">216</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">7</span><span class="token operator">|</span>     <span class="token number">343</span><span class="token operator">|</span>
<span class="token operator">|</span>  <span class="token number">8</span><span class="token operator">|</span>     <span class="token number">512</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>Spark SQL 并不保证表达式的执行顺序，例如，下列查询并不保证在执行表达式之前对 s 进行空校验：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT s FROM test1 WHERE s IS NOT NULL AND strlen(s) &gt; 1&quot;</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>通常推荐如下做法：</p> <ol><li>在 UDF 中做空检查</li> <li>使用 <code>IF</code>、<code>CASE WHEN</code> 表达式进行空校验。</li></ol> <p>Spark 可以连接多种数据源并运行 Spark SQL：</p> <ul><li><p><strong>spark-sql</strong>，并不会与 Spark Thrift Server 交互，而是直接与 Hive metastore 进行交互</p></li> <li><p><strong>beeline</strong>，可以通过与 Spark Thrift Server 交互，以 SQL 形式直接执行 Spark SQL</p></li> <li><p><strong>JDBC</strong>，Spark 也可以通过 spark-shell 连接传统的数据库，但需要先指定对应数据库的驱动包，并配置必要的选项：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>./bin/spark-shell --driver-class-path <span class="token variable">$database</span>.jar --jars <span class="token variable">$database</span>.jar
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210703230558794.png" alt="image-20210703230558794"></p></li></ul> <p>当在 Spark SQL 与外部 JDBC 数据源之间传输大量数据的时候，数据源进行分区非常重要。</p> <p>常用的几个配置如下：</p> <ul><li>numPartitions：指定 Spark 读/写的并行度，对应着多少个 JDBC 连接</li> <li>partitionColumn：用于划分数据 partition 的列，可以是 numeric、date、timestamp 类型</li> <li>lowerBound：指定分区列的下界值</li> <li>upperBound：指定分区列的上界值</li></ul> <blockquote><p>NOTE：指定 lowerBound 与 upperBound 时需要注意数据的分布，如果指定 numPartitons 为 10，那么每个数据分片的取值范围为 （upperBound - lowerBound）/ 10。</p></blockquote> <p>以读写 PostgreSQL 为例：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala</span>
<span class="token comment">// Read Option 1: Loading data from a JDBC source using load method val jdbcDF1 = spark</span>
<span class="token keyword">val</span> jdbcDF1 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read
	<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;jdbc:postgresql:[DBSERVER]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;dbtable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[SCHEMA].[TABLENAME]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[USERNAME]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[PASSWORD]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">// Read Option 2: Loading data from a JDBC source using jdbc method // Create connection properties</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util</span><span class="token punctuation">.</span>Properties
<span class="token keyword">val</span> cxnProp <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span>
cxnProp<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[USERNAME]&quot;</span><span class="token punctuation">)</span>
cxnProp<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[PASSWORD]&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// Load data using the connection properties val jdbcDF2 = spark</span>
<span class="token keyword">val</span> jdbcDF2 <span class="token operator">=</span> spark<span class="token punctuation">.</span>read
	<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">&quot;jdbc:postgresql:[DBSERVER]&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[SCHEMA].[TABLENAME]&quot;</span><span class="token punctuation">,</span> cxnProp<span class="token punctuation">)</span> 

<span class="token comment">// Write Option 1: Saving data to a JDBC source using save method</span>
jdbcDF1<span class="token punctuation">.</span>write
	<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">&quot;jdbc&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;url&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;jdbc:postgresql:[DBSERVER]&quot;</span><span class="token punctuation">)</span> 
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;dbtable&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[SCHEMA].[TABLENAME]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;user&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[USERNAME]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;password&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[PASSWORD]&quot;</span><span class="token punctuation">)</span>
	<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">// Write Option 2: Saving data to a JDBC source using jdbc method jdbcDF2.write</span>
jdbcDF2<span class="token punctuation">.</span>write
	<span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span>s<span class="token string">&quot;jdbc:postgresql:[DBSERVER]&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;[SCHEMA].[TABLENAME]&quot;</span><span class="token punctuation">,</span> cxnProp<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br></div></div><p>还有其他几种数据源参考如下：</p> <ul><li>Cassandra：<a href="https://github.com/datastax/spark-cassandra-connector" target="_blank" rel="noopener noreferrer">spark-cassandra-connector<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>MongoDB：<a href="https://docs.mongodb.com/spark-connector/master/" target="_blank" rel="noopener noreferrer">MongoDB Connector for Spark<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h3 id="高阶函数"><a href="#高阶函数" class="header-anchor">#</a> 高阶函数</h3> <p>对于复杂类型的操作，有两种常见的方式：</p> <ul><li><p>将嵌套的结构展开为多行，处理完后重新构造为嵌套结构</p> <div class="language-sql line-numbers-mode"><pre class="language-sql"><code><span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> collect_list<span class="token punctuation">(</span><span class="token keyword">value</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> <span class="token keyword">values</span> <span class="token keyword">FROM</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> EXPLODE<span class="token punctuation">(</span><span class="token keyword">values</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> <span class="token keyword">value</span>
<span class="token keyword">FROM</span> <span class="token keyword">table</span><span class="token punctuation">)</span> x
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> id
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>这种方式下，会涉及到数组里的排序问题，并且也会有 group by 这种昂贵的操作</p></li> <li><p>使用 udf 函数</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">&quot;SELECT id, plusOneInt(values) AS values FROM table&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>对比前种方式，不会有太大的开销，但处理过程中的序列化、反序列开销可能也会很大。</p></li></ul> <p>上述这两种方式都存在一定的缺陷。</p> <h4 id="使用内置函数处理复杂数据类型"><a href="#使用内置函数处理复杂数据类型" class="header-anchor">#</a> 使用内置函数处理复杂数据类型</h4> <p>相比上面的解决方式，Spark 2.4 开始提供了针对复杂类型的内置函数。</p> <p><strong>针对 Array 类型</strong>：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210709222329791.png" alt="image-20210709222329791"></p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210709222329791.png" alt=""></p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210709222412924.png" alt="image-20210709222412924"></p> <p><strong>针对 Map 类型</strong>：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210709222432452.png" alt="image-20210709222432452"></p> <h4 id="高阶函数-2"><a href="#高阶函数-2" class="header-anchor">#</a> 高阶函数</h4> <p>除了前面的内置函数，Spark 还提供了高阶函数，接收一个列（array 类型）与 lambda 表达式，并将表达式作用于列上，生成一个新的列，这类方法往往比 udf 更加高效。</p> <p>首先创建一个 table：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala</span>
<span class="token comment">// Create DataFrame with two rows of two arrays (tempc1, tempc2)</span>
<span class="token keyword">val</span> t1 <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">38</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> t2 <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> tC <span class="token operator">=</span> Seq<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span><span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">&quot;celsius&quot;</span><span class="token punctuation">)</span> 
tC<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">&quot;tC&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// Show the DataFrame</span>
tC<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span> 
<span class="token operator">|</span>             celsius<span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span> 
<span class="token operator">|</span><span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>|
<span class="token operator">|</span><span class="token punctuation">[</span><span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">]</span><span class="token operator">|</span>
<span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p><strong>transform</strong>，对数组进行转化，语法：<em>transform(array<T>, function&lt;T, U&gt;): array<U></U></T></em></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala/Python</span>
<span class="token comment">// Calculate Fahrenheit from Celsius for an array of temperatures </span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;
SELECT celsius,
transform(celsius, t -&gt; ((t * 9) div 5) + 32) as fahrenheit
FROM tC
&quot;&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>filter</strong>，过滤数组中符合条件的元素，语法：<em>filter(array<T>, function&lt;T, Boolean&gt;): array<T></T></T></em>：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala/Python</span>
<span class="token comment">// Filter temperatures &gt; 38C for array of temperatures </span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;
SELECT celsius,
 filter(celsius, t -&gt; t &gt; 38) as high
 FROM tC
&quot;&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>exists</strong>，一旦数组中存在符合条件的元素，就返回整个数组：<em>exists(array<T>, function&lt;T, V, Boolean&gt;): Boolean</T></em></p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala/Python</span>
<span class="token comment">// Is there a temperature of 38C in the array of temperatures </span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;
SELECT celsius,
       exists(celsius, t -&gt; t = 38) as threshold
FROM tC
&quot;&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>reduce</strong>，将数组中的元素进行合并，最后在进行一次处理，类似 rdd 的 reduce 方法：<em>reduce(array<T>, B, function&lt;B, T, B&gt;, function&lt;B, R&gt;)</T></em>：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// In Scala/Python</span>
<span class="token comment">// Calculate average temperature and convert to F </span>
spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token triple-quoted-string string">&quot;&quot;&quot;
SELECT celsius,
	reduce(
	celsius,
    0,
    (t, acc) -&gt; t + acc,
    acc -&gt; (acc div size(celsius) * 9 div 5) + 32
  	) as avgFahrenheit
  FROM tC
&quot;&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>开窗函数：<a href="https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html" target="_blank" rel="noopener noreferrer">Introducing Window Functions in Spark SQL<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>行转列：Pivoting</p> <h2 id="spark-sql-and-datasets"><a href="#spark-sql-and-datasets" class="header-anchor">#</a> Spark SQL and Datasets</h2> <p>DataSet 需要传入一个 case class，并要求字段名称与顺序跟数据的 schema（如果有）保持一致。</p> <p>DataFrame 可以轻松的转化为 DataSet：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">case</span> <span class="token keyword">class</span> erobook<span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> df <span class="token operator">=</span> <span class="token comment">// Generate a DataFrame</span>
df<span class="token punctuation">.</span>as<span class="token punctuation">[</span>erobook<span class="token punctuation">]</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>DataSet 相比 DataFrame，提供了编译时类型安全、面向对象编程风格。</p> <p>相比 DataFrame 直接使用 Tungsten 存储格式，DataSet 需要借助 Encoder 完成 Tungsten 内部格式到 JVM 对象之间的映射。DataFrame 可以看作是一个数据类型为 Row 的 Dataset，Row 内部为 Tungsten 存储结构。</p> <blockquote><p>NOTE： Encoders 负责 Tungsten 二进制格式到 JVM 对象之间的序列化、反序列化，提供了了原始类型、自定义类型的支持。</p></blockquote> <p>Spark 对 Dataset 和 DataFrame 的内存管理演化：</p> <ul><li><p>Spark 1.0 时，Spark 基于 RDD 的 Java 对象作为内存对象存储、序列/反序列化，受到 JVM 的限制。</p></li> <li><p>Spark 1.x 开始，Spark 推出了 Tungsten 项目，可以基于行将 DatsSet、DataFrame 存储在堆外，配合指针以及 offset 使用。Spark 使用 Encoders 在 JVM 对象以及内部 Tungsten 格式之间快速序列化、反序列化。</p></li> <li><p>Spark 2.x 带来了 wscg 以及基于列存储的向量化内存结构，可以充分利用近代处理器的 SIMD 特性。</p></li></ul> <p>相比 Java 对象，Tungsten 使用了紧凑的二进制数组结构存储数据，并且由于已经是二进制数组，因此可以灵活选择存储在堆内或堆外，同时也能节省部分操作（如网络传输时的序列化）。</p> <p>一个对象基于 Tungsten 行存储的结构如下：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/blog/image-20210819155126210.png" alt="image-20210819155126210"></p> <p>使用 Dataset 一个最大的问题就是存在 Tungsten 格式到 JVM 对象之间的序列化-反序列化开销，这也是为了使用面向对象编程的一个代价。</p> <p>减少这个开销通常有两种途径：</p> <ul><li>在高阶函数中尽量使用 DSL，而不使用 lambda、匿名函数，对于 Spark 的 Catalyst 优化器来说，lambda 与匿名函数属于一个“黑盒”操作，难以优化（同 UDF）</li> <li>尽可能使用同一种查询方式，而不是在不同方法之间（DSL 和面向对象）切换，这也是实践中最常用的方式</li></ul> <p>以下面代码为例：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util</span><span class="token punctuation">.</span>Calendar
<span class="token keyword">val</span> earliestYear <span class="token operator">=</span> Calendar<span class="token punctuation">.</span>getInstance<span class="token punctuation">.</span>get<span class="token punctuation">(</span>Calendar<span class="token punctuation">.</span>YEAR<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">40</span>
personDS
 <span class="token comment">// Everyone above 40: lambda-1</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> x<span class="token punctuation">.</span>birthDate<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;-&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt <span class="token operator">&gt;</span> earliestYear<span class="token punctuation">)</span>
 <span class="token comment">// Everyone earning more than 80K</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;salary&quot;</span> <span class="token operator">&gt;</span> <span class="token number">80000</span><span class="token punctuation">)</span>
 <span class="token comment">// Last name starts with J: lambda-2</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> x<span class="token punctuation">.</span>lastName<span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span><span class="token string">&quot;J&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token comment">// First name starts with D</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;firstName&quot;</span><span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span><span class="token string">&quot;D&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>这段查询会不断地在 Tungsten 与 JVM 对象之间来回序列化：</p> <p><img src="https://gitee.com/zhxuankun/Image/raw/master/blog/image-20210819160920302.png" alt="image-20210819160920302"></p> <p>修改为下：</p> <div class="language-scala line-numbers-mode"><pre class="language-scala"><code>personDS
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>year<span class="token punctuation">(</span>$<span class="token string">&quot;birthDate&quot;</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> earliestYear<span class="token punctuation">)</span> <span class="token comment">// Everyone above 40</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;salary&quot;</span> <span class="token operator">&gt;</span> <span class="token number">80000</span><span class="token punctuation">)</span> <span class="token comment">// Everyone earning more than 80K</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;lastName&quot;</span><span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span><span class="token string">&quot;J&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// Last name starts with J</span>
 <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>$<span class="token string">&quot;firstName&quot;</span><span class="token punctuation">.</span>startsWith<span class="token punctuation">(</span><span class="token string">&quot;D&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// First name starts with D</span>
 <span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>这段代码统一使用了 DSL 方式，存在来回切换的开销。</p> <h2 id="optimizing-and-tuning-spark-for-efficiency"><a href="#optimizing-and-tuning-spark-for-efficiency" class="header-anchor">#</a> Optimizing and Tuning Spark for Efficiency</h2> <p>Spark 配置读取顺序（优先级从低到高）：</p> <ol><li>Spark 的 conf 目录下</li> <li><code>spark-submit</code> 指定 <code>--conf</code></li> <li>应用程序内指定</li></ol> <p>开启 Spark 动态资源调整：</p> <ul><li>spark.dynamicAllocation.enabled true</li> <li>spark.dynamicAllocation.minExecutors 2</li> <li>spark.dynamicAllocation.schedulerBacklogTimeout 1m</li> <li>spark.dynamicAllocation.maxExecutors 20</li> <li>spark.dynamicAllocation.executorIdleTimeout 2min</li></ul> <blockquote><p>NOTE： Spark 动态资源调整是基于 pending task 的等待时长来决定是否申请额外资源的。</p></blockquote></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">8/21/2021, 10:56:15 AM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/books/da-shu-ju/spark/11.-ji-yi-cisparkstreaming-zuo-ye-you-yukerberos-guo-qi-dao-zhi-qia-si.html" class="prev"><i aria-label="icon: left" class="anticon anticon-left"><svg viewBox="64 64 896 896" focusable="false" data-icon="left" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M724 218.3V141c0-6.7-7.7-10.4-12.9-6.3L260.3 486.8a31.86 31.86 0 0 0 0 50.3l450.8 352.1c5.3 4.1 12.9.4 12.9-6.3v-77.3c0-4.9-2.3-9.6-6.1-12.6l-360-281 360-281.1c3.8-3 6.1-7.7 6.1-12.6z"></path></svg></i>
        11. 记一次SparkStreaming作业由于Kerberos过期导致卡死
      </a></span> <span class="next"><a href="/books/da-shu-ju/spark/13.spark-jie-xijson.html">
        13. Spark解析json
        <i aria-label="icon: right" class="anticon anticon-right"><svg viewBox="64 64 896 896" focusable="false" data-icon="right" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M765.7 486.8L314.9 134.7A7.97 7.97 0 0 0 302 141v77.3c0 4.9 2.3 9.6 6.1 12.6l360 281.1-360 281.1c-3.9 3-6.1 7.7-6.1 12.6V883c0 6.7 7.7 10.4 12.9 6.3l450.8-352.1a31.96 31.96 0 0 0 0-50.4z"></path></svg></i></a></span></p></div> </main> <!----></div><div class="global-ui"><!----></div></div>
    <script src="/books/assets/js/app.a32f3f13.js" defer></script><script src="/books/assets/js/2.f434c5a6.js" defer></script><script src="/books/assets/js/182.069a8f30.js" defer></script>
  </body>
</html>