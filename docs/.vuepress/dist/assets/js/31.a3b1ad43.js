(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{795:function(e,t,r){"use strict";r.r(t);var a=r(70),s=Object(a.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"kafka-mirror-maker-参数调优"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#kafka-mirror-maker-参数调优"}},[e._v("#")]),e._v(" Kafka mirror maker 参数调优")]),e._v(" "),r("p",[e._v("Kafka Mirror Maker，可以把一个kafka集群中的log复制到另一个kafka集群，架构图如下：")]),e._v(" "),r("p",[r("img",{attrs:{src:"https://raw.githubusercontent.com/Rianico/Image/master/ARTS_Tips/mirror_maker.jpg",alt:"Kafka Mirror Maker"}})]),e._v(" "),r("p",[e._v("从图中可以看出，Kafka Mirror Maker本质上是通过Consumer消费一个Kafka集群，再通过Producer将数据送往另一个集群的，因此调优的核心在于调整好Producer以及Consumer。")]),e._v(" "),r("h2",{attrs:{id:"_1-whitelist-or-blacklist"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-whitelist-or-blacklist"}},[e._v("#")]),e._v(" 1. Whitelist or blacklist")]),e._v(" "),r("p",[e._v("Kafka Mirror Maker通过"),r("code",[e._v("whitelist")]),e._v("或"),r("code",[e._v("blacklist")]),e._v("来决定消费并送往哪些topic，两者只能存在一个。")]),e._v(" "),r("h2",{attrs:{id:"_2-number-of-producers"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-number-of-producers"}},[e._v("#")]),e._v(" 2. Number of producers")]),e._v(" "),r("p",[r("code",[e._v("num.producers")]),e._v("可以指定Mirror Maker中Producer的线程数，每个Producer发出的请求，对应的Kafka Broker都会有一个单独的线程去处理，个人经验最好是Producer的数量最好能跟topic的partition数量对应上。")]),e._v(" "),r("blockquote",[r("p",[e._v("Note：比如topic有4个partition，我们部署了2个Mirror Maker实例，那么每个Mirror Maker实例可以将"),r("code",[e._v("num.producers")]),e._v("设置为2。")])]),e._v(" "),r("h2",{attrs:{id:"_3-number-of-consumption-streams"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-number-of-consumption-streams"}},[e._v("#")]),e._v(" 3. Number of consumption streams")]),e._v(" "),r("p",[r("code",[e._v("num.streams")]),e._v("可以指定Mirror Maker中Consumer的线程数，同建议Consumer的数量最好跟topic的partition数量对应上。")]),e._v(" "),r("blockquote",[r("p",[e._v("Note：比如topic有4个partition，我们部署了2个Mirror Maker实例，那么每个Mirror Maker实例可以将"),r("code",[e._v("num.streams")]),e._v("设置为2。")])]),e._v(" "),r("h2",{attrs:{id:"_4-producer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-producer"}},[e._v("#")]),e._v(" 4. Producer")]),e._v(" "),r("p",[e._v("Producer分为两种模式："),r("strong",[e._v("异步发送")]),e._v("和"),r("strong",[e._v("同步发送")]),e._v("（通过"),r("code",[e._v("producer.type")]),e._v("设置）。")]),e._v(" "),r("h3",{attrs:{id:"_4-1-异步发送"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-异步发送"}},[e._v("#")]),e._v(" 4.1 异步发送")]),e._v(" "),r("p",[e._v("为了更高的吞吐量，我们可以使用异步模式，并且设置为阻塞模式（"),r("code",[e._v("queue.enqueueTimeout.ms=-1")]),e._v("，默认值为0），若不设置该参数，一旦Producer的队列满了，消息会因为QueueFullExceptions而丢失。在阻塞模式下，一旦producer的队列满了，它会自动限制consumer的消费速率，并将部分message暂时存放在磁盘上。")]),e._v(" "),r("h3",{attrs:{id:"_4-2-同步发送"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-同步发送"}},[e._v("#")]),e._v(" 4.2 同步发送")]),e._v(" "),r("p",[e._v("如果需要保证partition内发送的消息有序，则可以设置为同步发送模式，"),r("code",[e._v("acks")]),e._v("设置为1("),r("code",[e._v("至少等待一个follower同步")]),e._v(")/-1("),r("code",[e._v("等待所有follower同步")]),e._v(")，并且将"),r("code",[e._v("retries")]),e._v("设置为1或以上，若为了更高的吞吐量并且不关心写入的结果，可以将acks设置为0，不需要等待follower即可立即返回。")]),e._v(" "),r("p",[e._v("同步模式下需要注意"),r("code",[e._v("producer.request.timeout.ms")]),e._v("（"),r("strong",[e._v("默认值30s")]),e._v("）这个参数，Producer发出请求后，如果返回response的间隔超过了这个阈值，Producer将会重新发送请求或者认定请求失败。")]),e._v(" "),r("p",[e._v("如果在日志中有看到Producer超时异常：")]),e._v(" "),r("div",{staticClass:"language-vim line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-vim"}},[r("code",[e._v("org"),r("span",{pre:!0,attrs:{class:"token operator"}},[e._v(".")]),e._v("apache"),r("span",{pre:!0,attrs:{class:"token operator"}},[e._v(".")]),e._v("kafka"),r("span",{pre:!0,attrs:{class:"token operator"}},[e._v(".")]),e._v("common"),r("span",{pre:!0,attrs:{class:"token operator"}},[e._v(".")]),e._v("errors"),r("span",{pre:!0,attrs:{class:"token operator"}},[e._v(".")]),e._v("TimeoutException"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" Expiring "),r("span",{pre:!0,attrs:{class:"token number"}},[e._v("1")]),e._v(" "),r("span",{pre:!0,attrs:{class:"token function"}},[e._v("record")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("s"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),r("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("for")]),e._v(" xxx due "),r("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("to")]),e._v(" "),r("span",{pre:!0,attrs:{class:"token number"}},[e._v("30024")]),e._v(" ms has passed since batch creation plus linger time。\n")])]),e._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[e._v("1")]),r("br")])]),r("p",[e._v("最直接的方式是适当调大Producer的超时时间，也可以通过增大batch size等。")]),e._v(" "),r("p",[e._v("官方建议该间隔还应大于"),r("code",[e._v("replica.lag.time.max.ms")]),e._v("，可以避免由于follower拉取产生的延迟从而导致额外的重试请求。")]),e._v(" "),r("h3",{attrs:{id:"_4-3-batch-size"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-batch-size"}},[e._v("#")]),e._v(" 4.3 batch.size")]),e._v(" "),r("p",[r("code",[e._v("batch.size")]),e._v("可以指定Producer每个batch发送的大小，默认为16K，若batch过小，会导致Producer频发发送请求，从而导致效率的降低（如前面提到的Producer发送超时），可根据实际场景适当调大。")]),e._v(" "),r("blockquote",[r("p",[e._v("注意：增大Batch Size也就意味着需要压缩数据的时间也相应增长，最后能否提升吞吐量还得自行测试，可以使用Kafka自带的压测工具"),r("code",[e._v("kafka-producer-perf-test.sh")]),e._v(" ，一般来说16K以及256K是一个较为合适的值。")])]),e._v(" "),r("p",[e._v("对该参数进行调整的时候需要考虑到"),r("strong",[e._v("message是否有压缩")]),e._v("，"),r("strong",[e._v("Broker允许接收的最大message大小")]),e._v("等，举个例子：若Broker接收的消息允许的最大值为5MB，消息压缩采用了snappy（压缩比~1:5），那么"),r("code",[e._v("batch.size")]),e._v("最大可以配置为1MB，否则会因此为超过了消息最大大小而导致Broker拒绝接收message。")]),e._v(" "),r("p",[e._v("此处列出常用的几种压缩格式的对比：")]),e._v(" "),r("table",[r("thead",[r("tr",[r("th",{staticStyle:{"text-align":"center"}},[e._v("Algorithm")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("% remaining")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("Encoding")]),e._v(" "),r("th",{staticStyle:{"text-align":"center"}},[e._v("Decoding")])])]),e._v(" "),r("tbody",[r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("GZIP")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("13.4%")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("21 MB/s")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("118 MB/s")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("LZO")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("20.5%")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("172 MB/s")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("410 MB/s")])]),e._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"center"}},[e._v("Zippy/Snappy")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("22.2%")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("172 MB/s")]),e._v(" "),r("td",{staticStyle:{"text-align":"center"}},[e._v("409 MB/s")])])])]),e._v(" "),r("h3",{attrs:{id:"_4-4-linger-ms"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-linger-ms"}},[e._v("#")]),e._v(" 4.4 linger.ms")]),e._v(" "),r("p",[r("code",[e._v("linger.ms")]),e._v("一般"),r("strong",[e._v("仅在异步模式下使用")]),e._v("，这个参数指定了Producer在发送消息前的最大等待时间，默认为0（立即发送）。")]),e._v(" "),r("p",[e._v("这里有个前提条件，就是得message大小小于"),r("code",[e._v("batch.size")]),e._v("，若在"),r("code",[e._v("linger.ms")]),e._v("指定的范围内消息先达到了"),r("code",[e._v("batch.size")]),e._v("，Producer也会立即发送消息。")]),e._v(" "),r("p",[e._v("调大这个值可以提升吞吐量，但也也会增加数据发送的延时。")]),e._v(" "),r("h3",{attrs:{id:"_4-5-buffer-memory"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-buffer-memory"}},[e._v("#")]),e._v(" 4.5 buffer.memory")]),e._v(" "),r("p",[r("code",[e._v("buffer.memory")]),e._v("指定了Producer可以用来缓存消息的内存大小，该值可以适当调大，若buffer过小从而频繁写满，会导致Consumer线程阻塞，如下图：")]),e._v(" "),r("p",[r("img",{attrs:{src:"https://raw.githubusercontent.com/Rianico/Image/master/ARTS_Tips/batch_buffer_small.png",alt:"buffer_memory_small"}})]),e._v(" "),r("p",[e._v("调整的大小可以参考该公式："),r("code",[e._v("buffer.size")]),e._v(" = "),r("code",[e._v("total_topic_partitions")]),e._v("* "),r("code",[e._v("batch.size")]),e._v("，buffer不仅会用来缓存消息，还会被用于压缩消息。")]),e._v(" "),r("h2",{attrs:{id:"_5-consumer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-consumer"}},[e._v("#")]),e._v(" 5. Consumer")]),e._v(" "),r("h3",{attrs:{id:"_5-1-session-timeout-ms-heartbeat-interval-ms"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-session-timeout-ms-heartbeat-interval-ms"}},[e._v("#")]),e._v(" 5.1 session.timeout.ms & heartbeat.interval.ms")]),e._v(" "),r("p",[e._v("通过"),r("code",[e._v("session.timeout.ms")]),e._v("配置，"),r("strong",[e._v("默认值10s")]),e._v("，用于确认一个消费者组内Consumer是否存活，若超过该时间仍没有heartbeat传递过来，则会认为Consumer已失效并触发rebalance。通常heartbeat间隔（"),r("code",[e._v("heartbeat.interval.ms")]),e._v("）应为该值的三分之一。")]),e._v(" "),r("p",[e._v("Kafka0.10之前，Consumer的heratbeat是跟poll一起发送的，这样当两个poll请求之间因为种种原因（e.g. 发生GC）延迟较大时，间隔大于"),r("code",[e._v("session.timeout.ms")]),e._v("从而导致Consumer超时失效：")]),e._v(" "),r("p",[r("img",{attrs:{src:"https://raw.githubusercontent.com/Rianico/Image/master/ARTS_Tips/heartbeat-old-way.png",alt:"image"}})]),e._v(" "),r("p",[e._v("从Kafka0.10开始，新版Consumer支持通过一个后台线程去发送heartbeat请求，而不是再跟随poll请求一起发送。")]),e._v(" "),r("p",[r("img",{attrs:{src:"https://raw.githubusercontent.com/Rianico/Image/master/ARTS_Tips/heartbeat-new-way.png",alt:"heartbeat-new-way"}})]),e._v(" "),r("p",[e._v("这样做的好处是heartbeat不再跟随poll一起发送，可以避免因为poll请求延迟的原因导致Consumer失效。")]),e._v(" "),r("blockquote",[r("p",[e._v("Note：在旧的heartbeat发送模式下，若为了防止poll请求的原因导致Consumer超时失效而将"),r("code",[e._v("session.timeout.ms")]),e._v("也跟着调大间隔，也就意味着Consumer真的故障的话，发现故障Consumer并重新分配的间隔也会变长。")])]),e._v(" "),r("h3",{attrs:{id:"_5-2-max-poll-records"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-max-poll-records"}},[e._v("#")]),e._v(" 5.2 max.poll.records")]),e._v(" "),r("p",[r("code",[e._v("max.poll.records")]),e._v("默认为500，意思是Consumer每次poll的最大条数，根据"),r("code",[e._v("session.timeout.ms")]),e._v("默认值为10s，也就是说官方认为在10s内最多可以poll这么多条数据，若看到下列异常信息：")]),e._v(" "),r("blockquote",[r("p",[e._v("Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured session.timeout.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.")])]),e._v(" "),r("p",[e._v("可以考虑增大"),r("code",[e._v("session.timeout.ms")]),e._v("或者减少"),r("code",[e._v("max.poll.records")]),e._v("，以及排查集群网络等。")]),e._v(" "),r("h3",{attrs:{id:"_5-3-max-poll-interval-ms-consumer-request-timeout-ms"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-max-poll-interval-ms-consumer-request-timeout-ms"}},[e._v("#")]),e._v(" 5.3 max.poll.interval.ms & consumer.request.timeout.ms")]),e._v(" "),r("p",[r("code",[e._v("max.poll.interval.ms")]),e._v("，"),r("strong",[e._v("默认值300s")]),e._v("，指定一个group中Consumer的poll请求之间的最大时间间隔，若超过该值，则会触发rebalance。设定这个值的时候，需要考虑到具体处理下游业务所花费的时间，比如下游写入数据库需要花费5min，那么"),r("code",[e._v("max.poll.interval.ms")]),e._v("则可以考虑设置为6min，间隔过段从而导致无谓的rebalance。")]),e._v(" "),r("p",[r("code",[e._v("consumer.request.timeout.ms")]),e._v("配置，"),r("strong",[e._v("默认值305s")]),e._v("，用于指定Consumer等待请求响应的超时时间，如果超过该值，Consumer将会重新发送请求或者认为请求失败。")]),e._v(" "),r("p",[e._v("由于"),r("code",[e._v("consumer.request.timeout.ms")]),e._v("也决定了多久没收到Consumer的响应就会离开group，所以"),r("code",[e._v("consumer.request.timeout.ms")]),e._v("应该总是略大于"),r("code",[e._v("max.poll.interval.ms")]),e._v("。")]),e._v(" "),r("h2",{attrs:{id:"_6-references"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-references"}},[e._v("#")]),e._v(" 6. References")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"https://kafka.apache.org/0110/documentation.html#consumerconfigs",target:"_blank",rel:"noopener noreferrer"}},[e._v("Kafka 0.11.0 Documentation"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://chrzaszcz.dev/2019/06/kafka-heartbeat-thread/",target:"_blank",rel:"noopener noreferrer"}},[e._v("What does the heartbeat thread do in Kafka Consumer?"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://engineering.salesforce.com/mirrormaker-performance-tuning-63afaed12c21",target:"_blank",rel:"noopener noreferrer"}},[e._v("MirrorMaker Performance Tuning"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330",target:"_blank",rel:"noopener noreferrer"}},[e._v("Kafka mirroring (MirrorMaker)"),r("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=s.exports}}]);