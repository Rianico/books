---
title: 01.ListenerBus 消息总线
date: 2021-06-12
---

## ListenerBus 消息总线

**Spark 版本**：3.1.0

## 1. ListenerBus 概述

ListenerBus 是 Spark 的消息总线接口，会维护一个 Listener 队列，并提供一个全局 Event 分发功能，将事件分发给注册了的 Listener，事件的具体处理逻辑则交由 Listener 自行实现，其继承结构如下：

![image-20210611194451769](https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210611194451769.png)

Spark 2.3 开始为 Listener 添加了 Event 处理时间的统计功能，可以很方便的查看各个 Event 的处理时间，能够帮助开发员人快速定位瓶颈。

Listener 的时间统计功能通过 *spark.scheduler.listenerbus.logSlowEvent*、*spark.scheduler.listenerbus.logSlowEvent.threshold* 参数控制，需要 ListenerBus 子类自行实现 `org.apache.spark.util.ListenerBus#getTimer`  方法，此处不是重点，暂且不关注。

ListenerBus 需要关注的代码如下：

```scala
  private[this] val listenersPlusTimers = new CopyOnWriteArrayList[(L, Option[Timer])]

  // Marked `private[spark]` for access in tests.
  private[spark] def listeners = listenersPlusTimers.asScala.map(_._1).asJava  

  ......
  /**
   * Add a listener to listen events. This method is thread-safe and can be called in any thread.
   */
  final def addListener(listener: L): Unit = {
    listenersPlusTimers.add((listener, getTimer(listener)))
  }

  /**
   * Remove a listener and it won't receive any events. This method is thread-safe and can be called
   * in any thread.
   */
  final def removeListener(listener: L): Unit = {
    listenersPlusTimers.asScala.find(_._1 eq listener).foreach { listenerAndTimer =>
      listenersPlusTimers.remove(listenerAndTimer)
    }
  }

  /**
   * Remove all listeners and they won't receive any events. This method is thread-safe and can be
   * called in any thread.
   */
  final def removeAllListeners(): Unit = {
    listenersPlusTimers.clear()
  }

  /**
   * This can be overridden by subclasses if there is any extra cleanup to do when removing a
   * listener.  In particular AsyncEventQueues can clean up queues in the LiveListenerBus.
   */
  def removeListenerOnError(listener: L): Unit = {
    removeListener(listener)
  }


  /**
   * Post the event to all registered listeners. The `postToAll` caller should guarantee calling
   * `postToAll` in the same thread for all events.
   */
  def postToAll(event: E): Unit = {
    // JavaConverters can create a JIterableWrapper if we use asScala.
    // However, this method will be called frequently. To avoid the wrapper cost, here we use
    // Java Iterator directly.
    val iter = listenersPlusTimers.iterator
    while (iter.hasNext) {
      val listenerAndMaybeTimer = iter.next()
      val listener = listenerAndMaybeTimer._1
      val maybeTimer = listenerAndMaybeTimer._2
      val maybeTimerContext = if (maybeTimer.isDefined) {
        maybeTimer.get.time()
      } else {
        null
      }
      lazy val listenerName = Utils.getFormattedClassName(listener)
      try {
        doPostEvent(listener, event)
        if (Thread.interrupted()) {
          // We want to throw the InterruptedException right away so we can associate the interrupt
          // with this listener, as opposed to waiting for a queue.take() etc. to detect it.
          throw new InterruptedException()
        }
      } catch {
        case ie: InterruptedException =>
          logError(s"Interrupted while posting to ${listenerName}. Removing that listener.", ie)
          removeListenerOnError(listener)
        case NonFatal(e) if !isIgnorableException(e) =>
          logError(s"Listener ${listenerName} threw an exception", e)
      } finally {
        if (maybeTimerContext != null) {
          val elapsed = maybeTimerContext.stop()
          if (logSlowEventEnabled && elapsed > logSlowEventThreshold) {
            logInfo(s"Process of event ${redactEvent(event)} by listener ${listenerName} took " +
              s"${elapsed / 1000000000d}s.")
          }
        }
      }
    }
  }

  /**
   * Post an event to the specified listener. `onPostEvent` is guaranteed to be called in the same
   * thread for all listeners.
   */
  protected def doPostEvent(listener: L, event: E): Unit
```

可以看到 ListenerBus 维护了一个带执行时间统计功能的队列 `listenersPlusTimers` 以及不带时间统计功能的队列 `listeners` ，本质上都是同一条队列，后者用于测试使用。

ListenerBus 提供了添加、移除 listener 的常用功能，代码比较简单，此处不做赘述，重点关注 `postToAll` 方法。这个方法会将遍历注册的 Listener，并将 Event 投递给各个 Listener。

这里需要说明下，每个 ListenerBus 子类都会持有各自的 Listener 类型，并且都会实现各自的 `org.apache.spark.util.ListenerBus#doPostEvent` 方法，通常就是将 Event 直接投递给 Listener，以 `SparkListenerBus` 为例，其实实现如下：

```scala
private[spark] trait SparkListenerBus
  extends ListenerBus[SparkListenerInterface, SparkListenerEvent] {

  protected override def doPostEvent(
      listener: SparkListenerInterface,
      event: SparkListenerEvent): Unit = {
    event match {
      case stageSubmitted: SparkListenerStageSubmitted =>
        listener.onStageSubmitted(stageSubmitted)
      case stageCompleted: SparkListenerStageCompleted =>
        listener.onStageCompleted(stageCompleted)
      case jobStart: SparkListenerJobStart =>
        listener.onJobStart(jobStart)
      // 后续代码省略...
```

这样做本质上是一种监听者模式，各个 ListenerBus 子类只需要在 doPostEvent 方法中专注于自己关心的 Event 投递即可，并且也方便后续扩展关心的事件。

## 2. Listener 概述

虽然 ListenerBus 维护了一组注册的 Listener，但并没有为其定义一个公共的 Listener 接口，从其定义也可以看出来：

```scala
private[spark] trait ListenerBus[L <: AnyRef, E] extends Logging {
  ...
}
```

其实各个 ListenerBus 都有各自不同的 Listener 类型，这里以最常用的事件总线 SparkListenerBus、事件监听器 SparkListener 以及事件类型 SparkListenerEvent 举例说明。

查看 SparkListenerBus 定义如下：

```scala
private[spark] trait SparkListenerBus
  extends ListenerBus[SparkListenerInterface, SparkListenerEvent] {
  ...
}
```

可以看到 SparkListenerBus 持有的是一个 SparkListenerInterface 类型的 Listener，这个接口的实现类有很多，其中最常见的就是 SparkListener，其定义如下：

```scala
@DeveloperApi
abstract class SparkListener extends SparkListenerInterface {
  override def onStageCompleted(stageCompleted: SparkListenerStageCompleted): Unit = { }

  override def onStageSubmitted(stageSubmitted: SparkListenerStageSubmitted): Unit = { }
  ...
}
```

其中每个 `onXXX` 方法都对应了 Spark 在运行时的各个生命周期，每个生命周期关心的事件也不同，其定义如下：

```scala
@DeveloperApi
case class SparkListenerStageCompleted(stageInfo: StageInfo) extends SparkListenerEvent
```

可以看到，其实这些事件都是 SparkListenerEvent 的实现。

## 3. 事件投递

外部系统也是通过 ListenerBus 来投递 Event 的，以 SparkContext 为例，其维护了一个 _listenerBus 变量：

```scala
private var _listenerBus: LiveListenerBus = _
_listenerBus = new LiveListenerBus(_conf)
```

Spark 2.3 版本之前，LiveListenerBus 也是 ListenerBus 的子类，从 2.3 开始，剥离了出来，改为存储多个 *org.apache.spark.scheduler.AsyncEventQueue*（其父类正是 *SparkListenerBus*）对象，由 SparkContext 按需添加。

查看 `org.apache.spark.SparkContext#postApplicationEnd` 方法，可以看到，SparkContext 调用了 LiveListenerBus 的 `post()` 方法：

```scala
  /** Post the application start event */
  private def postApplicationStart(): Unit = {
    // Note: this code assumes that the task scheduler has been initialized and has contacted
    // the cluster manager to get an application ID (in case the cluster manager provides one).
    listenerBus.post(SparkListenerApplicationStart(appName, Some(applicationId),
      startTime, sparkUser, applicationAttemptId, schedulerBackend.getDriverLogUrls,
      schedulerBackend.getDriverAttributes))
    _driverLogger.foreach(_.startSync(_hadoopConfiguration))
  }
```

`post()` 方法实现如下：

```scala
  /** Post an event to all queues. */
  def post(event: SparkListenerEvent): Unit = {
    if (stopped.get()) {
      return
    }

    metrics.numEventsPosted.inc()

    // If the event buffer is null, it means the bus has been started and we can avoid
    // synchronization and post events directly to the queues. This should be the most
    // common case during the life of the bus.
    if (queuedEvents == null) {
      postToQueues(event)
      return
    }

    // Otherwise, need to synchronize to check whether the bus is started, to make sure the thread
    // calling start() picks up the new event.
    synchronized {
      if (!started.get()) {
        queuedEvents += event
        return
      }
    }

    // If the bus was already started when the check above was made, just post directly to the
    // queues.
    postToQueues(event)
  }
```

其中 `postToQueues` 实际上就是将事件投递到 *AsyncEventQueue*：

```scala
  private def postToQueues(event: SparkListenerEvent): Unit = {
    val it = queues.iterator()
    while (it.hasNext()) {
      it.next().post(event)
    }
  }
```

再来看下 *AsyncEventQueue* 的 `post()` 方法：

```scala
  def post(event: SparkListenerEvent): Unit = {
    if (stopped.get()) {
      return
    }

    eventCount.incrementAndGet()
    if (eventQueue.offer(event)) {
      return
    }

    eventCount.decrementAndGet()
    droppedEvents.inc()
    droppedEventsCounter.incrementAndGet()
    if (logDroppedEvent.compareAndSet(false, true)) {
      // Only log the following message once to avoid duplicated annoying logs.
      logError(s"Dropping event from queue $name. " +
        "This likely means one of the listeners is too slow and cannot keep up with " +
        "the rate at which tasks are being started by the scheduler.")
    }
    logTrace(s"Dropping event $event")

    val droppedEventsCount = droppedEventsCounter.get
    val droppedCountIncreased = droppedEventsCount - lastDroppedEventsCounter
    val lastReportTime = lastReportTimestamp.get
    val curTime = System.currentTimeMillis()
    // Don't log too frequently
    if (droppedCountIncreased > 0 && curTime - lastReportTime >= LOGGING_INTERVAL) {
      // There may be multiple threads trying to logging dropped events,
      // Use 'compareAndSet' to make sure only one thread can win.
      if (lastReportTimestamp.compareAndSet(lastReportTime, curTime)) {
        val previous = new java.util.Date(lastReportTime)
        lastDroppedEventsCounter = droppedEventsCount
        logWarning(s"Dropped $droppedCountIncreased events from $name since " +
          s"${if (lastReportTime == 0) "the application started" else s"$previous"}.")
      }
    }
  }
```

可以看到，*AsyncEventQueue* 会将接收到的事件放到一个阻塞队列里。*AsyncEventQueue* 自身在实例化时会启动一个线程去不断消费这个队列里的事件：

```scala
  private val dispatchThread = new Thread(s"spark-listener-group-$name") {
    setDaemon(true)
    override def run(): Unit = Utils.tryOrStopSparkContext(sc) {
      dispatch()
    }
  }

  private def dispatch(): Unit = LiveListenerBus.withinListenerThread.withValue(true) {
    var next: SparkListenerEvent = eventQueue.take()
    while (next != POISON_PILL) {
      val ctx = processingTime.time()
      try {
        super.postToAll(next)
      } finally {
        ctx.stop()
      }
      eventCount.decrementAndGet()
      next = eventQueue.take()
    }
    eventCount.decrementAndGet()
  }
```

通过 Spark UI 界面，也可以看到 "spark-listener-group-$name" 线程：

![image-20210611222728321](https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/image-20210611222728321.png)

此处注意 `dispatch()` 方法里的 `super.postToAll(next)`，可以看到，这里也调用了父类 ListenerBus 的事件投递方法，将 Event 分发给了其他所有 Listener。

## 4. 如何使用消息总线

Spark 对消息总线进行了高度封装，再回顾下 `org.apache.spark.SparkContext#postApplicationEnd` 方法：

```scala
  /** Post the application start event */
  private def postApplicationStart(): Unit = {
    // Note: this code assumes that the task scheduler has been initialized and has contacted
    // the cluster manager to get an application ID (in case the cluster manager provides one).
    listenerBus.post(SparkListenerApplicationStart(appName, Some(applicationId),
      startTime, sparkUser, applicationAttemptId, schedulerBackend.getDriverLogUrls,
      schedulerBackend.getDriverAttributes))
    _driverLogger.foreach(_.startSync(_hadoopConfiguration))
  }
```

可以看到，Spark 内部在提交 Event 的时候，已经包含了很丰富的信息，并且我们也知道，这些事件最终会被投递给其他 Listener。

因此如果想要获取这些消息事件，方式十分简单，只需要继承一个 Listern 接口，重写关注的阶段，注册到 SparkContext 中即可。

继续以 `SparkListener` 为例，我们只需要在 SparkContext 中添加自定义 Listener，重写需要的生命周期方法，这里只重写 `onTaskEnd` 方法：

```scala
  def main(args: Array[String]): Unit = {
    val spark = SparkSession
      .builder()
      .appName("zkx-test1")
      .master("local[2]")
      .getOrCreate()
    spark.sparkContext.addSparkListener(new SparkListener {
      override def onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit = println("Task End...")
    })
    spark.sql("SELECT 1").show()
  }
```

执行后输出如下：

```bash
...
21/06/12 15:57:26 INFO DAGScheduler: Job 0 finished: show at TransportRPCTest.scala:19, took 0.823017 s
Task End...
21/06/12 15:57:26 INFO CodeGenerator: Code generated in 21.0197 ms
+---+
|  1|
+---+
|  1|
+---+
...
```

