---
title: Spark指定Hadoop实际操作用户（非安全环境下）
date: 2020-05-26 17:06:05
---
# Spark指定Hadoop实际操作用户（非安全环境下）



在集群执行`spark-shell --master yarn`的时候，由于集群机器上的spark安装文件属于**root**用户，而HDFS文件系统上的用户名又是**hdfs**，因此无法使用`sudo -u hdfs`来使用hdfs用户启动spark，而使用root用户启动在对HDFS进行读写操作时又会出现权限问题，报错为：

```bash
org.apache.hadoop.security.AccessControlException: Permission denied: user=root, access=WRITE, inode="/xxx":hdfs:supergroup:drwxr-xr-x
```

**解决思路**：指定Spark操作HDFS的用户为hdfs。

**问题解决**：由于Spark的`saveAsTextFile(...)`实质上调用的是Hadoop中保存文件的API，而Hadoop获取用户的代码如下：

```java
if (!isSecurityEnabled() && (user == null)) {
  String envUser = System.getenv(HADOOP_USER_NAME);
  if (envUser == null) {
    envUser = System.getProperty(HADOOP_USER_NAME);
  }
  user = envUser == null ? null : new User(envUser);
}
```

由上可得知，在Hadoop是通过获取系统参数来指定用户的。

> **Note**：在Kerberos安全集群环境下，获取用户的方式又有所不同，详细可以参考[Hadoop Authentication](http://www.udpwork.com/item/7047.html)，此处不做讨论。

到此思路比较明朗了，只要修改系统参数`HADOOP_USER_NAME`的值为hdfs即可，可以通过以下两种方式指定用户。

**方法一：**

在Linux环境下，可以先执行

```bash
export HADOOP_USER_NAME=hdfs
```

然后再启动spark-shell，执行`System.getProperty("HADOOP_USER_NAME")`，即可看到用户已经为hdfs。

**方法二（推荐）：**

对spark-shell的运行时环境进行设置，如下：

```bash
# spark.executor.extraJavaOptions：指定executor端的参数
# spark.driver.extraJavaOptions：指定driver端的参数
spark-shell --master yarn --conf spark.executor.extraJavaOptions=-DHADOOP_USER_NAME=hdfs --conf spark.driver.extraJavaOptions=-DHADOOP_USER_NAME=hdfs
```

执行`System.getProperty("HADOOP_USER_NAME")`，即可看到用户已经为hdfs。

再次执行Spark的保存文件操作，保存成功！

个人比较推荐第二种方法，不仅在spark-shell可以使用，在spark-submit等提交作业的时候也是通用的。

参考：

* [HDFS客户端的权限错误：Permission denied](http://www.huqiwen.com/2013/07/18/hdfs-permission-denied/)
* [Spark官方文档](http://spark.apache.org/docs/latest/configuration.html#runtime-environment)

