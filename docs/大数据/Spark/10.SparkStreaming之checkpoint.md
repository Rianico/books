---
title: 10.SparkStreaming之checkpoint
date: 2021-05-26
---

## SparkStreaming之checkpoint

Spark Streaming 是为了容错恢复的目的存在的，主要存储了以下两类数据：

- *Metadata checkpointing* - 将流式计算相关的定义信息存储到容错的存储中，如 HDFS。这些数据用于 Driver 端的恢复，主要包含：
  - *Configuration* - 创建流式应用时的相关配置。
  - *DStream operations* - 流式应用里定义的一组 DStream 操作。
  - *Incomplete batches* - 还在队列里未完成的 batch。
- *Data checkpointing* - 将生成的 RDD 数据保存在可靠的存储系统中。对于那些依赖多个批次的**有状态操作**来说是有必要的。为了避免无界的依赖链导致恢复时间过长，Spark 会周期性的将中间状态的 RDD 存储到可靠的存储介质上斩断依赖链。

Spark Streaming 从 checkpoint 恢复时，采取的是**重放** batch 计算，而非从上次失败的具体位置开始进行计算。

需要注意的是，当前 Accumulator、Broadcast 还不支持 checkpoint，因此如果开启了 checkpoint，这两者要以懒加载单例模式来进行创建，以便 Driver 从 checkpoint 恢复后能够重新在 executor 端实例化：

```scala
object WordExcludeList {

  @volatile private var instance: Broadcast[Seq[String]] = null

  def getInstance(sc: SparkContext): Broadcast[Seq[String]] = {
    if (instance == null) {
      synchronized {
        if (instance == null) {
          val wordExcludeList = Seq("a", "b", "c")
          instance = sc.broadcast(wordExcludeList)
        }
      }
    }
    instance
  }
}

object DroppedWordsCounter {

  @volatile private var instance: LongAccumulator = null

  def getInstance(sc: SparkContext): LongAccumulator = {
    if (instance == null) {
      synchronized {
        if (instance == null) {
          instance = sc.longAccumulator("DroppedWordsCounter")
        }
      }
    }
    instance
  }
}

wordCounts.foreachRDD { (rdd: RDD[(String, Int)], time: Time) =>
  // Get or register the excludeList Broadcast
  val excludeList = WordExcludeList.getInstance(rdd.sparkContext)
  // Get or register the droppedWordsCounter Accumulator
  val droppedWordsCounter = DroppedWordsCounter.getInstance(rdd.sparkContext)
  // Use excludeList to drop words and use droppedWordsCounter to count them
  val counts = rdd.filter { case (word, count) =>
    if (excludeList.value.contains(word)) {
      droppedWordsCounter.add(count)
      false
    } else {
      true
    }
  }.collect().mkString("[", ", ", "]")
  val output = "Counts at time " + time + " " + counts
})
```

参考：

- https://spark.apache.org/docs/latest/streaming-programming-guide.html#checkpointing

