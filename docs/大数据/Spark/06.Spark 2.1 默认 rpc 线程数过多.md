---
title: Spark 2.1 默认 rpc 线程数过多
date: 2021-02-22
---

# Spark 2.1 默认 rpc 线程数过多

通过 Spark UI 对 Driver 端的线程做分析的时候，发现有个名字为 `dispatcher-eventloop-xx` 格式的线程数目特别多，且绝大多数线程都处于 WAITING 状态：

![image](http://gitlab.haohandata.local/Delivery/CMCC_Guangdong_Processing/uploads/4d95a85e5a7aa48a4101fd0f8544dfc0/image.png)

查看该线程创建时线程数量的源码：

```scala
// org.apache.spark.rpc.netty.Dispatcher#threadpool
val numThreads = nettyEnv.conf.getInt("spark.rpc.netty.dispatcher.numThreads",
      math.max(2, Runtime.getRuntime.availableProcessors()))
```

也就是说，在不指定 `spark.rpc.netty.dispatcher.numThreads` 的场景下，该线程的数量去 2 与所在机器 CPU 的核心数，这种方式是较为浪费资源的。

结合 [SPARK-21408](https://issues.apache.org/jira/browse/SPARK-21408) 可以看到，官方在 Spark 2.3 开始，也对其做出了调整：

```scala
val numThreads = nettyEnv.conf.getInt("spark.rpc.netty.dispatcher.numThreads",
      math.max(2, availableCores))
```

默认取 2 与 `availableCores` 之间的较大者，其中 `availableCores` 是分配给该 Container 的核心数。

至于 Spark 2.3 之前，这可以通过指定 `spark.rpc.netty.dispatcher.numThreads` 来减少创建的线程数，建议设置为 0，避免单个线程挂掉后导致程序异常退出。