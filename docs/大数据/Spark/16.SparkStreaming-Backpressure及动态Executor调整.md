---
title: 16. SparkStreaming Backpressure 及动态 Executor 调整
date: 2021-08-18
---

## SparkStreaming Backpressure 及动态 Executor 调整

在 Medium 看到这篇文章：[Spark Streaming: Dynamic Scaling And Backpressure in Action](https://medium.com/@pmatpadi/spark-streaming-dynamic-scaling-and-backpressure-in-action-6ebdbc782a69)

其中有几个参数在官方文档没有找到：

![image-20210818155443845](https://gitee.com/zhxuankun/Image/raw/master/blog/image-20210818155443845.png)

实际是上就相当于 Spark Core 的动态资源分配，并且 SparkStreaming 与 Spark Core 的这个配置相互冲突，两者不能共存，详见 [**ExecutorAllocationManager**](https://github.com/apache/spark/blob/v3.0.3/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ExecutorAllocationManager.scala#L171)。

SparkStreaming 的 Executor 动态调整，目前来看只有在 Kafka Partition 发生变化时动态调整比较有用，但与Backpressure 结合使用时面临较多问题：

1. Executor 的扩容取决于作业 Processing Time / Batch Interval 的比例，但  也会影响到该值，有时候该比例超过扩容阈值 `0.9`，可能并非是 Executor 资源不足，而是消费速率过高导致的，容易误导 SparkStreaming 扩容 Executor，出现 Executor 并发度高于 Kafka Partition 数的现象。参考链接就是这种情况。
2. 为了避免第 1 点，可以简单的将扩容阈值设置的比较大，但如果此时 Executor 消费处理能力够，又很难触发扩容策略。例如流量低峰期即使一个 Executor 处理 Kafka 两个 Partition 的数据，也可能只用了一个 Batch Interval 多点，此时作业仍会堆积。

也就是说，在使用Backpressure时，由于Backpressure的动态调整，容易误导 SparkStreaming 的 Executor 扩容策略不准确。而不使用Backpressure转而采用固定消费速率的话，又会无法动态调整消费速率，目前来看属于一个比较鸡肋的功能，猜测这也是 Spark 官方文档不做介绍的原因。

目前来看，SparkStreaming 的 Executor 数目调整通过重启应用较为合适，亦或者 Spark Core 的动态资源调整会更加可控。

消费速率通过Backpressure解决。

DataBricks 有一篇文章进行了详细介绍：[Enable Back Pressure To Make Your Spark Streaming Application Production Ready](https://www.linkedin.com/pulse/enable-back-pressure-make-your-spark-streaming-production-lan-jiang)。

