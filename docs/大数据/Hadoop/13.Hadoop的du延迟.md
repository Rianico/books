---
title: 13. Hadoop 的 du 延迟
date: 2021-07-19
---

## Hadoop 的 du 延迟

### 1. du 与 df

HDFS 会使用 du 定期检测磁盘可用空间，通过 `fs.du.interval`（默认 10 分钟） 来控制扫描间隔。

du 命令会将文件的相关信息缓存到 cache 中，在大量文件夹以及文件的场景下，会频繁的淘汰 cache，以及大量的磁盘 I/O，影响整体的 I/O 效率。

相比 du 的扫描粒度则会细致到每个文件，df 只会返回磁盘的统计信息。

HDFS 使用 df 存在一个局限性，就是 df 粒度太粗，无法应对一个磁盘被多个 DN 使用，或者存在多个 BP 的场景。

### 2. 解决方案

#### 2.1 提高扫描间隔

调整扫描间隔，提高 `fs.du.interval` 的值，但治标不治本

#### 2.2 调整 cache

调低 `vm.vfs_cache_pressure`，让 cache 更倾向于缓存 inode 信息，减少磁盘 I/O，其参数含义如下：

- 100：默认值，表示内核将根据 pagecache 和 swapcache，把 directory 和 inode cache 保持在一个合理的百分比
- 低于100，内核倾向于保留 directory 和 inode cache，但同时意味着 cahce 使用掉的系统 memory 将会增加
- 增加该值超过100，将导致内核倾向于回收directory和inode cache

#### 2.3 升级 DataNode Layout

可以参考林意群大神的这篇：[DataNode Layout升级解决Du操作引发的性能问题](https://blog.csdn.net/Androidlushangderen/article/details/91348421)

原本的 HDFS 目录结构是 256X256，可以通过 [HDFS-8791](https://issues.apache.org/jira/browse/HDFS-8791) 这个 patch 升级为 32X32，目录的元数据呈指数级下降。

具体升级原理是会将原有 current 目录重命名为 previous.tmp，之后新建 current 目录，并将 previous.tmp 下的 block 根据新的规则建立 hardlink 链接到 current 新的目录下。

![在这里插入图片描述](https://gitee.com/zhxuankun/Image/raw/master/blog/20190609104806804.png)

Block 是根据位运算计算出目录编号的，原先实现如下：

```java
  /**
   * Get the directory where a finalized block with this ID should be stored.
   * Do not attempt to create the directory.
   * @param root the root directory where finalized blocks are stored
   * @param blockId
   * @return
   */
  public static File idToBlockDir(File root, long blockId) {
    int d1 = (int) ((blockId >> 16) & 0xFF);
    int d2 = (int) ((blockId >> 8) & 0xFF);
    String path = DataStorage.BLOCK_SUBDIR_PREFIX + d1 + SEP +
        DataStorage.BLOCK_SUBDIR_PREFIX + d2;
    return new File(root, path);
  }
```

在调整为 32X32 后，只需要将 0XFF 调整为 0x1F 即可。

#### 2.4 修改获取磁盘空间信息的方式

在 [HDFS-14313：Get hdfs used space from FsDatasetImpl#volumeMap#ReplicaInfo in memory instead of df/du](https://issues.apache.org/jira/browse/HDFS-14313) 这个 patch 中，通过改为从 ReplicaInfo 中计算得到各个磁盘的空间信息。

### 3. 扩展

#### 3.1 inode

在 Unix 设计艺术中，一切皆文件的思想可以将很复杂的东西抽象成简单的概念，从而大大简化接口。

磁盘一个扇区 512 字节，为了提高读取效率，会将多个扇区以一个 block 为单位读取，每个 block 通常为 4KB 大小，最大不能超过内存页的大小。

文件数据存储在 block 中，同时还需要使用一个对象来存储数据文件的元数据，比如文件的创建者、创建时间、大小、权限信息等，这种存储元数据的对象就是 **inode**。

inode 的大小通常为 128 或者 256 字节，可以通过以下命令查看：

```bash
$ less /etc/mke2fs.conf 
[defaults]
        base_features = sparse_super,large_file,filetype,resize_inode,dir_index,ext_attr
        default_mntopts = acl,user_xattr
        enable_periodic_fsck = 0
        blocksize = 4096
        inode_size = 256
        inode_ratio = 16384
```

- blocksize：操作系统 block 的大小
- inode_size：每个 inode 的大小
- inode_ratio：磁盘总大小除以该值可以得出 inode 数量

每个磁盘格式化后，都会有一定数量的 inode，可以通过 `df -iT` 查看 inode 使用情况。

对于 inode 真实大小，可以通过以下命令查看：

```bash
# 针对 xfs
$ xfs_info /dev/sdc1 | grep isize
meta-data=/dev/sdc1              isize=256    agcount=32, agsize=45785024 blks
# 针对 ext
$ tune2fs -l /dev/sdy2 | grep "Inode size"
Inode size:               256
```

每个 inode 都有一个号码，Unix/Linux 实际上是依靠 inode 来访问文件的，文件名只是个别称。

可以通过 `ls -i xxx` 来查看每个文件的 inode 信息，并通过 `stat xxx` 命令查看 inode 具体信息：

```bash
$ stat ./anaconda-ks.cfg 
  File: "./anaconda-ks.cfg"
  Size: 4508            Blocks: 16         IO Block: 4096   普通文件
Device: 802h/2050d      Inode: 14811145    Links: 1
Access: (0600/-rw-------)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2019-08-27 11:05:05.630999912 +0800
Modify: 2019-08-27 11:05:05.639999912 +0800
Change: 2019-08-27 11:05:14.319999912 +0800
```

软硬链接会对 inode 信息有不同的影响：

- 硬链接：使用的是同一个 inode 号码，Links 数会 +1，没删除一个硬链接则 -1；当 Links 为 0 的时候，表示没有文件指向该 inode，系统就会回收该 inode
- 软连接：使用一个新的 inode 号码，Links 数不变，软连接指向的时候 inode 的文件名称，而非 inode 自身

一些由于 inode 产生的特殊现象：

- 文件包含特殊字符无法删除时，删除 inode 也可以达到删除 inode 的目的
- 移动或者重命名文件时，修改的是 inode 里的文件名
- 打开一个文件后，系统就以 inode 识别文件，而不依赖文件名，可以借助这个特性，在不暂停程序的前提下替换文件，生成新的 inode，下次程序启动后就会根据文件名加载到新的 inode
- Unix/Linux 能否读取目录下的文件，权限信息早已存储在文件夹的 inode 中