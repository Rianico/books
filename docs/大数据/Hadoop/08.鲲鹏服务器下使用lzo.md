---
title: 鲲鹏环境下使用 lzo
date: 2021-05-10
---

## 背景

在 x86 服务器上程序使⽤ LZO 压缩时，需要引⼊相关包：

```xml
<dependency>
 <groupId>hadoop-lzo</groupId>
 <artifactId>hadoop-lzo</artifactId>
 <version>0.4.15-gplextras5.0.0</version>
 <type>jar</type>
</dependency>
```

并在启动指定 native 库路径：`-Djava.library.path=/path/to/lib/native`，其 `/path/to/lib/native` 内容如下：

```bash
./
└── native
    ├── libgplcompression.a
    ├── libgplcompression.la
    ├── libgplcompression.so
    ├── libgplcompression.so.0
    └── libgplcompression.so.0.0.0
```

代码使⽤方式：

```
if (compress.equals("lzo")) {
	codec = (CompressionCodec)
	ReflectionUtils.newInstance(Class.forName("com.hadoop.compression.lzo.LzopCodec"), conf);
} else if (compress.equals("gzip")) {
 	codec = (CompressionCodec)
	ReflectionUtils.newInstance(Class.forName("org.apache.hadoop.io.compress.GzipCodec"), conf);
}
try {
 	out = codec.createOutputStream(fs.create(outputFilePath));
} catch (IOException e) {
	 LOG.error("Failed to create HDFS file " + hdfsUri + outputPath + ", moving file to error directory", e);
	 IOUtils.closeStream(out);
	 IOUtils.closeStream(in);
}
```

这段代码在 x86 下使用没有任何问题，但是到了arm架构服务器，⽐如鲲鹏，则会报错：

```
java.lang.RuntimeException: native-lzo library not available
        at com.hadoop.compression.lzo.LzoCodec.createCompressor(LzoCodec.java:165)
        at com.hadoop.compression.lzo.LzopCodec.createOutputStream(LzopCodec.java:50)
        at com.hh.importer.plugin.file.preprocess.writer.HDFSWriter.write(HDFSWriter.java:244)
        at com.hh.importer.plugin.file.preprocess.FilePreProcess.process(FilePreProcess.java:60)
        at com.hh.importer.framework.PipeLine$1.transfer(PipeLine.java:116)
        at com.hh.importer.plugin.file.input.FileInput.run(FileInput.java:92)
        at com.hh.importer.framework.PipeLine.run(PipeLine.java:172)
```

## 问题分析

由于 lzo 压缩算法依赖于编译时的库，而 arm 和 x86 在库与指令方面有所区别，因此的 x86 的 lzo 库在 arm 上无法使用。

解决⽅法：重新编译 hadoop-lzo 的源码，并⽣成 arm 下的 native 库⽂件，重新引⼊新编译的包和库⽂件。

1. 下载lzo包：https://www.oberhumer.com/opensource/lzo/download/lzo-2.10.tar.gz 

2. 解压lzo包并到编译： 

   ```bash
   ./configure --enable-shared --prefix /usr/local/lzo-2.10
   make && sudo make install
   ```

3. 到 https://github.com/twitter/hadoop-lzo 下载源码，放到鲲鹏服务器路径下：`/usr/local/hadoop-lzo` 

4. 编译 hadoop-lzo：

   ```bash
   cd  /usr/local/hadoop-lzo
   C_INCLUDE_PATH=/usr/local/lzo-2.10/include
   LIBRARY_PATH=/usr/local/lzo-2.10/lib
   mvn clean package
   ```

5. 等待完成后，到指定⽂件夹可以看到jar包： `/usr/local/hadoop-lzo/target/hadoop-lzo-0.4.21-SNAPSHOT.jar`

6. native 库也⼀并编译出来了，⾥⾯包含五个⽂件：

   ```bash
   ll /usr/local/hadoop-lzo/target/native/Linux-aarch64-64/lib
   
   -rw-r--r-- 1 root root 117270 May  8 21:24 libgplcompression.a
   -rw-r--r-- 1 root root   1124 May  8 21:24 libgplcompression.la
   lrwxrwxrwx 1 root root     26 May  8 21:24 libgplcompression.so -> libgplcompression.so.0.0.0
   lrwxrwxrwx 1 root root     26 May  8 21:24 libgplcompression.so.0 -> libgplcompression.so.0.0.0
   -rwxr-xr-x 1 root root 127808 May  8 21:24 libgplcompression.so.0.0.0
   ```

在获得对应 jar 包以及 native 库文件后，再根据项目的具体方式引入即可。

## 验证

鲲鹏上查看 lzo 是否正确安装：

```bash
yum install lzop -y
echo ’testlzo’ > test
lzop test
lzop -dc test.lzo | more

# 输出内容
testlzo
```

