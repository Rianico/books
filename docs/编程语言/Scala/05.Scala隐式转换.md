---
title: Scala隐式转换
date: 2020-05-26 17:06:05
---
# Scala隐式转换

隐式转换可以对类的功能进行拓展，通常可以用于扩展第三方类的方法，添加自定义功能等，而无需额外修改原有类或创建新的类。

### String 类型功能扩展

以拓展String类型为例，将String作为入参（其他类型同理），通常使用隐式扩展功能，要么返回一个已定义的class（spark源码使用的方式），要么隐式定义一个新的class，如下：

```scala
object Solution1 {

  class RichString(str: String) {
    def read() = {
      println(str + "_fun")
    }
  }

  object Context {
    // 返回一个已定义的class，此方式更为常用
    implicit def fun(str: String) = new RichString(str)
      
    // 新定义一个class
    implicit class myString(str: String) {
      def read2() = {
        println(str + "_class")
      }
    }
  }

  def main(args: Array[String]): Unit = {
    import Context._

    "".read()
    "".read2()
  }

}

// 输出：
_fun
_class
```

隐式转换函数在同个作用域下，与名字无关，与入参类型有关。

### Spark 对 KV 元组的统一扩展

Spark 还借助隐式转换，对 KV 元组类型的 RDD 统一提供 `reduceByKey`、`groupByKey` 等扩展函数，从而无需为每个 KV 元组格式的 RDD 实现类维护这些方法。

首先定义一个提供了扩展函数的类：`org.apache.spark.rdd.PairRDDFunctions`

```scala
/**
 * Extra functions available on RDDs of (key, value) pairs through an implicit conversion.
 */
class PairRDDFunctions[K, V](self: RDD[(K, V)])
    (implicit kt: ClassTag[K], vt: ClassTag[V], ord: Ordering[K] = null)
  extends Logging with Serializable {
  ...
  def reduceByKey(partitioner: Partitioner, func: (V, V) => V): RDD[(K, V)] = self.withScope {
  ...
  }
  ...
}
```

之后在 RDD 类中通过隐式转换方式引入该类：

```scala
object RDD {

  ...
  implicit def rddToPairRDDFunctions[K, V](rdd: RDD[(K, V)])
    (implicit kt: ClassTag[K], vt: ClassTag[V], ord: Ordering[K] = null): PairRDDFunctions[K, V] = {
    new PairRDDFunctions(rdd)
  }
  ...
}
```

这样一来，`RDD[K, V]` 就能使用扩展函数了。
