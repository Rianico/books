---
titile: 12.Spark 之 AQE
date: 2021-05-08
---

## 1. AQE 三特性

AQE 主要是利用 Shuffle 阶段 Spark 获取到的一些数据相关信息，对整体执行流程进行动态的一种优化手段。

**自动分区合并**，指定一个期望的数据分片大小，以及期望的最小分区数，通过这两个参数各自计算出一个数据分片的大小，并其中的较小者。

**数据倾斜处理**，指定一个可以认定为倾斜分区的阈值，以及一个放大倍数。Spark 会统计出所有数据分片大小的中位数，当某个数据分片大小超过指定阈值，并且还超过中位数大小乘以放大倍数的时候，则会被认定为倾斜分区，并按照我们指定的数据分片期望大小进行切割。

**Join策略调整**，主要涉及了一个逻辑规则和一个物理策略，它们分别是 DemoteBroadcastHashJoin 和 OptimizeLocalShuffleReader。

- DemoteBroadcastHashJoin ：如果 Shuffle Write 之后存在小于广播阈值的表，并且该非空分区比例大于 `spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin`（默认 0.2），则会将 Sort Merge Join 降级为 Broadcast Join。
- OptimizeLocalShuffleReader：在进行常规 Shuffle Write 之后，大表一端不会再进行数据 Shuffle 网络传输，而是就近读取本地节点的中间文件。

## 2. 动态分区裁剪 DPP

**DPP（Dynamic Partition Pruning，动态分区剪裁）是谓词下推中的一个特例**，当两个表关联时，DPP 会将经过过滤的小表的 Join Key 及需要用到的 Value 广播到大表，减少大表需要扫描的数据量。

大表能够借助 DPP 减少扫描数据量有以下几个条件：

- 大表必须是分区表，且分区字段必须是 Join Key
- DPP 仅支持等值 Join
- 小表过滤后的数据集大小要小于广播阈值

## 3. Join 策略选择

对于参与关联的两张数据表，体量较大、主动扫描数据的表，称为**外表**或是**驱动表**；体量较小、被动参与数据扫描的表，称为**内表**或是**基表**。

Join 的类型共有 Nested Loop Join、Hash Join、Shuffle Merge Join 三种。

- NLJ：采用嵌套循环进行关联，每遍历一条外表数据，就会遍历一次内表进行关联，通常用在不等值关联场景，时间复杂度为 O(M * N)。

- Hash Join：对内表构建一个 Hash Table 到内存中，外表根据 key 做 Hash 以 O(1) 的方式进行关联。

- Sort Merge Join：先对两张表进行排序，再归并关联，时间复杂度为 O(M + N)：

  - 如果外表 Join Key 等于内表 Join Key，则进行关联，接着外表滑动到下一条记录
  - 如果外表 Join Key 小于内表 Join Key，不满足关联条件，则外表滑动到下一条记录
  - 如果外表 Join Key 大于内表 Join Key，不满足关联条件，则内表滑动到下一条记录

  ![](https://static001.geekbang.org/resource/image/e2/b2/e2a8f8d1b2572ff456fa83a3f25ccbb2.jpg)

  

在**等值关联**中，Spark 会按照 BHJ > SMJ > SHJ 的顺序选择 Join 策略。

由于 SMJ（外部排序） 比 SHJ（内存构建）稳定，因此优先级更高。

使用 SHJ 有以下两个条件：

1. 外表比内表大 3 倍以上
2. 内表大小不超过广播阈值

除此之外，还要求将 `spark.sql.join.preferSortMergeJoin` 设置为 false，否则 Spark 将永远优先选择 SMJ，且降级时也会降为 BHJ。

当设置为 false 后，如果满足了 BHJ （`spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin`）也会优先选择 BHJ，之后才选择 SHJ。

```scala
// spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin 
// 调整 BHJ 的触发阈值，以及是否关闭 SMJ 优先的开关
// /usr/local/src/spark-3.1.1-bin-hadoop2.7/bin/spark-shell --master local[201] --conf spark.sql.adaptive.enabled=true --conf spark.sql.autoBroadcastJoinThreshold=80B --conf spark.sql.adaptive.coalescePartitions.enabled=false --conf spark.sql.adaptive.localShuffleReader.enabeld=false --conf spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.005 --conf spark.sql.join.preferSortMergeJoin=false


import spark.implicits._

case class TestEntryKV(key: Int, value: String)

val input4 = sc.parallelize((1 to 200).map(nr => TestEntryKV(nr, nr.toString)), 100).toDF()
input4.createOrReplaceTempView("input4")

val input5 = sc.parallelize(Seq(TestEntryKV(1, "1"), TestEntryKV(2, "2"), TestEntryKV(3, "3"), TestEntryKV(4, "4"))).toDF()
input5.createOrReplaceTempView("input5")

val sqlQuery = spark.sql("SELECT * FROM input4 JOIN input5 ON input4.key = input5.key WHERE input4.value = '1'".stripMargin)

sqlQuery.collect
```

需要注意的是，Spark 对文件大小的判断是否超过广播阈值，在数据读取来源不同的情况下是有所差别的，当数据读取来源于外部存储时，则以外部存储上的大小作为广播阈值的依据；若数据来自内存，则以内存中的大小为依据。但这种方式存在一个问题，就是数据读到内存中后，往往会有一定的膨胀，如果未考虑进该因素，则可能导致 Driver 端 OOM。
