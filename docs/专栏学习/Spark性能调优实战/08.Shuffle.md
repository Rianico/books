---
title: 08.Shuffle
date: 2021-04-13
---

Spark 2.0 版本之后，Spark 将 Shuffle 操作统一交由 Sort Shuffle Manager 来管理。

Shuffle 的发生与否**并不取决于特定算子，而是根据 RDD 的依赖模型来决定的，通过判断子 RDD 与父 RDD 的 partitoner 获取依赖模型**。

> NOTE：比如 groupByKey 通常会引入 Shuffle ，但在存储的时候根据特定 key 进行 bucket 存储，后续读取该数据以该 key 做 groupByKey 操作时，是不会发生 Shuffle 的。

Shuffle 本质上就是 MapReduce：

- Map 阶段也可以称为 Shuffle Write，主要是将需要 Shuffle 的数据进行落盘，生成两类文件，后缀为 data 的数据文件存储待分发的数据，后缀为 index 的索引文件记录 data 文件中不同分区的偏移量。
- Reduce 阶段称为 Shuffle Read，主要是从指定节点上拉取所需数据。

Shuffle 需要使用大量的硬件资源，包括 CPU、内存、网络、磁盘等，由于不同磁盘的速度远远低于 CPU、内存等其它设备，同时会截断 Stage，因此 Shuffle 的性能是相当差的。

Shuffle Write 阶段，每个 task 的执行流程都是一样的，因此，总共有多少个 task 就会生成多少个最终的中间文件。

Shuffle 时会将需要落盘的数据先写到一个数据结构中暂存，该数据结构的存储容量有限，一旦快满的时候就会将数据进行落盘，并重复**排序（非必要）、溢出**直到所有数据落盘，最后通过归并排序（external sorter）对所有临时文件进行合并。

> NOTE：如果需要排序且为指定排序昂是，那么 Spark 会至少按照 partition 来排序。

不同的 Shuffle Write 所使用到的中间数据结构也不一样：

- 如果不需要在 Shuffle Write 阶段进行预聚合，则会使用一个 **PartitionedPairBuffer** 的数据结构：
  - PartitionedPairBuffer 是一个数组形式的缓存结构
  - 存储的每条数据记录占用数组中相邻的两个元素空间，第一个元素是**（目标分区，Key）**，第二个元素是 Value
- 如果需要在 Shuffle Write 阶段进行预聚合，则会使用一个 **PartitionedAppendOnlyMap** 的数据结构：
  - PartitionedAppendOnlyMap 是一个 Map，Value 值可累加、更新
  - PartitionedAppendOnlyMap 相对 PartitionedPairBuffer 来说，存储效率更高，落盘频率也越低

> NOTE：如果 Map 端有 aggregate 或者 sort 操作，则会根据 partitionId、key 进行排序，否则只是简单地将数据分到对应的 partition；如果 Map 端无 aggreate 操作且分区数小于 `spark.shuffle.sort.bypassMergeThreshold`，则可以跳过排序操作。

Shuffle Write 结束后，各个 executor 就会进行 Shuffle Read 拉取数据，本质上就是 stage 之间数据的分发，Shuffle Read 需要拉取数据的次数，会随着 task 的增长而呈指数级增长。