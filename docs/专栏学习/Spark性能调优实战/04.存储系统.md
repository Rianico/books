---
title: 04.存储系统
date: 2021-04-05
---

## 存储系统

Spark 存储系统主要用于存储三个方面的数据：

- **RDD 缓存**：将 RDD 以缓存的形式物化到内存或者磁盘中
- **Shuffle 中间文件**：Shuffle Map 阶段的输出结果，会以文件形式落到磁盘上
- **广播变量**：在 Executor 进程范围分发访问频次较高的小数据

Spark 存储系统主要有以下组件：

- BlockManager & BlockManagerMaster
- MemoryStore
- DiskStore & DiskBlockManager

## 1. 存储管理

BlockManager 是最为重要的组件，**它在 Executors 端负责统一管理和协调数据的本地存取与跨节点传输**:

- 对外，BlockManager 与 Driver 端的 BlockManagerMaster 通信，定期汇报本地数据元信息，不定时拉取全局数据存储状态，还负责与其他 Executor 端的 BlockManager 之间进行跨节点数据推送与拉取。
- 对内，BlockManager 调用存储系统内部组件的功能来实现数据的存取与收发。

## 2. 存储方式

Spark 提供了两种存储抽象：MemoryStore 和 DiskStore，BlockManager 用它们分别来管理数据在内存和磁盘中的存取。

Spark 支持两种数据存储形式：**对象值（Object Values)**和**字节数组（Byte Array）**，两者可以相互转化，对象值转化为字节数组的过程称为序列化，反过来则为反序列化。

### 2.1 MemoryStore

广播变量的全量数据会存储在 Executor 进程中，由 MemoryStore 管理。

RDD 可以选择缓存在内存（或者内存 + 磁盘混合）中，此时会涉及到 MemoryStore。

MemoryStore 既可以存储对象值，也可以存储字节数组，并统一采用 **MemoryEntry** 数据抽象进行封装。

MemoryEntry 有两个实现类：**DeserializedMemoryEntry** 和 **SerializedMemoryEntry**，分别用于封装原始对象值和序列化之后的字节数组。

DeserializedMemoryEntry 用 Array[T]来存储对象值序列，其中 T 是对象类型，而 SerializedMemoryEntry 使用 ByteBuffer 来存储序列化后的字节序列。

MemoryStore 使用了 LinkedHashMap[BlockId, MemoryEntry] 来管理 MemoryEntry，基于这种数据结构，可以很容易的实现 LRU 内存淘汰策略。

在逻辑关系上，RDD 的数据分片与存储系统的 Block（MemoryEntry） 一一对应，一个 RDD 数据分片会被物化成一个内存或磁盘上的 Block。

![](https://static001.geekbang.org/resource/image/1y/0b/1yy5fd9f111f4cab0edc7cf582bd2b0b.jpg)

RDD 缓存的具体过程如下：

- 先通过调用 **putIteratorAsValues** 或是 **putIteratorAsBytes** 方法把 RDD 迭代器展开为数据值，并将其存储到 **ValueHolder** 的数据结构里，这一步称为 ”Unroll“。
- 调用 ValueHolder 的 toArray 或 toByteBuffer 操作，转化为 MemoryEntry 数据结构，这一步叫做“从 Unroll memory 到 Storage memory 的 Transfer（转移）”。
- 包含 RDD 数据值的 MemoryEntry 和与之对应的 BlockId，会被一起存入 Key 为 BlockId、Value 是 MemoryEntry 引用的链式哈希字典中。

### 2.2 DiskStore

Shuffle 中间文件由于涉及到落盘，因此是由 DiskStore 管理的。

DiskStore 中数据存取本质上就是字节数组与磁盘文件之间的转换。DiskStore 自身并不负责维护文件路径，数据块对应关系等信息，而是交由 DiskBlockManager 进行维护。

DiskBlockManager 的主要负责**记录逻辑数据块 Block 与磁盘文件系统中物理文件的对应关系，每个 Block  对应一个磁盘文件**。

DiskBlockManager 初始化时，会根据 `spark.local.dir` 确定文件目录，接着根据 `spark.diskStore.subDirectories`（默认 64）指定的数

量创建子目录，这些目录用于存储 DiskStore 物化的文件，如 RDD 缓存、SHuffle 中间结果文件等。

![](https://static001.geekbang.org/resource/image/1e/4f/1eccayy6d9b7348ceea3cf3b12913a4f.jpg)

**Spark 默认采用 SortShuffleManager 来管理 Stages 间的数据分发，在 Shuffle write 过程中，有 3 类结果文件：temp_shuffle_XXX、shuffle_XXX.data 和 shuffle_XXX.index**：

- temp_shuffle_XXX：表示 Shuffle 中间结果的临时文件，后面会合并后删除
- shuffle_XXX.data：由 temp_shuffle_XXX 合并而来
- shuffle_XXX.index：记录了 shuffle_XXX.data 文件内不同分区的偏移地址

其中 XXX 为对应 Block 的 BlockID。

Shuffle Write 阶段，Shuffle Manager 会通过 BlockManager 调用 DiskStore 的 `putBytes` 方法将数据块写入文件中，文件由 DiskBlockManager 创建，这些文件会以 temp 或者 shuffle 开头，保存在 spark.local.dir 下。

Shuffle Read 阶段，Shuffle Manager 会通过 BlockManager 调用 DiskStore 的 getBytes 方法，读取 data 和 index 文件，将其转化为数据块，通过网络分发到 Reducer 端进行聚合。