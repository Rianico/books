---
title: 06.应用开发原则
date: 2021-04-10
---

## 应用开发原则

Spark 应用开发中，有几个原则应当遵守，分别为充分利用 Spark 自身提供的优化机制，以及代码编写中的一些规范。

### 1. Tungsten

**在数据结构方面，Tungsten 自定义了紧凑的二进制格式**，并且借由其二进制格式，天然地避免了 Java 对象序列化与反序列化引入的计算开销。

基于定制化的二进制数据结构，Tungsten 利用 Java Unsafe API 开辟堆外（Off Heap Memory）内存来管理对象。

在运行时，Tungsten 用**全阶段代码生成（Whole Stage Code Generation）**取代**火山迭代模型**，这不仅可以减少虚函数调用和降低内存访问频率，还能提升 CPU cache 命中率，做到大幅压缩 CPU idle 时间，从而提升 CPU 利用率。

[Spark SQL: Another 16x Faster After Tungsten](https://databricks.com/session/spark-sql-another-16x-faster-after-tungsten)

### 2. AQE

**AQE（Adaptive Query Execution）**全称“自适应查询执行”，它可以在 Spark SQL 优化的过程中动态地调整执行计划。

Spark SQL 的优化过程可以大致分为**语法分析**、**语义解析**、**逻辑计划**和**物理计划**这几个环节。在以前（Spark 3.0 之前）的 Spark SQL 中，一旦选定了物理执行计划，便无法再更改，而 **AQE 可以让 Spark 在运行时的不同阶段，结合实时的运行时状态，周期性地动态调整前面的逻辑计划，然后根据再优化的逻辑计划，重新选定最优的物理计划，从而调整运行时后续阶段的执行方式**。

![](https://static001.geekbang.org/resource/image/4c/17/4cdd21d991c290a12e34d5dbfbdf1f17.jpg)

AQE 主要带来了 3 个方面的改进：

- **自动分区合并**，AQE 会自动检测过小的数据分区，并对它们自动合并。
- **数据倾斜（Data Skew）**，在数据关联（Joins）的场景中，如果 AQE 发现某张表存在倾斜的数据分片，就会自动对它做加盐处理，同时对另一张表的数据进行复制。
- **Join 策略调整**，两个有序表要进行数据关联的时候，Spark SQL 在优化过程中总会选择 Sort Merge Join 的实现方式。但有一种情况是，其中一个表在排序前需要对数据进行过滤，过滤后的表小到足可以由广播变量容纳。这个时候，AQE 会切换为 Broadcast Join。

### 3. 能省则省、能拖则拖

应用开发中，我们执行的操作，尽可能的将能够减少数据量的操作提前，并减少 shuffle 操作，如果无法避免 shuffle 操作，则尽量将其延后。

### 4. 跳出单机思维

如果需要对两张表进行关联，那么可以考虑是否能将其中一张表的数据量缩减，从而将 shuffle 优化为 Broadcast Join。

例如将其中一张表的多个 Join Key 转化为 hash，然后附带必要列的数据。

