---
title: 01.时间复杂度
date: 2020-07-22 14:48:49
---
## 1. 为什么需要复杂度分析？

将代码跑一遍，对性能进行统计、监控得出执行时间以及内存占用，这种方法叫做**事后统计法**，这种方法两个缺点：

1. **测试结果受运行环境影响较大**，运行在不同的环境、硬件（比如i3跟i9的处理器）上得到的结果是不同的。
2. **不同数据规模得出的结论不一样**，比如对一段已经有序的数据， 排序算法不需要做任何操作，执行时间就会非常短。 再比如于小规模的数据排序，插入排序可能反倒会比快速排序要快！ 

因此通过复杂度分析，**可以很快地估算出执行效率**。

## 2. 大 O 复杂度表示法

以下面代码为例：

```java
 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

假设一行代码是 1 个 `unit_time`，那么这段代码第 2, 3 行总共就是 2 个 `unit_time`，第 4~6 行里共循环了 n 次，则是 n 个 `unit_time`，第 7 行为 1 个 `unit_time`，那么总共花费的时间为：

$$T(n) = 2*unit\_time + n*unit\_time + 1*unit\_time= (3 + n)*unit\_time$$

按照这个思路，再分析以下代码：

```java
 int cal(int n) {
   int sum = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1;
     for (; j <= n; ++j) {
       sum = sum +  i * j;
     }
   }
 }
```

其中第 2~3 行花费的时间为 3 个 `unit_time`，第 6 行则为 n 个 `unit_time`，第 8 行由于有两层 n 次循环的嵌套，所以是 n * n 个 `unit_time` ，总共花费的执行时间为：

$$T(n)=3*unit\_time + n*unit\_time + n*n*unit\_time\\\ \ \ \ \ \ \ =(3 + n + n^2)*unit\_time$$

可以推导出这样一个结论：**所有代码的执行时间 T(n) 与每行代码执行的次数 n 成正比**。

因此我们可以将其整理为以下公式：

$$T(n)=O(f(n))$$

* T(n)：指代码的执行时间。
* f(n)：表示代码执行的总次数，可以用数学中的公式来表示。
* O：代表两者间关系成正比。

以上称为**大 O 时间复杂度表示法**，并不代表代码执行花费的真正时间，而是指**随着数据规模的变化执行时间呈现的变化趋势**，因此也被称为**渐进时间复杂度**，简称**时间复杂度**。

当 n 很大的时候，其中的低阶、常量、系数并不会很大程度地左右时间复杂度的增长趋势，因此只需关注最大的那个量级即可。

比如上面两段代码的时间复杂度用大 O 表示法可表示为：

$$T(n) = O(n) \\
T(n) = O(n^2)$$

## 3. 时间复杂度分析

大 O 时间复杂度表示法只是表示了时间复杂度的一种变化趋势，我们在分析一个算法，一段代码的时候，也只关注最大的那个量级，那么如何找出这个最大的量级呢？下面介绍 3 个常用的法则。

### 3.1  只关注循环执行次数最多的一段代码

**分析一个算法、一段代码的时间复杂度，只关注循环执行次数最多的那一段代码即可**。 以下面的代码为例：

```java
 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

上面的代码第2、3、7行都是常量级的执行时间，只有第 4~6 行循环了 n 次，因此要重点关注，因此这段代码的时间复杂度就是 $O(n)$。

### 3.2 加法法则：总复杂度等于量级最大的那段代码的复杂度

在有多个时间复杂度相加的情况下，取其中最大的量级。也就是说：**总的时间复杂度就等于量级最大的那段代码的时间复杂度。**

以下面代码为例

```java
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }

   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }

   return sum_1 + sum_2 + sum_3;
 }
```

这里的时间复杂度可以分为三大块，分别是求 sum_1、sum_2、sum_3，按照前面的思路，可以知道三块代码的时间复杂度分别为 $O(100)$，$O(n)$，$O(n^2)$，由于 $O(n^2)$ 是量级最大的那个，所以我们可以说这段代码的时间复杂度为 $O(n^2)$。

### 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

乘法法则， 我们可以看成是嵌套循环，以下面代码为例：

```java
int cal(int n) {
   int ret = 0; 
   int i = 1;
   for (; i < n; ++i) {
     ret = ret + f(i);
   } 
 } 

int f(int n) {
    int sum = 0;
    int i = 1;
    for (; i < n; ++i) {
        sum = sum + i;
    } 
    return sum;
}
```

我们先看  `cal(...)` 算法，第 5 行代码的时间复杂度为 $O(n)$，函数 `f()` 中第 13 行的时间复杂度也为 $O(n)$，那么总的时间复杂度就是 $T(n) = O(n) * O(n) = O(n^2)$。

## 4. 几种常见的时间复杂度

![&#x51E0;&#x79CD;&#x5E38;&#x89C1;&#x306E;&#x65F6;&#x95F4;&#x590D;&#x6742;&#x5EA6;](https://static001.geekbang.org/resource/image/37/0a/3723793cc5c810e9d5b06bc95325bf0a.jpg)

复杂度量级可以粗略的分为**多项式量级**和**非多项式量级** （NP， Non-Deterministic Polynomial，非确定多项式 ），其中非多项式量级只有两个： $O(2^n)$  和  $O(n!)$ 。

非多项式量级会随着数据规模n的增大而急剧增长，所以 NP 级别的算法性能是非常差的。

接下来主要介绍几种多项式量级的复杂度。

### 4.1 O(1)

大 O 表示法只是呈现执行效率随着数据规模变化的趋势，所以可以知道 $O(1)$ 是指算法执行效率不会随着数据规模 n 的增长而增长。

```java
 int i = 8;
 int j = 6;
 int n = 100;
 int sum = i + j;
```

以上代码时间复杂度就是 $O(1)$，无论 n 多大，执行效率都不会受到影响，一般来说，**只要代码中不存在循环、递归等语句**，我们都可以认为时间复杂度是 $O(1)$ 级别的。

### 4.2 O(logn)、O(nlogn)

对数阶时间复杂度十分常见，但分析起来较难，以下面代码为例：

```java
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

其中 i 每次都会乘以2，也就是说最开始的 i 可以看成 $2^0$，第一次执行则是 $2^1$，第二次为 $2^2$，以此类推，可以得到如下规律：
$$2^0=n$$
$$2^1=n$$
$$2^2=n$$
$$......$$
$$2^k=n$$

这里 k 是最终执行的次数，由此我们可以求得 $log_2^n=k$，所以这段代码的时间复杂度就是 $O(log_{2}n)$。

再看以下代码：

```java
 i=1;
 while (i <= n)  {
   i = i * 3;
 }
```

结合前面的内容，可以轻松知道这段代码的执行次数$x$是$log_3^n=x$，由于对数都是可以相互转化的，所以我们也可以转化为$log_3^2*log_2^n=x$，根据前面大O表示法提到的系数可以忽略，所以我们又可以将其看为$log_2^n=x$。

由上面两个例子可以得知，对数阶时间复杂度不管对数阶的底数是多少，都是可以相互转化的，为了方便表示，一般我们统一使用$O(logn)$来表示。

至于$O(nlogn)$，假如一段代码的时间复杂度是$O(logn)$，然后我们外部又将其循环了n遍，那么根据乘法法则就是$O(nlogn)$了。

### 3. O(m+n)、O(m*n)

有时候代码里会有多个部分的执行效率会受到数据规模的影响，假设数据规模分别为m、n，如下：

```java
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

由于我们无法事先确定m,n的数据规模，此时将其中一个省略掉就不合适了，即加法法则在这里算作是失效，所以将其时间复杂度就是$O(m+n)$。

而乘法法则仍然生效，只不过一个n次的算法又被执行了m次（也可能反过来），表示为$O(m*n)$。

## 5. 空间复杂度分析

时间复杂度的全称是**渐进时间复杂度**，表示**算法的执行时间与数据规模之间的增长关系**。

类比一下，空间复杂度全称就是**渐进空间复杂度（asymptotic space complexity）**，表示算法的存储空间与数据规模之间的增长关系。

常见的空间复杂度有 $O(1)$、$O(n)$、$O(n^2)$，像 $O(logn)$、$O(nlogn)$ 这样的对数阶则较为少见。

## 6. 时间复杂度进阶

在前面讲的时间复杂度的基础上，根据四种场景，还能再将其细分出四种：**最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）**。

### 6.1 最好、最坏时间复杂度

```java
// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) pos = i;
  }
  return pos;
}
```

上面的代码中，我们查找一个数据，最后返回结果的时间复杂度为$O(n)$，但这样的代码不够高效，进一步优化：

```java
// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

这时候再行进行分析会发现，上面这段代码的时间复杂度不一定是 $O(n)$了，假如要查找的元素在数组第一位，那么时间复杂度就是 $O(1)$，若在最后一位，那么时间复杂度则为 $O(n)$，因此这里引申出两个概念：**最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）**。

* 最好情况时间复杂度：**在最理想的情况下，执行一段代码的时间复杂度**。
* 最坏情况时间复杂度：**在最糟糕的情况下，执行一段代码的时间复杂度**。

那么这时候如何确定时间复杂度呢？可以看下接下来介绍的**平均情况时间复杂度（average case time complexity）**。

### 6.2 平均情况时间复杂度

由于最好情况时间复杂以及最坏情况时间复杂度都是在极端情况下发生的，真实场景中很难遇到，但为了能够囊括前面两种情况，因此又引入了**平均情况时间复杂度（average case time complexity）**的概念，后面简称平均时间复杂度。

仍然借助这段代码进行分析：

```java
// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

元素查找的情况分为在数组中（n 种情况）以及不在数组中（1种情况），总共n+1种情况。再根据每种情况需要遍历的次数除以总的情况：

$$
\frac{1+2+3+\cdots+n+n}{n+1}=\frac{n(n+2)}{2(n+1)}
$$

再结合我们前面关于大O表示法中对常量，系数，低阶可以省略的元组，那么平均时间复杂度就是$O(n)$。

上面的计算方式还有点问题，关于元素在不在数组中，我们假设每种情况都为1/2，元素在某个位置上出现的概率就变为了1/2n，可得出下面计算工时：

$$
\begin{aligned} & 1 \times \frac{1}{2 n}+2 \times \frac{1}{2 n}+3 \times \frac{1}{2 n}+\cdots+n \times \frac{1}{2 n}+n \times \frac{1}{2} = \frac{3 n+1}{4} \end{aligned}
$$

这个值就是概率论中的**加权平均值**，也叫作期望值，所以平均时间复杂度的全称应该叫**加权平均时间复杂度**或者**期望时间复杂度**。

可以看到，最后的时间复杂度仍为 $O(n)$，很多时候我们不需要这么具体的分析，只有分析同一段代码在不同场景的时间复杂度的时候才需要这么计算。

### 6.3 均摊时间复杂度

最好、最坏、平均三种复杂度在某些场景才会用到，而**均摊时间复杂度（amortized time complexity）**应用的场景比它们更加特殊、更加有限。

以下面代码为例：

```java
 // array表示一个长度为n的数组
 // 代码中的array.length就等于n
 int[] array = new int[n];
 int count = 0;

 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i < array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }

    array[count] = val;
    ++count;
 }
```

这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 `count == array.length` 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。

最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 $O(1)$。

最坏的情况下，数组中没有空闲空间了，需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 $O(n)$。

平均时间复杂度则为：$1 \times \frac{1}{n+1}+1 \times \frac{1}{n+1}+\dots+1 \times \frac{1}{n+1}+n \times \frac{1}{n+1}=0(1)$。

然而，这样计算下来时很麻烦的，我们其实可以发现，O(n)  的出现其实是很规律的，往往前面会伴随着 n-1 次  $O(1)$  操作，因此我们可以将第 n 次的时间复杂度 $O(n)$ 直接平摊到前面 n-1 次操作中，也就可以直接得出时间复杂度 $O(1)$ 的结论了，这样的方式计算出来的时间复杂度称之为**均摊时间复杂度（amortized time complexity，通过摊还分析得到的时间复杂度）**。

均摊时间复杂也可以看成是一种特殊情况下的平均时间复杂度。

## 总结

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系。其中越是高阶的算法， 执行效率越低，下图列出几个复杂度呈现的大致趋势：

![&#x590D;&#x6742;&#x5EA6;&#x51FD;&#x6570;](https://static001.geekbang.org/resource/image/49/04/497a3f120b7debee07dc0d03984faf04.jpg)

**Q：**有人说，我们项目之前都会进行性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此一举呢？而且，每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？你怎么看待这个问题呢？

**A：**对复杂度作分析，可以让我们对不同算法的执行效率有一个大致的认知，从而为我们对算法效率的判断先行提供了一个科学的理论依据，并且往往低阶的复杂度执行效率是比高阶高的，可以先帮助我们进行筛选一波。

至于实际的性能测试，复杂度分析与其并不冲突，而是相辅相成的，如果说复杂度分析是一个横向对比分析，那么实际的性能测试就是一个纵向的对比，毕竟复杂度分析**只是提供一个大致的性能渐变趋势**，比如 O(logN) 的算法就不一定优于 O(n) ，在数据规模达到一定程度的时候就会出现其他情况。

