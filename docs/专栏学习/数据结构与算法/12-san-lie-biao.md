---
title: 12-san-lie-biao
date: 2020-07-22 14:48:49
permalink: /pages/046d2a/
categories: 
  - Algorithm
  - 数据结构与算法（专栏学习）
tags: 
  - 
---
# 12 | 散列表

**散列表**（Hash Table），是在数组的基础上，通过hash算法取得对象的hash值作为数组下标，将其存储到数组指定位置。当需要再访问对象时，再根据对象的hash值即可借助数组随机访问的特性来快速定位对象位置。

## 1. 散列函数

散列函数，是散列表中的核心，它是一个函数，能够将对讲转化为一个hash值。假设对象的hash值为key，那么可以表示为 `key=hash(obj)` ，伪代码如下：

```vim
int hash(String key) {
  // 获取后两位字符
  string lastTwoChars = key.substr(length-2, length);
  // 将后两位字符转换为整数
  int hashValue = convert lastTwoChas to int-type;
  return hashValue;
}
```

如何设计散列函数对于散列表来说至关重要，散列函数有三点设计要求：

1. 散列函数得到的hash值必须是一个正整数，因为数组的下标只能是0以及正整数。
2. 如果 obj1=obj2，那么 hash\(obj1\)=hash\(obj2\)。
3. 如果 obj1!=obj2，那么 hash\(obj1\)!=hash\(obj2\)。

然而在实际情况中，第三点是做不到的，即使像 [MD5](https://zh.wikipedia.org/wiki/MD5)、[SHA](https://zh.wikipedia.org/wiki/SHA%E5%AE%B6%E6%97%8F)、[CRC](https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%92%B0%E5%86%97%E9%A4%98%E6%A0%A1%E9%A9%97) 等哈希算法，也无法完全做到避免这种**散列冲突**。并且，在数组空间有限的情况下，冲突的概率会更大。

## 2. 散列冲突

散列冲突无法避免，我们通常可以采用两种方法来处理散列冲突：**开放寻址法**（open addressing）和**链表法**（chaining）

### 2.1 开放寻址法

开放寻址法的思想是，当探测到的位置已经存在数据时，则探寻另一个空闲的位置，最简单的探寻方法是**线性探测**（Linear Probing）。

线性探测的做法是，当探测到一个位置已经有数据的时候，则继续往后探测，直到找到一个空间的位置，如下：

![&#x7EBF;&#x6027;&#x63A2;&#x6D4B;](https://static001.geekbang.org/resource/image/5c/d5/5c31a3127cbc00f0c63409bbe1fbd0d5.jpg)

橙色表示已经存储了数据，当hash值探测到的位置已经有元素的时候，则继续往下找。

这种方法虽然简单，但是在更新、删除数据方面会有较多问题，比如当我们查找一个数据的时候，若有散列冲突，线性探测过程中若有一个数据被删除了，那么按照我们原本的查找算法， 遇到空闲的位置就停止不动了，从而导致在后面存在的数据，查找不到。

解决方法是不删除数据，而是将其标记为deleted，在线性查找的时候遇到deleted不停止，而是继续往下探测：

![](https://static001.geekbang.org/resource/image/fe/1d/fe7482ba09670cbe05a9dfe4dd49bd1d.jpg)

线性探测存在的问题，就是在数据空间越来越少的时候，我们需要探测的位置越来越多，最终导致需要遍历整个数组，从O\(1\)的时间复杂度退化到了O\(n\)。

对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，**二次探测**（Quadratic probing）和**双重散列**（Double hashing）。

二次探测，就是在线性探测的基础上进行改造的，若线性探测是hash\(obj\)+0，hash\(obj\)+1，hash\(obj\)+2……那么二次探测就是hash\(obj\)+0，hash\(obj\)+1^2， hash\(obj\)+2^2……也就是在线性探测步长的基础上进行开方。

双重散列，就是使用一组散列函数 hash1\(obj\)，hash2\(obj\)，hash3\(obj\) ，假如第一个散列函数造成了冲突，那么我们再使用第二个散列函数，直到找到空闲位置。

### 2.2 链表法

链表法是一种更加常用的散列冲突解决办法（也是Java中HashMap采用的做法），当发生散列冲突时，在对应的桶或者说是槽上，将冲突的元素组织成一个链表。

![&#x94FE;&#x8868;&#x6CD5;](https://static001.geekbang.org/resource/image/a4/7f/a4b77d593e4cb76acb2b0689294ec17f.jpg)

当我们需要插入的时候，只需要根据散列值访问对应的位置并追加进去即可，所以插入的时间复杂度是O\(1\)。查找 元素的时间复杂度取决于链表的长度 k ，所以当数据分布较均匀的时候，理论上查找的时间复杂度为 n/m ，n为数据个数，m为散列表的桶个数。

## 3. 装载因子

不管采用哪种方法，**当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高**。为了尽可能保证散列表的操作效率，一般情况下，**我们会尽可能保证散列表中有一定比例的空闲槽位**。我们用装载因子（load factor）来表示空位的多少。

装载因子的计算公式是：

> 散列表的装载因子=填入表中的元素个数/散列表的长度

装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。当数据个数与散列表桶个数达到装载因子的时候，通常为了性能，我们会对散列表进行扩容。

## 4. 散列表存在的问题

散列表虽然理论上各个操作都很高效，但在散列冲突严重的时候性能会大大下降，散列攻击就是通过一组精心设计的值，一直产生散列冲突，从而达到让服务器高负荷拒绝服务的目的。

散列表有两点因素直接决定了一个散列表设计的好坏：散列函数和装载因子。

### 4.1 散列函数的设计

一个好的散列函数，能够很大程度上的减少散列碰撞的概率，从而提高散列表的性能，但同时又不能设计的太复杂，若过于复杂导致求散列值的性能下降，也就影响了散列表的性能。

以手机号码为例子，当我们对手机号求散列值的时候，我们往往可以忽略前面几位，因为很多手机号前面几位都是相同的，但到后面几个尾数往往就不尽相同了，以尾数来求散列值相比前面几位能够降低散列碰撞的概率。

再以单词举例，我们可以对字母进行进位相加操作，再对散列表长度进行求余从而得到散列值：

```java
hash("nice")=(("n" - "a") * 26*26*26 + ("i" - "a")*26*26 + ("c" - "a")*26+ ("e"-"a")) / 78978
```

散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等，这些只要了解，不需要全都掌握。

### 4.2 装载因子的大小

装载因子决定了散列表在内存空间与效率上的一个取舍，过大的装载因子会导致散列碰撞概率增大，过小又会导致频繁扩容浪费内存空间。

当装载因子过大时，比如0.8，我们就需要对散列表进行动态扩容，否则会导致散列碰撞严重从而大大降低性能。假如散列表容量扩大一倍，那么负载因子就变成了0.4，但同时也需要进行数据迁移，并且数据位置往往也会发生变化，如下：

![](https://static001.geekbang.org/resource/image/67/43/67d12e07a7d673a9c1d14354ad029443.jpg)

也就是在某次插入时会发生扩容，时间复杂度为 O\(n\) ，但根据均摊算法，插入的操作的平均时间复杂度为 O\(1\) 。

### 4.3 避免低效扩容

按照前面提到的，一旦某个时刻发生了扩容，由于需要进行一个 O\(n\) 的数据迁移操作，那么在那个时间点性能就会大大降低，从而影响使用。这里讨论一些思路可以尽可能优化这些操作。

当发生扩容时，我们申请一个新的数组，但并不立刻将旧数组的数据迁移到新数组，而是在每次有新的数据插入到新数组的时候，也跟着将旧数组的一个数据插入到新数组，这样一来就可以将扩容操作的代价均摊到多次操作中。

至于数据查询的话，可以先到旧数组进行查询，查询不到再到新数组中。

![](https://static001.geekbang.org/resource/image/6d/cb/6d6736f986ec4b75dabc5472965fb9cb.jpg)

## 5. 开放寻址法 VS 链表法

前面提到了两种解决散列冲突的方法：开放寻址法、链表法。

开放寻址法实现简单，而且都是存储在数组中，可以利用CPU缓存，不需要额外的链表空间，指针等，序列化起来也较为简单，但是在进行删除操作的时候较为麻烦，需要特殊的操作，并且由于都存在一个数组中，比起链表法发生冲突的概率更高。因此综合来说，**开放寻址法更适合数据量以及装载因子都比较小的场景**，比如Java中ThreadLocalMap就是采用开放寻址法。

链表法使用了额外的链表空间来存储同个数组位置的元素，因此可以大大减少散列碰撞的概率，对负载因子大小的容忍度更高，但由于使用了链表，对内存空间的消耗也会增多（若存储的对象更大则可以忽略不计），对CPU缓存也是不友好的。所以**链表法更适用于大数据量的场景**。

链表法实际还能再优化，比如Java8中的HashMap，当链表的长度大于8时，会将链表转化为红黑树，从而将查找的时间复杂度降为 O\(logn\) 。

## 6. Java中HashMap分析

Java中的HashMap就是一个典型的工业级数据结构的实现。一个工业级的数据结构，通常要考虑以下几点：

1. **查找、删除、更新等操作的高效。**
2. **对内存空间的合理占用**。
3. **性能稳定，能够应对对各种异常情况**。

### 6.1 初始大小

HashMap 默认的初始大小是 16，这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。

HashMap中有很多操作为了效率都是位运算，所以这也是HashMap中的默认初始容量 16 为 2 的幂次方的原因，并且即使自己手动指定初始容量， HashMap 也会自动将其向上取值到最近的 2 的幂次方。

### 6.2 装载因子和动态扩容

HashMap 的负载因子为 0.75 ，是一种在性能与空间占用折衷的做法。当 HashMap 中元素个数超过 0.75\*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。

### 6.3 散列冲突解决方法

HashMap 底层采用链表法来解决冲突。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。

在 JDK1.8 版本中，为了对 HashMap 做进一步优化，引入了红黑树。当链表长度太长（默认超过 8）时，链表就转换为红黑树。我们可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。

### 6.4 散列函数

HashMap的散列函数设计并不复杂，追求的是简单高效，分布均匀：

```java
int hash(Object key) {
    int h = key.hashCode()；
    return (h ^ (h >>> 16)) & (capicity -1); //capicity表示散列表的大小
}
```

此处的 `(h ^ (h >>> 16)) & (capicity -1)` 是一个位操作，相当于十进制中的求余操作。

其中，hashCode\(\) 返回的是 Java 对象的 hash code。比如 String 类型的对象的 hashCode\(\) 就是下面这样：

```java
public int hashCode() {
  int var1 = this.hash;
  if(var1 == 0 && this.value.length > 0) {
    char[] var2 = this.value;
    for(int var3 = 0; var3 < this.value.length; ++var3) {
      var1 = 31 * var1 + var2[var3];
    }
    this.hash = var1;
  }
  return var1;
}
```

## 7. 散列表＆链表

散列表经常链表一起出现，链表插入、删除操作的时间复杂度为 O\(1\) ，而查找操作的时间复杂度为 O\(n\) ，和散列表一起结合使用的时候，可以借助散列表的特性将查找操作缩短到 O\(1\) ，从而大大提高性能。

之前学习链表的时候，借助链表实现了LRU缓存淘汰算法，一个缓存（cache）系统主要包含下面这几个操作：

* 往缓存中添加一个数据；
* 从缓存中删除一个数据；
* 在缓存中查找一个数据。

如果单纯使用链表来实现的话，每次更新、删除元素的时候都需要经过时间复杂度为 O\(n\) 的查找操作，因此这里可以结合**散列表 + 链表**来提高效率：

![&#x6563;&#x5217;&#x8868;&amp;&#x94FE;&#x8868;](https://static001.geekbang.org/resource/image/ea/6e/eaefd5f4028cc7d4cfbb56b24ce8ae6e.jpg)

在上面的数据结构图中，使用的是双向链表，但在双向链表的双向指针（`prev`、`next`）的基础上，还增加了`hnext`指针，这个 `hnext` 指针是用于散列表中的链表法的，也就是在这个数据结构中有两条链：**双向链表**以及**散列表用来解决散列冲突的链表**。

这样一来，当我们需要查找某个元素的时候，就可以借助散列表快速定位元素，添加、删除元素则利用双向链表的的 O\(1\) 操作，同时由于存在双向链表，我们又可以有序遍历序列（散列表经过散列函数后顺序是打乱的）。

实际上 Java 的 LinkedHashMap 就是这么实现的，其中的 Linked 不仅仅指使用了链表法来解决散列冲突，还指使用了双向链表来保证其有序性以及插入、删除等操作的高效性。

```java
HashMap<Integer, Integer> m = new LinkedHashMap<>();
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);

for (Map.Entry e : m.entrySet()) {
  System.out.println(e.getKey());
}

// output:
3, 1, 5, 2
```

如上代码，输出的结果是按照我们添加元素的顺序输出的，就是利用了双向链表来记录其顺序。除此之外，我们来可以选择根据元素访问时间来输出：

```java
// 10是初始大小，0.75是装载因子，true是表示按照访问时间排序
HashMap<Integer, Integer> m = new LinkedHashMap<>(10, 0.75f, true);
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);

m.put(3, 26);
m.get(5);

for (Map.Entry e : m.entrySet()) {
  System.out.println(e.getKey());
}

// output:
1, 2, 3, 5
```

第二行代码中的 true 代表开启根据访问时间调整元素顺序的位置，该特性会将最近一次有访问操作（如查找、更新、插入等）的元素移动到双向链表队尾，其实这就是一个 LRU缓存淘汰算法 。

## 8. Redis有序集合

在跳表那一节提到了 Redis 的有序集合，一个Redis 有序集合可以细化为以下几个操作：

* 添加一个成员对象；
* 按照键值来删除一个成员对象；
* 按照键值来查找一个成员对象；
* 按照分值区间查找数据，比如查找积分在 \[100, 356\] 之间的成员对象；
* 按照分值从小到大排序成员变量；

实际上，一个有序集合会有两个属性， **key** （键值）和 **socre** （分值）。比如一个用户积分系统，一个用户有着 ID（key） 和 积分（score），假如我们根据积分来组织一个跳表，那么当我们需要根据用户 ID 来操作元素的时候，效率就会很低。

解决思路跟前面一节一样，就是根据用户 ID 来组织一个散列表，这样一来查找、删除元素的操作就为 O\(1\) ，同时借助跳表的操作结构，其他操作也非常高效。

实际上，Redis 有序集合的操作还有另外一类，也就是查找成员对象的排名（Rank）或者根据排名区间查找成员对象。这个功能单纯用刚刚讲的这种组合结构就无法高效实现了。这块内容后面再学习。

## 9. 思考

**Q：在散列表和链表结合使用的例子里，使用的都是双向链表。如果把双向链表改成单链表，还能否正常工作呢？为什么呢？**

> 改为单链表后仍然能够正常工作，只不过当需要删除、移动中间结点的时候，需要重新从头遍历找到目标节点的前驱节点，从而导致操作的时间复杂度变为了 O\(n\) 。

**Q：假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作：**

* 根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息；
* 查找积分在某个区间的猎头 ID 列表；
* 查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表。

> 1. 可以根据猎头 ID 建立散列表，从而可以通过 O\(1\) 时间复杂度定位到猎头操作其信息。
> 2. 根据猎头积分简历跳表，跳表更适合于区间查找。
> 3. 当前还无法实现。

