---
title: NUMA 架构
date: 2021-02-19
---



NUMA （[Non-uniform memory access](https://en.wikipedia.org/wiki/Non-uniform_memory_access)，非一致性内存访问）架构是近代计算机常见的一种架构，主要是随着 CPU 近年来性能提升速度的逐渐放缓，开始出现通过多个 CPU 共同工作来提升性能的方案。

## 1. 硬件角度

从硬件角度来看，如果按照以前的计算机架构，多个 CPU 之间访问同一块内存，会共用一个 bus：

![img](https://i2.wp.com/jcole.us/blog/files/uma-architecture.png)

但是这样一来，bus 就很可能出现性能瓶颈，导致整体性能的降低，因此就出现了 NUMA 架构：

![img](https://i2.wp.com/jcole.us/blog/files/numa-architecture.png)

每个 CPU 都拥有自己的一块 “本地” 内存，其他 CPU 的内存则可以看做是 “远程” 内存。这种架构下，CPU 访问自己的本地内存会有更低的延迟以及更高的性能表现。

## 2. Linux 角度

从 Linux 角度来看，基于这种硬件结构，一个 CPU 会被抽象成一个 NUMA Node， 并且尽可能将 CPU 所需要的内存分配在它的本地内存中。

但是在一个 NUMA Node 的内存即将耗尽的时候，Linux 采取的默认策略是 **swap/淘汰** 内存页，这样对于大内存应用（比如一个应用内存大于一个 NUMA Node 的所有内存）来说，一旦某个后续需要用到那部分内存页，就会出现明显的性能下降。

## 3. 解决方案

目前有几个比较主流的方法如下：

- 使用 `numactl --interleave=all` 指定程序运行时随机分配在多个 NUMA Node 上。
- 设置 `vm.zone_reclaim_mode=0`，当本地内存不够时优先去远程内存分配。
- 使用 numad 自动管理 NUMA 内存分配。

`numactl --interleave=all` 咋看之下好像失去了 NUMA 的优势，但是大部分情况下，一个应用可以分为稳定的线程（系统线程）以及经常变化的线程（用户创建的线程），对于稳定的线程来说，固定在一个 NUMA Node 下可以获得最好的性能，而对于随机分配在不同 CPU 下的用户线程来说，随机分配反而可以产生奇效，借用网上的一个性能测试结果：

![img](https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/20210220163016.png)

从上面的图可以看出，绝大部分场景下的性能表现，NUMA 默认 < 手动绑定 Numa Node < interleave 方式。因此，绝大部分场景下，NUMA 的性能瓶颈不在于远程内存访问，而是在于 NUMA 导致的内存页 swap/淘汰。

numad，是属于提供 NUMA 自动内存管理的守护线程，[官方](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/performance_tuning_guide/index#sect-Red_Hat_Enterprise_Linux-Performance_Tuning_Guide-Performance_Monitoring_Tools-numad)介绍如下：

> numad is an automatic NUMA affinity management daemon. It monitors NUMA topology and resource usage within a system in order to dynamically improve NUMA resource allocation and management (and therefore system performance). Depending on system workload, numad can provide up to 50 percent improvements in performance benchmarks. It also provides a pre-placement advice service that can be queried by various job management systems to provide assistance with the initial binding of CPU and memory resources for their processes.

numad 会周期性地地监控 NUMA 的资源使用情况，必要的时候会在 NUMA Node 之间移动进程以求达到最佳性能效果。

numad 主要的受益对象有：

- 消耗大量系统资源且长时间运行的进程
- 同时消耗多个 NUMA Node 资源的进程。

对于那些只运行数分钟，或者只消耗少量资源的进程，numad 并不能带来性能上的提升，此外，那些具有连续性、不可预测的内存访问的系统，比如大内存的数据，也无法从 numad 获得提升。

对于 numad 的使用，可以参照[官方文档](https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-tool_reference-numad)。

## 4. 实际效果

目前有看到比较好的测试案例：https://indico.cern.ch/event/304944/contributions/1672535/attachments/578723/796898/numa.pdf 。

自身实际测试中，运行一个 Spark 流式作业，使用 `-XX:+UseParallelGC -XX:+UseNUMA`，可以观察到开启了 numad 的节点，对比其他节点，GC 时间明显少了 15%，且任务耗费时间在两百多个节点中，也是明显更加优秀：

![image-20210220172233373](https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/20210220172233.png)



参考：

- [NUMA架构的CPU -- 你真的用好了么？](http://cenalulu.github.io/linux/numa/)
- [The MySQL “swap insanity” problem and the effects of the NUMA architecture](https://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/)