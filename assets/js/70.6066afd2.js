(window.webpackJsonp=window.webpackJsonp||[]).push([[70],{792:function(a,t,s){"use strict";s.r(t);var e=s(70),r=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h2",{attrs:{id:"_1-spark-rdd-与-spark-sql"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-spark-rdd-与-spark-sql"}},[a._v("#")]),a._v(" 1. Spark RDD 与 Spark SQL")]),a._v(" "),s("p",[a._v("Spark 3.0 中对 Spark SQL 进行了大量的优化更新：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/47/75/479cd67e687a3a7cdc805b55b5bdef75.jpg",alt:""}})]),a._v(" "),s("p",[a._v("Spark SQL 取代了 Spark Core，成为了新一代的引擎，其他组件都能从中获的收益。")]),a._v(" "),s("p",[a._v("Spark RDD 主要存在以下痛点：")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("优化空间有限")]),a._v("，对于 Spark 来说，它可以感知到我们做了 map、filter 等操作，但我们执行的函数操作，对于 Spark 来说是一个黑盒，只能简单的将其分发到各个 Executor 执行")]),a._v(" "),s("li",[s("strong",[a._v("数据元信息过少")]),a._v("，Spark 对 RDD 形式的数据集能感知的信息很少，并且 RDD 能存储各种半结构、非结构化的数据，Spark 无法对其进行优化")])]),a._v(" "),s("p",[a._v("Spark SQL 中的 DataFrame 中所携带的 Schema 可以让 Spark 根据明确的字段类型设计定制化的数据结构（"),s("strong",[a._v("Tungsten")]),a._v("），从而大幅提升数据的存储和访问效率，同时也可以让 Spark  基于启发式的规则和策略（"),s("strong",[a._v("Catalyst")]),a._v("），甚至是动态的运行时信息（"),s("strong",[a._v("AQE")]),a._v("）去优化 DataFrame 的计算过程。")]),a._v(" "),s("p",[a._v("Spark Core 能够提供很灵活的操作，但也正因此 Spark 也无法获取关于数据太多的数据，也就无法针对性的做出优化。")]),a._v(" "),s("h2",{attrs:{id:"_2-spark-sql-核心组件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-spark-sql-核心组件"}},[a._v("#")]),a._v(" 2. Spark SQL 核心组件")]),a._v(" "),s("h3",{attrs:{id:"_2-1-catalyst"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-catalyst"}},[a._v("#")]),a._v(" 2.1 Catalyst")]),a._v(" "),s("p",[a._v("Spark 会基于 DataFrame 确切的计算逻辑，使用第三方的 SQL 解析器 ANTLR 来生成抽象语法树（AST，Abstract Syntax Tree），节点记录的是"),s("strong",[a._v("标量算子（如 select、filter）的处理逻辑")]),a._v("，边携带的是数据信息："),s("strong",[a._v("关系表和数据列")]),a._v("。")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/1c/6f/1c0a5e8c1ccdc5eb6ecc29cc45d3f96f.jpg",alt:""}})]),a._v(" "),s("p",[a._v("Spark 中的语法树也称为 "),s("code",[a._v("Unresolved Logical Plan")]),a._v("，是 Catalyst 优化的起点，这个阶段中记录的信息仅仅是一些字符串，这些数据来与 Dataframe 中的 DSL 语句，还未跟实际的数据格式对应起来。")]),a._v(" "),s("p",[a._v("Catalyst 分两步走：")]),a._v(" "),s("p",[s("strong",[a._v("逻辑计划部分")]),a._v("：")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("逻辑计划解析")]),a._v("：结合 DataFrame 中的 Schema 信息，确认计划中的表名、字段名、字段类型是否与实际一致，经过这个步骤转换后，"),s("code",[a._v("Unresolved Logical Plan")]),a._v(" 会转为 "),s("code",[a._v("Analyzed Logical Plan")]),a._v("。")]),a._v(" "),s("li",[s("strong",[a._v("逻辑计划优化")]),a._v("，基于解析过后的 "),s("code",[a._v("Analyzed Logical Plan")]),a._v("，Catalyst 会利用"),s("strong",[a._v("启发式的规则")]),a._v("和"),s("strong",[a._v("执行策略")]),a._v("，最终把逻辑计划转换为优化后的逻辑计划  "),s("code",[a._v("Optimized Logical Plan")]),a._v("。")])]),a._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" Parsed Logical Plan "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("\nRelation"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("age#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7L")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("name#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" json\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" Analyzed Logical Plan "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("\nage"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" bigint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" string\nRelation"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("age#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7L")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("name#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" json\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" Optimized Logical Plan "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("\nRelation"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("age#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7L")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("name#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" json\n\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" Physical Plan "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("\nFileScan json "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("age#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7L")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("name#"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" Batched"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" DataFilters"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" Format"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" JSON"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" Location"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" InMemoryFileIndex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("file"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("usr"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("local"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("spark"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.1")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v(".1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v("bin"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v("hadoop3"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("examples"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("main"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("resources"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v("peopl"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" PartitionFilters"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" PushedFilters"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" ReadSchema"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" struct"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("age"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v("bigint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v("string"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br"),s("span",{staticClass:"line-number"},[a._v("7")]),s("br"),s("span",{staticClass:"line-number"},[a._v("8")]),s("br"),s("span",{staticClass:"line-number"},[a._v("9")]),s("br"),s("span",{staticClass:"line-number"},[a._v("10")]),s("br"),s("span",{staticClass:"line-number"},[a._v("11")]),s("br"),s("span",{staticClass:"line-number"},[a._v("12")]),s("br")])]),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/f3/72/f3ffb5fc43ae3c9bca44c1f4f8b7e872.jpg",alt:""}})]),a._v(" "),s("p",[s("strong",[a._v("物理计划部分")]),a._v("：")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("优化 Spark Plan")]),a._v("：在优化 Spark Plan 的过程中，Catalyst "),s("strong",[a._v("基于既定的优化策略")]),a._v("（Strategies），把逻辑计划中的关系操作符一一映射成物理操作符，生成 Spark Plan。")]),a._v(" "),s("li",[s("strong",[a._v("生成 Physical Plan")]),a._v("：在生成 Physical Plan 过程中，Catalyst 再"),s("strong",[a._v("基于事先定义的 Preparation Rules")]),a._v("，对 Spark Plan 做进一步的完善、生成可执行的 Physical Plan。")])]),a._v(" "),s("p",[a._v("可以看出，Catalyst 的优化操作来源于 Dataframe 的开发方式。")]),a._v(" "),s("p",[a._v("对于同样一种计算逻辑，实现方式可以有多种，按照不同的顺序对算子做排列组合，我们就可以演化出不同的实现方式。最好的方式是，我们遵循“能省则省、能拖则拖”的开发原则，去选择所有实现方式中最优的那个。")]),a._v(" "),s("h4",{attrs:{id:"_2-1-1-逻辑计划"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-1-逻辑计划"}},[a._v("#")]),a._v(" 2.1.1 逻辑计划")]),a._v(" "),s("p",[a._v("Catalyst 在 Spark 3.0 版本中，共有 81 条优化规则（Rules），分为 27 组（Batches），不考虑规则的重复性，27 组共有 129 个优化规则，但主要可以分为三大类：")]),a._v(" "),s("ul",[s("li",[s("strong",[a._v("谓词下推")]),a._v("，结合列式存储格式的文件注脚（Footer）中的统计信息，能够大幅度减少扫描数据量，降低 I/O 开销\n"),s("ul",[s("li",[a._v("将过滤规则提前到接近数据源的地方，从源头减少扫描量")]),a._v(" "),s("li",[a._v("对一些谓词做优化，如 "),s("code",[a._v("in")]),a._v(" 替换为 "),s("code",[a._v("=")]),a._v("，多个谓词进行合并等。")])])]),a._v(" "),s("li",[s("strong",[a._v("动态裁剪")]),a._v("，扫描数据源的时候，只读取与查询相关的字段，节省 I/O 开销")]),a._v(" "),s("li",[s("strong",[a._v("常量替换")]),a._v("，将查询条件中的一些计算替换为常量")])]),a._v(" "),s("p",[a._v("Catalyst 除了会基于优化规则进行优化外，还会借助 Cache Manager 中记录的信息减少计算成本。")]),a._v(" "),s("p",[a._v("Cache Manager 维护了一个 Mapping 映射字段，字典的 Key 值是逻辑计划，Value 是对应的 Cache 元信息。")]),a._v(" "),s("p",[a._v("Catalyst 在对逻辑计划进行优化前，会先从 Cache Manager 中查找当前的逻辑计划或者分支是否存在已被记录，如果可以获取到相应信息，则会采用 "),s("strong",[a._v("InMemoryRelation")]),a._v(" 节点替换整个计划或者计划的一部分，充分利用缓存。")]),a._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" Physical Plan "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v("\nCollectLimit "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" Project "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n   "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" InMemoryTableScan "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" InMemoryRelation "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n               "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" Scan json  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br")])]),s("p",[a._v("Catalyst 逻辑计划优化的类主要是借助 "),s("strong",[a._v("QueryPlan")]),a._v(" 以及 "),s("strong",[a._v("TreeNode")]),a._v(" 实现的，其中 QueryPlan 是 TreeNode 的子类，TreeNode 中有一个叫做 "),s("strong",[a._v("children")]),a._v(" 的字段，类型为 "),s("strong",[a._v("Seq[TreeNode]")]),a._v("，从而构成了一个树结构，接着借助 "),s("strong",[a._v("transformDown")]),a._v(" 递归函数不断将各个优化规则作用（Apply）于当前节点，之后再作用到 children 中的子节点，直到整棵树的叶子节点。")]),a._v(" "),s("p",[a._v("从 Analyzed Logical Plan 到 Optimized Logical Plan 的转化，其实就是从一个 TreeNode 生成另一个 TreeNode 的过程，不断将各组优化规则作用到整棵树，且结构不再变化为止。")]),a._v(" "),s("p",[a._v("以 "),s("code",[a._v("org.apache.spark.sql.catalyst.expressions.Expression")]),a._v(" 为例：")]),a._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("//Expression的转换")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[a._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("sql"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("catalyst"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("expressions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("_\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" myExpr"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" Expression "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" Multiply"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("Subtract"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" Subtract"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("val")]),a._v(" transformed"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" Expression "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" myExpr transformDown "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("case")]),a._v(" BinaryOperator"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" r"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("=>")]),a._v(" Add"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" r"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("case")]),a._v(" IntegerLiteral"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("=>")]),a._v(" Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("case")]),a._v(" IntegerLiteral"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("=>")]),a._v(" Literal"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br"),s("span",{staticClass:"line-number"},[a._v("7")]),s("br"),s("span",{staticClass:"line-number"},[a._v("8")]),s("br")])]),s("p",[a._v("最后将 （（6 - 4）*（1 - 9）） 通过自定义规则转化为了 （（1 + 0）+（0 + 1））。")]),a._v(" "),s("h4",{attrs:{id:"_2-1-2-物理计划"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-2-物理计划"}},[a._v("#")]),a._v(" 2.1.2 物理计划")]),a._v(" "),s("p",[a._v("在逻辑计划优化完成后，物理计划阶段会以优化后的逻辑计划为起点开始生成。")]),a._v(" "),s("p",[a._v("首先在优化 Spark Plan 过程中，Catalyst 共有 14 类优化策略：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/51/56/51ca111dfb9ebd60e2443c86e9b0cb56.jpeg",alt:""}})]),a._v(" "),s("p",[a._v("同逻辑计划优化类似，优化 Spark Plan 阶段也是基于"),s("strong",[a._v("偏函数")]),a._v("模式，把逻辑计划中的操作符映射为 Spark Plan 中的物理算子，例如 BasicOperators 策略直接把 Project、Filter、Sort 等逻辑操作符平行地映射为物理操作符。BasicOperators 中包含了一个 Expression CodeGen 优化，各个具体实现类都实现了 "),s("code",[a._v("org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate")]),a._v(" 特质，在出现 WSCG 后，只会生成部分代码，与其他代码组成 WSCG。")]),a._v(" "),s("p",[a._v("优化后的逻辑计划，还并未选择具体的 Join 策略，此处以场景使用最广泛，对执行性能影响大最大的 "),s("strong",[a._v("JoinSelection")]),a._v(" 为例，Catalyst 共有以下几种 Join 策略：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/39/fb/39642808b292abb0b5b37ea69bfb19fb.jpeg",alt:""}})]),a._v(" "),s("p",[a._v("本质上就是来自 2 种数据分发方式（Boradcast 和 Shuffle）与 3 种 Join 机制实现的组合：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/e9/48/e9bf1720ac13289a9e49e0f33a334548.jpg",alt:""}})]),a._v(" "),s("p",[a._v("Catalyst 会按照性能从高到低依次选择出符合场景的策略，通过两大类条件做决策：")]),a._v(" "),s("ol",[s("li",[a._v("条件性信息：\n"),s("ul",[s("li",[a._v("按照 Join 类型（是否等值、连接形式等），来源于查询语句自身")]),a._v(" "),s("li",[a._v("内表尺寸，可以来自于 Hive 的 ANALYZE YZE TABLE 语句、Spark 对于 Parquet、ORC 等文件尺寸的预估，甚至是 AQE 的动态统计信息")])])]),a._v(" "),s("li",[a._v("指令型信息，也就是 Join Hints")])]),a._v(" "),s("p",[a._v("在这之后，Spark Plan 就可以决定使用哪种 Join 策略了，接着 Catalyst 需要对 Spark Plan 作进一步转换为 Physical Plan：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/53/fd/534dd788609386c14d9e977866301dfd.jpg",alt:""}})]),a._v(" "),s("p",[a._v("Spark Plan 转化为 Physical Plan 需要经过几组 Preparation Rules 的规则，对 Spark Plan 进行细节的补充，这几组规则如下：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/18/f7/187a85d53d585c5b3656353e3304fdf7.jpeg",alt:""}})]),a._v(" "),s("p",[a._v("以 EnsureRequirements 为例，该规则会对执行计划中的每一个操作节点，使用 4 个属性描述数据输入和数据输出的分布状态：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/f8/yf/f8cae1364372a2a8c034a5ab00850yyf.jpeg",alt:""}})]),a._v(" "),s("p",[a._v("该规则要求子节点的输出数据要满足父节点的输入要求，假设父节点为 SortMergeJoin：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/05/00/05467eecb3c983d4fc4a3db8a0e7e600.jpg",alt:""}})]),a._v(" "),s("p",[a._v("此时 Project 节点的输出数据，并没有满足 SortMergeJoin 的要求（数据按照 partition 分区及排序），因此 EnsureRequirements 会介入添加必要的操作符，以满足父节点对子节点数据的要求：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/a8/15/a8c45d1d6ecb6a120205252e21b1b715.jpg",alt:""}})]),a._v(" "),s("p",[a._v("其中 Exchange 表示 Shuffle 操作，Sort 表示排序，满足了 SortMergeJoin 的要求。")]),a._v(" "),s("p",[a._v("之后 Spark 通过调用 Physical Plan 的 doExecute 方法，把结构化查询的计算结果，转换成 "),s("strong",[a._v("RDD[InternalRow]")]),a._v("（InternalRow 为 Tungsten 定制化的二进制数据结构）。")]),a._v(" "),s("p",[a._v("以下图的 Physical Plan 为例：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/65/33/656e29b2d25549488087fc1a4af8cd33.png",alt:""}})]),a._v(" "),s("p",[a._v("可以看到物理计划添加了 Exchange、Sort 节点，Join 策略为 SortMergeJoin，* 表示 Tungsten 的 WSCG，括号里的数字表示 Stage 编号，括号中相同数字的操作，都会被捏合成一份 “手写代码”，由 Tungsten 的 WSCG 完成。")]),a._v(" "),s("h3",{attrs:{id:"_2-2-tungsten"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-tungsten"}},[a._v("#")]),a._v(" 2.2 Tungsten")]),a._v(" "),s("p",[a._v("在 Catalyst 生成物理计划后，还会交给 Tungsten 继续进行优化，Tungsten 主要从数据存储以及全阶段代码生成两个方面进行优化。")]),a._v(" "),s("h4",{attrs:{id:"_2-2-1-数据存储"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-1-数据存储"}},[a._v("#")]),a._v(" 2.2.1 数据存储")]),a._v(" "),s("p",[a._v("Tungsten 在数据存储方面，有两个较大的改进，分别是"),s("strong",[a._v("紧凑的数据格式 Unsafe Row")]),a._v(" 以及"),s("strong",[a._v("内存页管理")]),a._v("。")]),a._v(" "),s("p",[a._v("Tungsten 自定义了 Unsafe Row 数据格式，可以以十分高效的方式存储二进制数据，对比 Java 的数据结构实现，"),s("strong",[a._v("可以节省大量的内存空间以及对象数量")]),a._v("，大大提高了存储效率以及 GC 效率。")]),a._v(" "),s("p",[a._v("Tungsten 依赖于 DataFrame 携带的 Schema 信息，根据 offset 以及 length，高效存储数据：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/20/02/20230c764200cfde05dedec1cae6b702.jpg",alt:""}})]),a._v(" "),s("ul",[s("li",[a._v("对于定长的字段，直接安插到字节数组中")]),a._v(" "),s("li",[a._v("对于变长的字段，则会先在 Schema 的相应位置插入偏移地址，再把字段长度以及字段值存储到字节数组后面")])]),a._v(" "),s("p",[a._v("也就是说，Tungsten 需要知道每一个字段的数据类型及长度，才能做出高效率的存储。")]),a._v(" "),s("blockquote",[s("p",[a._v("NOTE：对于复杂类型，Tungsten 则很难入手优化，这也是 Spark SQL 对比 Spark RDD 高效的原因之一。")])]),a._v(" "),s("p",[a._v("对比原来 JVM 存储多个字段值使用 GenericMutableRow 封装一条数据，Array 存储实际的值的方式，JVM 采取的方式主要存在两个问题：")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("存储开销大")]),a._v("，Java 对象存储字段值，往往会有一定的膨胀，如对象头、指针、哈希码等信息。")]),a._v(" "),s("li",[s("strong",[a._v("对象数量多")]),a._v("，为了存储字段值，需要多个对象进行辅助，而 Tungsten 则可以一个字节数组存储多个字段值。")])]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/fd/69/fd00cf1364c800659a7d492cd25c6569.jpg",alt:""}})]),a._v(" "),s("p",[a._v("由此看来，"),s("strong",[a._v("Tungsten 字节数组的存储方式在消除存储开销的同时，仅用一个数组对象就能轻松完成一条数据的封装，显著降低 GC 压力")]),a._v("。")]),a._v(" "),s("p",[a._v("Tungsten 还采用"),s("strong",[a._v("基于内存页的内存管理来定位数据")]),a._v("，对比起传统的 Java 标准库 HashMap 来看，降低了存储开销和 GC 负担，同时还能提高 CPU 命中率和访问效率。")]),a._v(" "),s("p",[a._v("为了统一管理 Off Heap 和 On Heap 内存空间，Tungsten 定义了统一的 128 位内存地址，简称 Tungsten 地址。Tungsten 地址分为两部分：前 64 位预留给 Java Object，后 64 位是偏移地址 Offset，并且 Off Heap 和 On Heap 的寻址方式也不同。")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/90/47/904dc1d1846dddffe363e834ce892347.jpg",alt:""}})]),a._v(" "),s("ul",[s("li",[a._v("Off Heap：Spark 通过 Java Unsafe API 直接管理操作系统内存，不存在 Java Object 的概念，因此前 64 位为 null，后 64 位则用于在堆外空间中直接寻址操作系统的内存空间，直接定位数据。")]),a._v(" "),s("li",[a._v("On Heap：Spark 借助一个叫"),s("strong",[a._v("页表（Page Table）"),s("strong",[a._v("的")]),a._v("数组结构")]),a._v("来定位数据，页表记录了一个又一个内存页（Memory Page），内存页的前 64 位记录了 Object 在 JVM 中的地址，后 64 位记录了数据在 Object 中的偏移量。Spark 定位数据的过程如下：\n"),s("ol",[s("li",[a._v("通过页表获取 Object 所在位置")]),a._v(" "),s("li",[a._v("通过页表获取数据在该 Object 里的偏移量")])])])]),a._v(" "),s("p",[a._v("页表管理的方式使用 Java 中的 HashMap 也可以实现，但存在两个问题：")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("存储开销和 GC 负担大")]),a._v("，HashMap 中存储真正数据的对象可能只有一半，其余皆为指针、长度等信息。")]),a._v(" "),s("li",[s("strong",[a._v("CPU 缓存命中率低")]),a._v("，HashMap 是以数组 + 链表的方式实现的，链表可以利用零散的内存区域，提升内存利用效率，但在进行扫描的时候，这种零散的存储方式会引入大量的随机内存访问，降低 CPU 缓存命中率。")])]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/1b/84/1bc7f9553dfe7yyb51a641f51093c284.jpg",alt:""}})]),a._v(" "),s("p",[a._v("因此 Tungsten 采用数组 + 内存页的方式实现了 HashMap 对应的功能，内存页存储的则是 Object 引用以及数据偏移量，并且数组存储内存页的方式还可以充分利用 CPU 缓存，提高命中率。")]),a._v(" "),s("h4",{attrs:{id:"_2-2-2-页表实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-2-页表实现"}},[a._v("#")]),a._v(" 2.2.2 页表实现")]),a._v(" "),s("p",[a._v("Tungsten 管理自定义存储结构的实现在 TaskMemoryManager 中，该类使用了页表的思想对内存块进行了统一管理：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://gitee.com/zhxuankun/Image/raw/5aa6cb7f4ef089ce18aae7493031dc2e34d10452/blog/image-20210508142411733.png",alt:""}})]),a._v(" "),s("p",[a._v("实际存储数据的是一个内存页数组 "),s("code",[a._v("pageTable")]),a._v("，其类型为 "),s("code",[a._v("MemoryBlock[]")]),a._v("，一个内存页 "),s("code",[a._v("MemoryBlock")]),a._v(" 可以存储多条数据。")]),a._v(" "),s("p",[a._v("外部需要寻址时需要提供一个 64 bit 的地址，其高 13 bit 用于定位内存页数组下标，低 51 bit 为数据在内存块中的 offset。")]),a._v(" "),s("p",[a._v("BytesToByteMap 就是使用了页表的一个例子，key 是哈希码, value 为一个用于寻址的 64 bit 地址，该 map 使用了数组结构，同时又能做 Hash 寻址，遇到冲突时采用"),s("strong",[a._v("开放定址法")]),a._v("解决。")]),a._v(" "),s("p",[a._v("通过 Hash 取得内存页地址后，交给 TaskMemoryManager 就能获取到对应内存页。")]),a._v(" "),s("h4",{attrs:{id:"_2-2-3-wscg"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-3-wscg"}},[a._v("#")]),a._v(" 2.2.3 WSCG")]),a._v(" "),s("p",[s("strong",[a._v("全阶段代码生成（WSCG，Whole Stage Code Generation），指的是基于同一 Stage 内操作符之间的调用关系，生成一份“手写代码”，真正把所有计算融合为一个统一的函数")]),a._v("。")]),a._v(" "),s("p",[a._v("相比 DAGScheduler 对同一 Stage 内函数的合并，DAGScheduler 只是简单地对函数进行了嵌套调用，但这样一来会"),s("strong",[a._v("涉及多次虚函数调用以及内存的随机访问")]),a._v("，降低 CPU 的缓存命中率：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/03/03/03052d8fc98dcf1740ec4a7c29234403.jpg",alt:""}})]),a._v(" "),s("p",[a._v("在有 WSCG 之前，Spark 只能使用**火山迭代模型（Volcano Iteration Model，简称 VI）**融合函数，VI 模型依托于 AST 语法树，对所有计算统一进行了封装，所有操作符都需要实现 VI 模型的迭代器抽象（如 hasNext、next 方法），之后只要任何一个算子实现了该抽象，即可加入到语法树种参与计算，灵活组合。")]),a._v(" "),s("p",[a._v("VI 模型中，语法树每个操作符都需要完成如下步骤：")]),a._v(" "),s("ol",[s("li",[a._v("从内存中读取父操作符的输出结果作为输入数据")]),a._v(" "),s("li",[a._v("调用 hasNext、next 方法，以操作符逻辑处理数据，如过滤、投影、聚合等等")]),a._v(" "),s("li",[a._v("将处理后的结果以统一的标准形式输出到内存，供下游算子消费")])]),a._v(" "),s("p",[a._v("任意两个操作符之间的交互都会涉及第 1、 2 点，即内存的随机存取和虚函数调用，导致 CPU 利用率低下。")]),a._v(" "),s("p",[a._v("WSCG 正是为了消除函数嵌套调用存在的，通过生成手写代码的方式完成：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/53/e7/5389b8bd80748dcc706b1c3c95ddbce7.jpg",alt:""}})]),a._v(" "),s("p",[a._v("计算逻辑会一次性的应用到数据上，每条指令也是明确的，可以顺序加载到 CPU 寄存器上。")]),a._v(" "),s("p",[a._v("Catalyst 生成 Physical Plan 之前，有一条 Preparation Rules，其中一条 "),s("strong",[a._v("CollapseCodegenStages")]),a._v(" 就是将其交给 Tungsten 生成手写代码，分为两个步骤：")]),a._v(" "),s("ol",[s("li",[s("strong",[a._v("从父节点到子节点，递归调用 doProduce，生成代码框架")])]),a._v(" "),s("li",[s("strong",[a._v("从子节点到父节点，递归调用 doConsume，向框架填充每一个操作符的运算逻辑")])])]),a._v(" "),s("p",[s("img",{attrs:{src:"https://static001.geekbang.org/resource/image/68/2d/68cfc6aec121511303ccec179bd4a32d.jpg",alt:""}})]),a._v(" "),s("p",[a._v("Tungsten 在 Stage 顶端节点添加 "),s("strong",[a._v("WholeStageCodeGen")]),a._v(" 节点，WholeStageCodeGen 节点调用 doExecute 触发代码生成过程：")]),a._v(" "),s("ol",[s("li",[a._v("doExecute 递归调用子节点的 doProduce 函数，直到遇到 Stage 边界，并生成手写代码的框架（图中蓝色代码部分）")]),a._v(" "),s("li",[a._v("接下来 doProduce 函数会反向递归调用 doConsume 函数，将关系表达式转化为 Java 代码")])]),a._v(" "),s("p",[a._v("Tungsten 利用 CollapseCodegenStages 规则，通过两层递归调用，把 Spark Plan 加工成了一份 “手写代码”，并将其交付给 DAGScheduler 执行。")]),a._v(" "),s("p",[a._v("WSCG 解决了两个核心痛点：")]),a._v(" "),s("ol",[s("li",[a._v("操作符之间频繁的虚函数调用")]),a._v(" "),s("li",[a._v("操作符之间数据交换引入的内存随机访问")])]),a._v(" "),s("h2",{attrs:{id:"_3-总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-总结"}},[a._v("#")]),a._v(" 3. 总结")]),a._v(" "),s("p",[a._v("Spark SQL  能够基于 DataFrame 简单的标量算子和明确的 Schema 定义，借助 Catalyst 优化器和 Tungsten，有能力在运行时构建起一套端到端的优化机制。这套机制运用启发式的规则与策略，以及运行时的执行信息，将原本次优、甚至是低效的查询计划转换为高效的执行计划，再从字节码层面生成代码，消除函数与函数之间的开销，从而提升端到端的执行性能。")]),a._v(" "),s("p",[a._v("https://www.waitingforcode.com/apache-spark-sql/why-code-generation-apache-spark-sql/read")])])}),[],!1,null,null,null);t.default=r.exports}}]);