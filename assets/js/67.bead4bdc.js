(window.webpackJsonp=window.webpackJsonp||[]).push([[67],{789:function(e,t,a){"use strict";a.r(t);var r=a(70),l=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"shuffle"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle"}},[e._v("#")]),e._v(" Shuffle")]),e._v(" "),a("p",[e._v("Spark 2.0 版本之后，Spark 将 Shuffle 操作统一交由 Sort Shuffle Manager 来管理。")]),e._v(" "),a("p",[e._v("Shuffle 的发生与否"),a("strong",[e._v("并不取决于特定算子，而是根据 RDD 的依赖模型来决定的，通过判断子 RDD 与父 RDD 的 partitoner 获取依赖模型")]),e._v("。")]),e._v(" "),a("blockquote",[a("p",[e._v("NOTE：比如 groupByKey 通常会引入 Shuffle ，但在存储的时候根据特定 key 进行 bucket 存储，后续读取该数据并以该 key 做 groupByKey 操作时，是不会发生 Shuffle 的。")])]),e._v(" "),a("p",[e._v("Shuffle 本质上就是 MapReduce：")]),e._v(" "),a("ul",[a("li",[e._v("Map 阶段也可以称为 Shuffle Write，主要是将需要 Shuffle 的数据进行落盘，生成两类文件，后缀为 data 的数据文件存储待分发的数据，后缀为 index 的索引文件记录 data 文件中不同分区的偏移量。")]),e._v(" "),a("li",[e._v("Reduce 阶段称为 Shuffle Read，主要是从指定节点上拉取所需数据。")])]),e._v(" "),a("p",[e._v("Shuffle 需要使用大量的硬件资源，包括 CPU、内存、网络、磁盘等，由于不同磁盘的速度远远低于 CPU、内存等其它设备，同时会截断 Stage，因此 Shuffle 的性能是相当差的。")]),e._v(" "),a("p",[e._v("Shuffle Write 阶段，每个 task 的执行流程都是一样的，因此，总共有多少个 task 就会生成多少个最终的中间文件。")]),e._v(" "),a("p",[e._v("Shuffle 时会将需要落盘的数据先写到一个数据结构中暂存，该数据结构的存储容量有限，一旦快满的时候就会将数据进行落盘，并重复"),a("strong",[e._v("排序（非必要）、溢出")]),e._v("直到所有数据落盘，最后通过归并排序（external sorter）对所有临时文件进行合并。")]),e._v(" "),a("blockquote",[a("p",[e._v("NOTE：如果需要排序且为指定排序昂是，那么 Spark 会至少按照 partition 来排序。")])]),e._v(" "),a("p",[e._v("不同的 Shuffle Write 所使用到的中间数据结构也不一样：")]),e._v(" "),a("ul",[a("li",[e._v("如果不需要在 Shuffle Write 阶段进行预聚合，则会使用一个 "),a("strong",[e._v("PartitionedPairBuffer")]),e._v(" 的数据结构：\n"),a("ul",[a("li",[e._v("PartitionedPairBuffer 是一个数组形式的缓存结构")]),e._v(" "),a("li",[e._v("存储的每条数据记录占用数组中相邻的两个元素空间，第一个元素是**（目标分区，Key）**，第二个元素是 Value")])])]),e._v(" "),a("li",[e._v("如果需要在 Shuffle Write 阶段进行预聚合，则会使用一个 "),a("strong",[e._v("PartitionedAppendOnlyMap")]),e._v(" 的数据结构：\n"),a("ul",[a("li",[e._v("PartitionedAppendOnlyMap 是一个 Map，Value 值可累加、更新")]),e._v(" "),a("li",[e._v("PartitionedAppendOnlyMap 相对 PartitionedPairBuffer 来说，存储效率更高，落盘频率也越低")])])])]),e._v(" "),a("blockquote",[a("p",[e._v("NOTE：如果 Map 端有 aggregate 或者 sort 操作，则会根据 partitionId、key 进行排序，否则只是简单地将数据分到对应的 partition；如果 Map 端无 aggreate 操作且分区数小于 "),a("code",[e._v("spark.shuffle.sort.bypassMergeThreshold")]),e._v("，则可以跳过排序操作。")])]),e._v(" "),a("p",[e._v("Shuffle Write 结束后，各个 executor 就会进行 Shuffle Read 拉取数据，本质上就是 stage 之间数据的分发，Shuffle Read 需要拉取数据的次数，会随着 task 的增长而呈指数级增长。")])])}),[],!1,null,null,null);t.default=l.exports}}]);