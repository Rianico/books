(window.webpackJsonp=window.webpackJsonp||[]).push([[63],{785:function(e,r,t){"use strict";t.r(r);var a=t(70),_=Object(a.a)({},(function(){var e=this,r=e.$createElement,t=e._self._c||r;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h2",{attrs:{id:"存储系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#存储系统"}},[e._v("#")]),e._v(" 存储系统")]),e._v(" "),t("p",[e._v("Spark 存储系统主要用于存储三个方面的数据：")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("RDD 缓存")]),e._v("：将 RDD 以缓存的形式物化到内存或者磁盘中")]),e._v(" "),t("li",[t("strong",[e._v("Shuffle 中间文件")]),e._v("：Shuffle Map 阶段的输出结果，会以文件形式落到磁盘上")]),e._v(" "),t("li",[t("strong",[e._v("广播变量")]),e._v("：在 Executor 进程范围分发访问频次较高的小数据")])]),e._v(" "),t("p",[e._v("Spark 存储系统主要有以下组件：")]),e._v(" "),t("ul",[t("li",[e._v("BlockManager & BlockManagerMaster")]),e._v(" "),t("li",[e._v("MemoryStore")]),e._v(" "),t("li",[e._v("DiskStore & DiskBlockManager")])]),e._v(" "),t("h2",{attrs:{id:"_1-存储管理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-存储管理"}},[e._v("#")]),e._v(" 1. 存储管理")]),e._v(" "),t("p",[e._v("BlockManager 是最为重要的组件，"),t("strong",[e._v("它在 Executors 端负责统一管理和协调数据的本地存取与跨节点传输")]),e._v(":")]),e._v(" "),t("ul",[t("li",[e._v("对外，BlockManager 与 Driver 端的 BlockManagerMaster 通信，定期汇报本地数据元信息，不定时拉取全局数据存储状态，还负责与其他 Executor 端的 BlockManager 之间进行跨节点数据推送与拉取。")]),e._v(" "),t("li",[e._v("对内，BlockManager 调用存储系统内部组件的功能来实现数据的存取与收发。")])]),e._v(" "),t("h2",{attrs:{id:"_2-存储方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-存储方式"}},[e._v("#")]),e._v(" 2. 存储方式")]),e._v(" "),t("p",[e._v("Spark 提供了两种存储抽象：MemoryStore 和 DiskStore，BlockManager 用它们分别来管理数据在内存和磁盘中的存取。")]),e._v(" "),t("p",[e._v("Spark 支持两种数据存储形式："),t("strong",[e._v("对象值（Object Values)"),t("strong",[e._v("和")]),e._v("字节数组（Byte Array）")]),e._v("，两者可以相互转化，对象值转化为字节数组的过程称为序列化，反过来则为反序列化。")]),e._v(" "),t("h3",{attrs:{id:"_2-1-memorystore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-memorystore"}},[e._v("#")]),e._v(" 2.1 MemoryStore")]),e._v(" "),t("p",[e._v("广播变量的全量数据会存储在 Executor 进程中，由 MemoryStore 管理。")]),e._v(" "),t("p",[e._v("MemoryStore 负责 RDD 在内存中的存储，既可以存储对象数组，也可以存储字节数组，并统一采用 "),t("strong",[e._v("MemoryEntry")]),e._v(" 数据抽象进行封装。")]),e._v(" "),t("p",[e._v("MemoryEntry 有两个实现类："),t("strong",[e._v("DeserializedMemoryEntry")]),e._v(" 和 "),t("strong",[e._v("SerializedMemoryEntry")]),e._v("，分别用于封装对象数组和字节数组。")]),e._v(" "),t("p",[e._v("DeserializedMemoryEntry 用 "),t("strong",[e._v("Array[T]")]),e._v(" 来存储对象值序列，其中 T 是对象类型，而 SerializedMemoryEntry 使用 "),t("strong",[e._v("Array[ByteBuffer]")]),e._v(" 来存储序列化后的字节序列。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://gitee.com/zhxuankun/Image/raw/master/blog/image-20210714162403924.png",alt:"image-20210714162403924"}})]),e._v(" "),t("p",[e._v("MemoryStore 使用了 "),t("strong",[e._v("LinkedHashMap[BlockId, MemoryEntry]")]),e._v(" 来管理 MemoryEntry，基于这种数据结构，可以很容易的实现 LRU 内存淘汰策略。")]),e._v(" "),t("p",[e._v("在逻辑关系上，RDD 的数据分片与存储系统的 Block（MemoryEntry） 一一对应，一个 RDD 数据分片会被物化成一个内存或磁盘上的 Block。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://static001.geekbang.org/resource/image/1y/0b/1yy5fd9f111f4cab0edc7cf582bd2b0b.jpg",alt:""}})]),e._v(" "),t("p",[e._v("RDD 缓存的具体过程如下：")]),e._v(" "),t("ul",[t("li",[e._v("先通过调用 "),t("strong",[e._v("putIteratorAsValues")]),e._v(" 或是 "),t("strong",[e._v("putIteratorAsBytes")]),e._v(" 对 RDD 进行迭代，并将每个元素存储到 "),t("strong",[e._v("ValueHolder")]),e._v(" 的数据结构里，这一步称为 ”Unroll“。")]),e._v(" "),t("li",[e._v("调用 ValueHolder 的 toArray 或 toByteBuffer 操作，转化为 MemoryEntry（是对 RDD 缓存数据数组的封装），这一步叫做“从 Unroll memory 到 Storage memory 的 Transfer（转移）”。")]),e._v(" "),t("li",[e._v("包含 RDD 数据值的 MemoryEntry 和与之对应的 BlockId，会被一起存入 Key 为 BlockId、Value 是 MemoryEntry 引用的链式哈希字典中。")])]),e._v(" "),t("p",[e._v("RDD 在展开过程中，Spark 会按照一定条数间隔检查可用内存，结合 Execution、Storage Memory 决定是否继续展开以及淘汰缓存，并不断更新 Execution Memory 与 Storage Memory 之间的可用内存。从这里也可以看出，Spark 划分内存本质上只是逻辑概念，目的是为了能够按照自定义的策略，对内存进行管理。")]),e._v(" "),t("h3",{attrs:{id:"_2-2-diskstore"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-diskstore"}},[e._v("#")]),e._v(" 2.2 DiskStore")]),e._v(" "),t("p",[e._v("Shuffle 中间文件由于涉及到落盘，因此是由 DiskStore 管理的。")]),e._v(" "),t("p",[e._v("DiskStore 中数据存取本质上就是字节数组与磁盘文件之间的转换。DiskStore 自身并不负责维护文件路径，数据块对应关系等信息，而是交由 DiskBlockManager 进行维护。")]),e._v(" "),t("p",[e._v("DiskBlockManager 的主要负责"),t("strong",[e._v("记录逻辑数据块 Block 与磁盘物理文件的对应关系，每个 Block  对应一个磁盘文件")]),e._v("。")]),e._v(" "),t("p",[e._v("DiskBlockManager 初始化时，会根据 "),t("code",[e._v("spark.local.dir")]),e._v(" 确定文件目录，接着根据 "),t("code",[e._v("spark.diskStore.subDirectories")]),e._v("（默认 64）指定的数量创建子目录，这些目录用于存储 DiskStore 物化的文件，如 RDD 缓存、Shuffle 中间结果文件等。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://static001.geekbang.org/resource/image/1e/4f/1eccayy6d9b7348ceea3cf3b12913a4f.jpg",alt:""}})]),e._v(" "),t("p",[t("strong",[e._v("Spark 默认采用 SortShuffleManager 来管理 Stages 间的数据分发，在 Shuffle Write 过程中，有 3 类结果文件：temp_shuffle_XXX、shuffle_XXX.data 和 shuffle_XXX.index")]),e._v("：")]),e._v(" "),t("ul",[t("li",[e._v("temp_shuffle_XXX：表示 Shuffle 中间结果的临时文件，后面会合并后删除")]),e._v(" "),t("li",[e._v("shuffle_XXX.data：由 temp_shuffle_XXX 合并而来")]),e._v(" "),t("li",[e._v("shuffle_XXX.index：记录了 shuffle_XXX.data 文件内不同分区的偏移地址")])]),e._v(" "),t("p",[e._v("其中 XXX 为对应 Block 的 BlockID。")]),e._v(" "),t("p",[e._v("Shuffle Write 阶段，ShuffleManager 会通过 BlockManager 调用 DiskStore 的 "),t("code",[e._v("putBytes")]),e._v(" 方法将数据块写入文件中，文件由 DiskBlockManager 创建，这些文件会以 temp 或者 shuffle 开头，保存在 spark.local.dir 下。")]),e._v(" "),t("p",[e._v("Shuffle Read 阶段，Shuffle Manager 会通过 BlockManager 调用 DiskStore 的 getBytes 方法，读取 data 和 index 文件，将其转化为数据块，通过网络分发到 Reducer 端进行聚合。")])])}),[],!1,null,null,null);r.default=_.exports}}]);