(window.webpackJsonp=window.webpackJsonp||[]).push([[72],{794:function(s,t,a){"use strict";a.r(t);var n=a(70),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"实战优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实战优化"}},[s._v("#")]),s._v(" 实战优化")]),s._v(" "),a("h3",{attrs:{id:"大表-join-小表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#大表-join-小表"}},[s._v("#")]),s._v(" 大表 Join 小表")]),s._v(" "),a("p",[s._v("通常说的大小表，都是相对比较的，在实际工作中，总会遇到一些场景，小表超过了 Broadcast 的阈值，这时需要采取一些手段进行优化。")]),s._v(" "),a("ol",[a("li",[a("p",[s._v("针对 Join Key 远远大于需要关联起来的值的时候，通常一个较好的做法就是"),a("strong",[s._v("将 Join Key 替换为 Hash")]),s._v("，并且为了避免 Hash 碰撞，还可以通过双重哈希，几乎不可能存在碰撞。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://static001.geekbang.org/resource/image/bb/bf/bb79544467e98f9d2b6f13a437bb2dbf.jpg",alt:""}})])]),s._v(" "),a("li",[a("p",[s._v("借助 Spark AQE 的 Join 策略调整，当维度表过滤了部分数据达到 Broadcast 阈值后触发 Broadcast Join。")])]),s._v(" "),a("li",[a("p",[s._v("如果 Join Key 能够过滤事实表较多的数据，或者种类较少，那么可以提前按照该 Key 值进行分区，充分利用 DPP 特性。")])]),s._v(" "),a("li",[a("p",[s._v("如果小表数据分布均匀，那么可以考虑将其做 Shuffle Hash Join；如果分布不均，则可以借助 AQE 的自动倾斜处理切割数据分片再做 Shuffle Hash Join。")])])]),s._v(" "),a("h3",{attrs:{id:"数据倾斜"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据倾斜"}},[s._v("#")]),s._v(" 数据倾斜")]),s._v(" "),a("p",[s._v("当大表 Join 大表时，调优策略跟上面类似，但当存在数据倾斜时，则通常需要采取两种措施：")]),s._v(" "),a("ol",[a("li",[s._v("分治，将查询拆分为多次查询，最后做 union")]),s._v(" "),a("li",[s._v("针对倾斜的 key 做加盐操作，之后进行"),a("strong",[s._v("两阶段 Shuffle 关联")])])]),s._v(" "),a("p",[s._v("分治较好理解，如果需要查询一个月的数据，那么通过一天天查询后再做 union 结果合并即可。")]),s._v(" "),a("p",[s._v("针对大表的数据倾斜，AQE 只能解决其 task 之间的倾斜，但对同个 executor 来说，仍存在负载不均衡的问题，这时就可以通过两阶段 Shuffle 关联来解决问题。")]),s._v(" "),a("p",[s._v("两阶段 Shuffle 关联主要分为两阶段：")]),s._v(" "),a("ol",[a("li",[s._v("筛选出倾斜的 key，对两个需要关联数据集的倾斜 key 按照相同规则进行加盐，经过 Shuffle 后进行一次预关联")]),s._v(" "),a("li",[s._v("对 key 值去盐后再次进行 Shuffle 关联")])]),s._v(" "),a("p",[s._v("以 orders 和 transactions 两张表为例，其中数据倾斜为单边倾斜：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//统计订单交易额的代码实现")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" txFile"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" orderFile"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _\n \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" transactions"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parquent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("txFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" orders"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parquent"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("orderFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \ntransactions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“transactions”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\norders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“orders”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" query"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(' "\nselect sum'),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("quantity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" as revenue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId\nfrom transactions as tx inner join orders as o\non tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId\nwhere o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("status "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'COMPLETE'")]),s._v("\nand o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("date between "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2020-01-01'")]),s._v(" and "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2020-03-31'")]),s._v("\ngroup by o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v('orderId\n"\n \n'),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" outFile"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _\nspark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("query"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parquet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("outFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("p",[s._v("接着按照倾斜的 key，将数据集分为倾斜与非倾斜两部分：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//根据Join Keys是否倾斜、将内外表分别拆分为两部分")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("functions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array_contains")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//将Join Keys分为两组，存在倾斜的、和分布均匀的")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" skewOrderIds"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" evenOrderIds"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" Array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _\n \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" skewTx"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" transactions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("filter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array_contains"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("skewOrderIds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"orderId"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" evenTx"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" transactions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("filter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array_contains"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("evenOrderIds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"orderId"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" skewOrders"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" orders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("filter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array_contains"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("skewOrderIds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"orderId"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" evenOrders"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" orders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("filter"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("array_contains"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("evenOrderIds"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("$"),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"orderId"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br")])]),a("p",[s._v("对于数据分布均匀的数据集，可以采用 Shuffle Hash Join 来进行关联：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//将分布均匀的数据分别注册为临时表")]),s._v("\nevenTx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“evenTx”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nevenOrders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“evenOrders”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" evenQuery"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" “\nselect "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*+ shuffle_hash(orders) */")]),s._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("quantity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" as revenue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId\nfrom evenTx as tx inner join evenOrders as o\non tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId\nwhere o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("status "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ‘COMPLETE’\nand o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("date between ‘"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),s._v("’ and ‘"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),s._v("’\ngroup by o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId\n”\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" evenResults"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("evenQuery"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br")])]),a("p",[s._v("对于数据倾斜的数据集，则进行两阶段 Shuffle 关联：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("functions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("udf")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//定义获取随机盐粒的UDF")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" numExecutors"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" rand "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" scala"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("util"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nextInt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("numExecutors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" randUdf "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" udf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("rand"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//第一阶段的加盐操作。注意：保留orderId字段，用于后期第二阶段的去盐化")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//外表随机加盐")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" saltedSkewTx "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" skewTx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("withColumn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“joinKey”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("$“orderId”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“_”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" randUdf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//内表复制加盐")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("var")]),s._v(" saltedskewOrders "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" skewOrders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("withColumn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“joinKey”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("$“orderId”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“_”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("<-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" to numExecutors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\nsaltedskewOrders "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" saltedskewOrders union skewOrders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("withColumn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“joinKey”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" concat"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("$“orderId”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“_”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("p",[s._v("接着进行第一阶段的 Shuffle 关联：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//将加盐后的数据分别注册为临时表")]),s._v("\nsaltedSkewTx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“saltedSkewTx”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsaltedskewOrders"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“saltedskewOrders”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" skewQuery"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" “\nselect "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*+ shuffle_hash(orders) */")]),s._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("quantity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" as initialRevenue"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("orderId"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("joinKey\nfrom saltedSkewTx as tx inner join saltedskewOrders as o\non tx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("joinKey "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("joinKey\nwhere o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("status "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ‘COMPLETE’\nand o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("date between ‘"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("01")]),s._v("’ and ‘"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("03")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),s._v("’\ngroup by o"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("joinKey\n”\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//第一阶段加盐、Shuffle、关联、聚合后的初步结果")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" skewInitialResults"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("skewQuery"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br")])]),a("p",[s._v("得到第一阶段的关联结果后，接着进行第二阶段的去盐化关联：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" skewResults"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" DataFrame "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" skewInitialResults"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“initialRevenue”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" “orderId”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("groupBy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("col"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“orderId”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("agg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("col"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“initialRevenue”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("alias"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("“revenue”"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("最后合并倾斜与非倾斜的结果集：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[s._v("evenResults union skewResults\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("两阶段 Shuffle 主要是开发成本与执行性能的博弈，当 executor 因为数据倾斜而称为整个执行性能瓶颈的时候，则这种开发投入就是值得的。")])])}),[],!1,null,null,null);t.default=e.exports}}]);