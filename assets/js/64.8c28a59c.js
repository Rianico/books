(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{786:function(t,a,s){"use strict";s.r(a);var e=s(70),r=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"_1-spark-内存管理模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-spark-内存管理模式"}},[t._v("#")]),t._v(" 1. Spark 内存管理模式")]),t._v(" "),s("p",[t._v("在管理方式上，Spark 会区分"),s("strong",[t._v("堆内内存（On-heap Memory）"),s("strong",[t._v("和")]),t._v("堆外内存（Off-heap Memory）")]),t._v("，其中堆内内存由 JVM 统一管理，堆外内存则由 Spark 自行管理（调用 Java 的 Unsafe）。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://iamluminousmen-media.s3.amazonaws.com/media/dive-into-spark-memory/dive-into-spark-memory-10.jpg",alt:"Executor Container"}})]),t._v(" "),s("p",[t._v("在堆内存的管理上，Spark 创建、删除对象都是交由 JVM 管理，这种方式下，Spark 对内存的估计是存在一个误差的，容易导致 OOM。")]),t._v(" "),s("p",[t._v("Overhead 属于 Container 的一部分，以堆外的形式存在，主要承担了一些额外的开销，如虚拟机的开销，内部字符串或者一些本地开销。3.0 之前，该部分内存包含了 off-heap，3.0 开始则将两者分离开来。")]),t._v(" "),s("h2",{attrs:{id:"_2-内存区域的划分"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-内存区域的划分"}},[t._v("#")]),t._v(" 2. 内存区域的划分")]),t._v(" "),s("h3",{attrs:{id:"_2-1-堆内内存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-堆内内存"}},[t._v("#")]),t._v(" 2.1 堆内内存")]),t._v(" "),s("p",[t._v("Spark Executor 内存划分如下：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://www.tutorialdocs.com/upload/2018/08/spark-memory-01.svg",alt:"img"}})]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Reserved Memory")]),t._v("：用于存储 Spark 自身的一些对象，如 BlockManager 等")]),t._v(" "),s("li",[s("strong",[t._v("User Memory")]),t._v("：存储用户自定义数据结构")]),t._v(" "),s("li",[s("strong",[t._v("Storage Memory")]),t._v("：用于缓存 RDD、广播变量等数据")]),t._v(" "),s("li",[s("strong",[t._v("Execution Memory")]),t._v("：用于执行分布式任务，如 Shuffle、Sort 和 Aggregate 等操作，并存储一些运行时需要的数据：\n"),s("ul",[s("li",[t._v("Shuffle Map 阶段的数据转换、映射、排序、聚合、归并等操作")]),t._v(" "),s("li",[t._v("Shuffle Reduce 阶段的数据排序和聚合操作")])])])]),t._v(" "),s("p",[t._v("Execution Memory 和 Storage Memory 之间的转化规则如下：")]),t._v(" "),s("ul",[s("li",[t._v("双方都只能抢占彼此空闲的内存")]),t._v(" "),s("li",[t._v("如果 Storage Memory 占用了部分 Execution Memory，当计算任务有需要时，需要立刻归还占用的 Execution Memory")]),t._v(" "),s("li",[t._v("如果 Execution Memory 占用了部分 Storage Memory，即使需要缓存数据，也需要等待计算任务完成再释放 Execution Memory。")])]),t._v(" "),s("p",[t._v("Execution Memory 存储了中间计算结果，由于需要参与后续计算，因此不能像 Storage Memory 一样简单的将其淘汰出内存。")]),t._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dict"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" List"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" List"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("“spark”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" “scala”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" words"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sparkContext"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("“"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("words"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("csv”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" keywords"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" RDD"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" words"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" dict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contains"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nkeywords"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cache\nkeywords"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count\nkeywords"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" _"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br")])]),s("p",[t._v("第 1 行代码的 "),s("code",[t._v("dict")]),t._v(" 对象使用了 User Memory，而由于第四行的 "),s("code",[t._v("cache")]),t._v(" 方法，因此第 4、5 行都使用了 Storage Memory，第 6 行涉及到 shuffle，因此会消耗 Execution Memory。")]),t._v(" "),s("h3",{attrs:{id:"_2-2-非堆内存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-非堆内存"}},[t._v("#")]),t._v(" 2.2 非堆内存")]),t._v(" "),s("p",[t._v("非堆内存的划分则较为简单，直接划分为了 Storage Memory 以及 Execution Memory，两者之间可以相互转化：")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://www.tutorialdocs.com/upload/2018/08/spark-memory-02.svg",alt:"img"}})]),t._v(" "),s("p",[t._v("非堆内存使得 Spark 可以直接操作 JVM 之外的内存，减少不必要的内存消耗，GC 负载等，从而提升性能。")]),t._v(" "),s("p",[t._v("尽管非堆内存可以提供性能上的提升，但使用起来需要非常小心。在某些场景下，也会带来"),s("strong",[t._v("堆内到堆外对象拷贝以及序列化的开销")]),t._v("，同时也带来了 GC 负载。")]),t._v(" "),s("blockquote",[s("p",[t._v("NOTE：堆内堆外的内存空间不共享，task 往往会优先使用堆外，再使用堆内，但如果一个 task 堆外空间不够用，不会使用堆内而是直接 OOM。")])]),t._v(" "),s("h2",{attrs:{id:"_3-oom"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-oom"}},[t._v("#")]),t._v(" 3. OOM")]),t._v(" "),s("p",[t._v("Spark 中的 OOM 通常分为 Driver 与 Executor 端。")]),t._v(" "),s("h3",{attrs:{id:"_3-1-driver-端"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-driver-端"}},[t._v("#")]),t._v(" 3.1 Driver 端")]),t._v(" "),s("p",[t._v("Driver 端情况较为简单，通常是处于以下两类问题：")]),t._v(" "),s("ul",[s("li",[t._v("创建的数据集过大，如使用 parallelize、createDataFrame 等 API")]),t._v(" "),s("li",[t._v("收集的数据集过大，显式的如 take、show、collect 等，隐式的有从 Executor 端汇聚广播变量")])]),t._v(" "),s("p",[t._v("其中广播变量导致的 OOM 常见信息如下：")]),t._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("java"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lang"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("OutOfMemoryError"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Not enough memory to build and broadcast\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br")])]),s("p",[t._v("可以通过以下代码先预估需要的内存大小：")]),t._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" df"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataFrame "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" _\ndf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" plan "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("queryExecution"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("logical\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" estimated"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" BigInt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" spark\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sessionState\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("executePlan"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("plan"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizedPlan\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sizeInBytes\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br")])]),s("h3",{attrs:{id:"_3-2-executor-端"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-executor-端"}},[t._v("#")]),t._v(" 3.2 Executor 端")]),t._v(" "),s("p",[t._v("Executor 端情况较为复杂， 由于 Spark 将其划分为了多块内存，因此需要逐个分析。")]),t._v(" "),s("p",[t._v("通常可以先排除 Reserved Memory 以及 Storage Memory，前者是固定大小，用户无法控制，后者在内存不足时，会选择落盘。")]),t._v(" "),s("p",[t._v("对于 User Memory 的 OOM，常见信息如下：")]),t._v(" "),s("div",{staticClass:"language-scala line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("java"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lang"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("OutOfMemoryError"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Java heap space at java"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Arrays"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("copyOf\n \njava"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lang"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("OutOfMemoryError"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Java heap space at java"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lang"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reflect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("newInstance\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br")])]),s("p",[t._v("用户自定义的数据结构大小 #size，需要结合 Executor 线程数量 #threads，得出自定义数据总的消耗内存： #size * #threads，一旦消耗内存超过 User Memory 则会 OOM。")]),t._v(" "),s("p",[t._v("对于 Execution Memory 的 OOM，情况较为复杂，"),s("strong",[t._v("通常导致其 OOM 的原因并不是数据量过大，而是没有平衡好分片大小与并发度（线程可分配内存）之间的关系")]),t._v("。")]),t._v(" "),s("p",[t._v("假设一个 Executor 的并发度为 N，那么最理想的情况下，每个线程可分配的内存在 1/2N ~ 1/N 之间，如果某个 task 所需内存大小大于线程所能获取的内存，则很可能会产生 OOM。同时这里也要考虑真实并发度 ~N 并不总是等于 Executor 设定的线程数（<= N），但最终会逐渐趋于 N。")]),t._v(" "),s("p",[t._v("通常有以下两种场景会导致数据分片大小超过线程内存大小：")]),t._v(" "),s("ul",[s("li",[t._v("数据倾斜，某个数据分片过大")]),t._v(" "),s("li",[t._v("数据膨胀，数据读取到内存后，往往会有一定程度的膨胀，这是由于数据在加载之前可能进行了序列化、压缩等，同时 JVM 里的对象也往往大于原始数据")]),t._v(" "),s("li",[t._v("Execution 剩余内存无法满足 Reducer task 所需内存 "),s("code",[t._v("spark.reducer.maxSizeInFlight")])])]),t._v(" "),s("p",[t._v("解决思路通常有三种：")]),t._v(" "),s("ul",[s("li",[t._v("对于某个数据分片过大的，可以通过打散数据，降低数据粒度")]),t._v(" "),s("li",[t._v("减少 Executor 并发度以增加线程单个线程所能够分配到的内存（需结合业务场景）")]),t._v(" "),s("li",[t._v("增加 Executor 内存，提高每个线程所能够分配到的内存")])]),t._v(" "),s("h3",{attrs:{id:"_3-3-堆外内存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-堆外内存"}},[t._v("#")]),t._v(" 3.3 堆外内存")]),t._v(" "),s("p",[t._v("堆外内存 OOM 较为少见，通常发生在 Shuffle Reduce 阶段，Reducer task 通过 Netty 拉取远端数据到堆外内存中。")]),t._v(" "),s("p",[t._v("首先确认是否数据倾斜问题，某个数据分片如果特别大，很可能会把堆外内存用光（JDK8 开始不指定的话默认最大值不超过堆内存），解决了数据倾斜大概率这个问题也会消失。")]),t._v(" "),s("p",[t._v("如果仍然存在这个问题，那么可以通过控制 Shuffle Reduce 落到磁盘来解决，设置 "),s("code",[t._v("spark.maxRemoteBlockSizeFetchToMem")]),t._v(" 来触发 buffer 的尽早落盘。")]),t._v(" "),s("p",[t._v("参考：")]),t._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://luminousmen.com/post/dive-into-spark-memory",target:"_blank",rel:"noopener noreferrer"}},[s("strong",[t._v("Dive into Spark memory")]),s("OutboundLink")],1)])])])}),[],!1,null,null,null);a.default=r.exports}}]);