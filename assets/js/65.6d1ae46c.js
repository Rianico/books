(window.webpackJsonp=window.webpackJsonp||[]).push([[65],{787:function(t,a,r){"use strict";r.r(a);var e=r(70),s=Object(e.a)({},(function(){var t=this,a=t.$createElement,r=t._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h2",{attrs:{id:"应用开发原则"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#应用开发原则"}},[t._v("#")]),t._v(" 应用开发原则")]),t._v(" "),r("p",[t._v("Spark 应用开发中，有几个原则应当遵守，分别为充分利用 Spark 自身提供的优化机制，以及代码编写中的一些规范。")]),t._v(" "),r("h2",{attrs:{id:"_1-tungsten"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-tungsten"}},[t._v("#")]),t._v(" 1. Tungsten")]),t._v(" "),r("p",[r("strong",[t._v("在数据结构方面，Tungsten 自定义了紧凑的二进制格式")]),t._v("，并且借由其二进制格式，天然地避免了 Java 对象序列化与反序列化引入的计算开销。")]),t._v(" "),r("p",[t._v("基于定制化的二进制数据结构，Tungsten 利用 Java Unsafe API 开辟堆外（Off Heap Memory）内存来管理对象。")]),t._v(" "),r("p",[t._v("在运行时，Tungsten 用"),r("strong",[t._v("全阶段代码生成（Whole Stage Code Generation）"),r("strong",[t._v("取代")]),t._v("火山迭代模型")]),t._v("，这不仅可以减少虚函数调用和降低内存访问频率，还能提升 CPU cache 命中率，做到大幅压缩 CPU idle 时间，从而提升 CPU 利用率。")]),t._v(" "),r("p",[r("a",{attrs:{href:"https://databricks.com/session/spark-sql-another-16x-faster-after-tungsten",target:"_blank",rel:"noopener noreferrer"}},[t._v("Spark SQL: Another 16x Faster After Tungsten"),r("OutboundLink")],1)]),t._v(" "),r("h2",{attrs:{id:"_2-aqe"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-aqe"}},[t._v("#")]),t._v(" 2. AQE")]),t._v(" "),r("p",[t._v("**AQE（Adaptive Query Execution）**全称“自适应查询执行”，它可以在 Spark SQL 优化的过程中动态地调整执行计划。")]),t._v(" "),r("p",[t._v("Spark SQL 的优化过程可以大致分为"),r("strong",[t._v("语法分析")]),t._v("、"),r("strong",[t._v("语义解析")]),t._v("、"),r("strong",[t._v("逻辑计划")]),t._v("和"),r("strong",[t._v("物理计划")]),t._v("这几个环节。在以前（Spark 3.0 之前）的 Spark SQL 中，一旦选定了物理执行计划，便无法再更改，而 "),r("strong",[t._v("AQE 可以让 Spark 在运行时的不同阶段，结合实时的运行时状态，周期性地动态调整前面的逻辑计划，然后根据再优化的逻辑计划，重新选定最优的物理计划，从而调整运行时后续阶段的执行方式")]),t._v("。")]),t._v(" "),r("p",[r("img",{attrs:{src:"https://static001.geekbang.org/resource/image/4c/17/4cdd21d991c290a12e34d5dbfbdf1f17.jpg",alt:""}})]),t._v(" "),r("p",[t._v("AQE 主要带来了 3 个方面的改进：")]),t._v(" "),r("ul",[r("li",[r("strong",[t._v("自动分区合并")]),t._v("，AQE 会自动检测过小的数据分区，并对它们自动合并。")]),t._v(" "),r("li",[r("strong",[t._v("数据倾斜（Data Skew）")]),t._v("，在数据关联（Joins）的场景中，如果 AQE 发现某张表存在倾斜的数据分片，就会自动对它做加盐处理，同时对另一张表的数据进行复制。")]),t._v(" "),r("li",[r("strong",[t._v("Join 策略调整")]),t._v("，两个有序表要进行数据关联的时候，Spark SQL 在优化过程中总会选择 Sort Merge Join 的实现方式。但有一种情况是，其中一个表在排序前需要对数据进行过滤，过滤后的表小到足可以由广播变量容纳。这个时候，AQE 会切换为 Broadcast Join。")])]),t._v(" "),r("h2",{attrs:{id:"_3-能省则省、能拖则拖"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-能省则省、能拖则拖"}},[t._v("#")]),t._v(" 3. 能省则省、能拖则拖")]),t._v(" "),r("p",[t._v("应用开发中，我们执行的操作，尽可能的将能够减少数据量的操作提前，并减少 shuffle 操作，如果无法避免 shuffle 操作，则尽量将其延后。")]),t._v(" "),r("h2",{attrs:{id:"_4-跳出单机思维"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-跳出单机思维"}},[t._v("#")]),t._v(" 4. 跳出单机思维")]),t._v(" "),r("p",[t._v("如果需要对两张表进行关联，那么可以考虑是否能将其中一张表的数据量缩减，从而将 shuffle 优化为 Broadcast Join。")]),t._v(" "),r("p",[t._v("例如将其中一张表的多个 Join Key 转化为 hash，然后附带必要列的数据。")])])}),[],!1,null,null,null);a.default=s.exports}}]);