(window.webpackJsonp=window.webpackJsonp||[]).push([[71],{793:function(s,t,a){"use strict";a.r(t);var n=a(70),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"_1-aqe-三特性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-aqe-三特性"}},[s._v("#")]),s._v(" 1. AQE 三特性")]),s._v(" "),a("p",[s._v("AQE 主要是利用 Shuffle 阶段 Spark 获取到的一些数据相关信息，对整体执行流程进行动态的一种优化手段。")]),s._v(" "),a("p",[a("strong",[s._v("自动分区合并")]),s._v("，指定一个期望的数据分片大小，以及期望的最小分区数，通过这两个参数各自计算出一个数据分片的大小，并其中的较小者。启动示例如下：")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("spark-sconf spark.sql.adaptive.enabled"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true --conf spark.sql.adaptive.coalescePartitions.enabled"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("true --conf spark.sql.adaptive.coalescePartitions.minPartitionNum"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" --conf spark.sql.adaptive.advisoryPartitionSizeInBytes"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("64m\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[a("strong",[s._v("数据倾斜处理")]),s._v("，指定一个可以认定为倾斜分区的阈值，以及一个放大倍数。Spark 会统计出所有数据分片大小的中位数，当某个数据分片大小超过指定阈值，并且还超过中位数大小乘以放大倍数的时候，则会被认定为倾斜分区，并按照我们指定的数据分片期望大小进行切割。")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[a("strong",[s._v("Join策略调整")]),s._v("，主要涉及了一个逻辑规则和一个物理策略，它们分别是 DemoteBroadcastHashJoin 和 OptimizeLocalShuffleReader。")]),s._v(" "),a("ul",[a("li",[s._v("DemoteBroadcastHashJoin ：如果 Shuffle Write 之后存在小于广播阈值的表，并且该非空分区比例大于 "),a("code",[s._v("spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin")]),s._v("（默认 0.2），则会将 Sort Merge Join 降级为 Broadcast Join。")]),s._v(" "),a("li",[s._v("OptimizeLocalShuffleReader：在进行常规 Shuffle Write 之后，大表一端不会再进行数据 Shuffle 网络传输，而是就近读取本地节点的中间文件。")])]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h2",{attrs:{id:"_2-动态分区裁剪-dpp"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-动态分区裁剪-dpp"}},[s._v("#")]),s._v(" 2. 动态分区裁剪 DPP")]),s._v(" "),a("p",[a("strong",[s._v("DPP（Dynamic Partition Pruning，动态分区剪裁）是谓词下推中的一个特例")]),s._v("，当两个表关联时，DPP 会将经过过滤的小表的 Join Key 及需要用到的 Value 广播到大表，减少大表需要扫描的数据量。")]),s._v(" "),a("p",[s._v("大表能够借助 DPP 减少扫描数据量有以下几个条件：")]),s._v(" "),a("ul",[a("li",[s._v("大表必须是分区表，且分区字段必须是 Join Key")]),s._v(" "),a("li",[s._v("DPP 仅支持等值 Join")]),s._v(" "),a("li",[s._v("小表过滤后的数据集大小要小于广播阈值")])]),s._v(" "),a("h2",{attrs:{id:"_3-join-策略选择"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-join-策略选择"}},[s._v("#")]),s._v(" 3. Join 策略选择")]),s._v(" "),a("p",[s._v("对于参与关联的两张数据表，体量较大、主动扫描数据的表，称为"),a("strong",[s._v("外表")]),s._v("或是"),a("strong",[s._v("驱动表")]),s._v("；体量较小、被动参与数据扫描的表，称为"),a("strong",[s._v("内表")]),s._v("或是"),a("strong",[s._v("基表")]),s._v("。")]),s._v(" "),a("p",[s._v("Join 的类型共有 Nested Loop Join、Hash Join、Shuffle Merge Join 三种。")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("NLJ：采用嵌套循环进行关联，每遍历一条外表数据，就会遍历一次内表进行关联，通常用在不等值关联场景，时间复杂度为 O(M * N)。")])]),s._v(" "),a("li",[a("p",[s._v("Hash Join：对内表构建一个 Hash Table 到内存中，外表根据 key 做 Hash 以 O(1) 的方式进行关联。")])]),s._v(" "),a("li",[a("p",[s._v("Sort Merge Join：先对两张表进行排序，再归并关联，时间复杂度为 O(M + N)：")]),s._v(" "),a("ul",[a("li",[s._v("如果外表 Join Key 等于内表 Join Key，则进行关联，接着外表滑动到下一条记录")]),s._v(" "),a("li",[s._v("如果外表 Join Key 小于内表 Join Key，不满足关联条件，则外表滑动到下一条记录")]),s._v(" "),a("li",[s._v("如果外表 Join Key 大于内表 Join Key，不满足关联条件，则内表滑动到下一条记录")])]),s._v(" "),a("p",[a("img",{attrs:{src:"https://static001.geekbang.org/resource/image/e2/b2/e2a8f8d1b2572ff456fa83a3f25ccbb2.jpg",alt:""}})])])]),s._v(" "),a("p",[s._v("在"),a("strong",[s._v("等值关联")]),s._v("中，Spark 会按照 BHJ > SMJ > SHJ 的顺序选择 Join 策略。")]),s._v(" "),a("p",[s._v("由于 SMJ（外部排序） 比 SHJ（内存构建）稳定，因此优先级更高。")]),s._v(" "),a("p",[s._v("使用 SHJ 有以下两个条件：")]),s._v(" "),a("ol",[a("li",[s._v("外表比内表大 3 倍以上")]),s._v(" "),a("li",[s._v("内表大小不超过广播阈值")])]),s._v(" "),a("p",[s._v("除此之外，还要求将 "),a("code",[s._v("spark.sql.join.preferSortMergeJoin")]),s._v(" 设置为 false，否则 Spark 将永远优先选择 SMJ，且降级时也会降为 BHJ。")]),s._v(" "),a("p",[s._v("当设置为 false 后，如果满足了 BHJ （"),a("code",[s._v("spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin")]),s._v("）也会优先选择 BHJ，之后才选择 SHJ。")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin ")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 调整 BHJ 的触发阈值，以及是否关闭 SMJ 优先的开关")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// /usr/local/src/spark-3.1.1-bin-hadoop2.7/bin/spark-shell --master local[201] --conf spark.sql.adaptive.enabled=true --conf spark.sql.autoBroadcastJoinThreshold=80B --conf spark.sql.adaptive.coalescePartitions.enabled=false --conf spark.sql.adaptive.localShuffleReader.enabeld=false --conf spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.005 --conf spark.sql.join.preferSortMergeJoin=false")]),s._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[s._v("spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("implicits")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("case")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" TestEntryKV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" input4 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parallelize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" to "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nr "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" TestEntryKV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("nr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" nr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toString"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toDF"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ninput4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"input4"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" input5 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parallelize"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Seq"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("TestEntryKV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" TestEntryKV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" TestEntryKV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"3"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" TestEntryKV"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"4"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toDF"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ninput5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("createOrReplaceTempView"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"input5"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" sqlQuery "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" spark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("sql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("\"SELECT * FROM input4 JOIN input5 ON input4.key = input5.key WHERE input4.value = '1'\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("stripMargin"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nsqlQuery"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("collect\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br")])]),a("p",[s._v("需要注意的是，Spark 对文件大小的判断是否超过广播阈值，在数据读取来源不同的情况下是有所差别的，当数据读取来源于外部存储时，则以外部存储上的大小作为广播阈值的依据；若数据来自内存，则以内存中的大小为依据。但这种方式存在一个问题，就是数据读到内存中后，往往会有一定的膨胀，如果未考虑进该因素，则可能导致 Driver 端 OOM。")]),s._v(" "),a("p",[s._v("https://docs.databricks.com/spark/latest/spark-sql/aqe.html")])])}),[],!1,null,null,null);t.default=e.exports}}]);