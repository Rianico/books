(window.webpackJsonp=window.webpackJsonp||[]).push([[59],{780:function(r,v,_){"use strict";_.r(v);var t=_(70),e=Object(t.a)({},(function(){var r=this,v=r.$createElement,_=r._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":r.$parent.slotKey}},[_("h2",{attrs:{id:"相关问答"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#相关问答"}},[r._v("#")]),r._v(" 相关问答")]),r._v(" "),_("p",[_("strong",[r._v("Q：DAGScheduler 在创建 Tasks 的过程中，是如何设置每一个任务的本地性级别？")])]),r._v(" "),_("p",[r._v("A：DAGScheduler 会通过 SchedulerBackend 获取集群资源的可用信息：")]),r._v(" "),_("ul",[_("li",[r._v("如果 RDD 被缓存")]),r._v(" "),_("li",[r._v("如果 RDD 有 preferredLocations 属性")]),r._v(" "),_("li",[r._v("找到属于窄依赖的父 RDD")])]),r._v(" "),_("p",[r._v("DAGScheduler将生成好的TaskSet提交给TaskSetManager进行任务的本地性级别计算")]),r._v(" "),_("p",[r._v("C：待看源码")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：为什么 Spark 使用 LinkedHashMap 来记录 Block 的元数据？")])]),r._v(" "),_("p",[r._v("A：Spark 出于存储空间的考虑，会采用 LRU 算法自动淘汰一段时间内用不到的存储对象，而 LinkedHashMap 的 put/get 特性，正好可以实现这种淘汰策略。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：Broadcast 广播变量的存储？")])]),r._v(" "),_("p",[r._v("C：待看源码，直到 Spark 3.0 为止，无论广播变量在哪生成，都会先收集到 driver 端在进行分发。")]),r._v(" "),_("hr"),r._v(" "),_("p",[r._v("Q：什么是火山迭代模型和阶段代码生成（Whole Stage Code Generation）？")]),r._v(" "),_("p",[r._v("A：")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：AQE 的分区合并算法略显简单粗暴，如果让你来重新实现分区合并特性的话，你都有哪些思路呢？")])]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：AQE 中数据倾斜的处理机制，你认为有哪些潜在的隐患？")])]),r._v(" "),_("hr"),r._v(" "),_("p",[r._v("Q：自动数据倾斜处理")]),r._v(" "),_("p",[r._v("https://www.waitingforcode.com/apache-spark-sql/whats-new-apache-spark-3-join-skew-optimization/read")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：Spark 3.0 中，除了 Broadcast 关键字之外还支持那些 Join Hints？")])]),r._v(" "),_("p",[r._v("A：参考 JoinStrategyHint.scala")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：从 Executor 并发度、执行内存大小和分布式任务并行度出发，你认为在什么情况下会出现 OOM 的问题？")])]),r._v(" "),_("p",[r._v("并发度决定了数据分片的大小，当一个数据分片需要的内存大于（执行内存 / 并行度）时，则会发生 OOM。")]),r._v(" "),_("p",[r._v("由于 Storage Memory 跟 Execution Memory 使用的不是同一把锁，Executor 如果并发度过高，在极端情况下，当一个 task 请求 Storage Memory 的内存成功后，如果在 allocation 之前那块内存被其他 task 抢占了，且此时没有其余内存空闲，那么会导致 OOM。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：由于执行内存总量 M 是动态变化的，并发任务数 N~ 也是动态变化的，因此每个线程申请内存的上下限也是动态调整的，你知道这个调整周期以什么为准？")])]),r._v(" "),_("p",[r._v("A：Executor内正在运行的这批任务执行完，下一批任务被执行前，就进行资源调整。根据此时（执行内存/min(待分配任务数，executor.cores)）进行内存分配，所以如果有多个 core，但只有一个 task，该 task 也是可以获得全部执行内存的。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：User Memory、Execution Memory、Storage Memory 是属于 Spark 自身对内存区域的划分，但 Spark 的 executor 实际上又是一个 JVM，假如我把 User Memory 设置的非常小，又自定义了一个很大的数据结构，此时 User Memory 不够用了，而 Execution Memory、Storage Memory 还有很大的空闲，那么这时候会不会 OOM？")])]),r._v(" "),_("p",[r._v("A：Spark 并不会立刻 OOM，如果其余部分的内存仍有剩余，那么 User Memory 也是会占用其内存的，Spark 对内存的预估并没有那么精准。")]),r._v(" "),_("p",[r._v("Spark 对各个区域内存的划分本质上更加倾向于一种软限制，并不会突破 JVM 的限制。而 User Memory 这种额外的抢占，很可能出现有时看起来是 rdd 缓存或者执行内存导致了 OOM，实际上是由于 User Memory 抢占了这部分内存空间才导致的。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：DAG 以 Shuffle 为边界划分 Stages，Spark 是根据什么来判断一个操作是否会引入 Shuffle 的呢？")])]),r._v(" "),_("p",[r._v("A：从 Action 开始溯源，如果子 RDD 依赖父 RDD 的数据，并且两者的分区器不同，则会产生 Shuffle，常见表现为宽依赖，窄依赖则不一定，所以本质上还是取决于分区器。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：在 Spark 中，同一 Stage 内的所有算子会融合为一个函数是如何实现的？")])]),r._v(" "),_("p",[r._v("A：task 启动后，会在 Stages 内部最后的 rdd 处，将其 compute 作用于父 rdd 之上，父 RDD 则继续往上传递并作用，如此反复直到根 rdd。")]),r._v(" "),_("p",[r._v("https://www.jianshu.com/p/45c9ee55eea6")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：既然 Catalyst 在逻辑优化阶段有 81 条优化规则，我们还需要遵循“能省则省、能拖则拖”的开发原则吗？")])]),r._v(" "),_("p",[r._v("A：Catalyst 的优化只是一种普世的优化逻辑，不可能覆盖所有的场景，因此仍需要我们遵循特定的开发规则，结合业务特点，达到自我优化+底层框架优化的双重效果。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：你能说说 Spark 为什么用偏函数，而不是普通函数来定义 Catalyst 的优化规则吗？")])]),r._v(" "),_("p",[r._v("A：普通的函数可以理解为输入一个变量 x，就会执行特定的运算得到一个 y，可以把 y 看成是执行了一个特定计算的 x。Scala 中的偏函数更类似于一种匹配，如果匹配到一个特定的计算则继续执行下一个指定的计算，否则执行其他计算，可以灵活拆分组合。")]),r._v(" "),_("p",[r._v("Catalyst 使用偏函数来实现，可以很灵活的制定优化规则，只关注需要优化的场景，一旦部分场景满足了 Catalyst 的优化规则，则应用该优化，并且也可以随时添加新的优化规则增加覆盖的场景。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：为什么 Spark SQL 没有实现 Broadcast Sort Merge Join 策略？")])]),r._v(" "),_("p",[r._v("A：Broadcast 已支持的两种 Join 策略分别为：")]),r._v(" "),_("ul",[_("li",[r._v("Hash Join：主要用于等值连接")]),r._v(" "),_("li",[r._v("Nested Loop Join：笛卡尔积，不等值等")])]),r._v(" "),_("p",[r._v("这两种方式其实已经覆盖了 Broadcast Sort Merge Join 的需求，当能够进行 Broadcast 的时候，也说明数据量相对较少较少，排序带来的收益也并不高，因此没必要实现。")]),r._v(" "),_("hr"),r._v(" "),_("p",[_("strong",[r._v("Q：为什么 Spark SQL 仅支持 RBO（Rule Based Optimization，基于规则的优化）而不是重点依赖于 CBO（Cost Based Optimization，基于成本的优化）？")])]),r._v(" "),_("p",[r._v("A：Spark 在 2.2 版本推出了 CBO，CBO 的特点是实事求是，但应用存在三个问题：")]),r._v(" "),_("ol",[_("li",[_("strong",[r._v("窄")]),r._v("：引用范围太小，仅支持注册到 Hive Metastore 的数据表，而不支持其它数据源")]),r._v(" "),_("li",[_("strong",[r._v("慢")]),r._v("：CBO 的统计信息收集效率较低，对于注册到 Hive Me他store 的数据表，开发者需要调用 ANALYZE TABLE COMPUTE STATISTICS 消耗大量时间")]),r._v(" "),_("li",[_("strong",[r._v("静")]),r._v("：静态优化，与 RBO 一样，不会动态的修改执行计划")])])])}),[],!1,null,null,null);v.default=e.exports}}]);