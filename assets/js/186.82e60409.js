(window.webpackJsonp=window.webpackJsonp||[]).push([[186],{910:function(r,e,a){"use strict";a.r(e);var t=a(70),n=Object(t.a)({},(function(){var r=this,e=r.$createElement,a=r._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":r.$parent.slotKey}},[a("h2",{attrs:{id:"sparkstreaming-backpressure-及动态-executor-调整"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sparkstreaming-backpressure-及动态-executor-调整"}},[r._v("#")]),r._v(" SparkStreaming Backpressure 及动态 Executor 调整")]),r._v(" "),a("p",[r._v("在 Medium 看到这篇文章："),a("a",{attrs:{href:"https://medium.com/@pmatpadi/spark-streaming-dynamic-scaling-and-backpressure-in-action-6ebdbc782a69",target:"_blank",rel:"noopener noreferrer"}},[r._v("Spark Streaming: Dynamic Scaling And Backpressure in Action"),a("OutboundLink")],1)]),r._v(" "),a("p",[r._v("其中有几个参数在官方文档没有找到：")]),r._v(" "),a("p",[a("img",{attrs:{src:"https://gitee.com/zhxuankun/Image/raw/master/blog/image-20210818155443845.png",alt:"image-20210818155443845"}})]),r._v(" "),a("p",[r._v("实际是上就相当于 Spark Core 的动态资源分配，并且 SparkStreaming 与 Spark Core 的这个配置相互冲突，两者不能共存，详见 "),a("a",{attrs:{href:"https://github.com/apache/spark/blob/v3.0.3/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ExecutorAllocationManager.scala#L171",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[r._v("ExecutorAllocationManager")]),a("OutboundLink")],1),r._v("。")]),r._v(" "),a("p",[r._v("SparkStreaming 的 Executor 动态调整，目前来看只有在 Kafka Partition 发生变化时动态调整比较有用，但与Backpressure 结合使用时面临较多问题：")]),r._v(" "),a("ol",[a("li",[r._v("Executor 的扩容取决于作业 Processing Time / Batch Interval 的比例，但  也会影响到该值，有时候该比例超过扩容阈值 "),a("code",[r._v("0.9")]),r._v("，可能并非是 Executor 资源不足，而是消费速率过高导致的，容易误导 SparkStreaming 扩容 Executor，出现 Executor 并发度高于 Kafka Partition 数的现象。参考链接就是这种情况。")]),r._v(" "),a("li",[r._v("为了避免第 1 点，可以简单的将扩容阈值设置的比较大，但如果此时 Executor 消费处理能力够，又很难触发扩容策略。例如流量低峰期即使一个 Executor 处理 Kafka 两个 Partition 的数据，也可能只用了一个 Batch Interval 多点，此时作业仍会堆积。")])]),r._v(" "),a("p",[r._v("也就是说，在使用Backpressure时，由于Backpressure的动态调整，容易误导 SparkStreaming 的 Executor 扩容策略不准确。而不使用Backpressure转而采用固定消费速率的话，又会无法动态调整消费速率，目前来看属于一个比较鸡肋的功能，猜测这也是 Spark 官方文档不做介绍的原因。")]),r._v(" "),a("p",[r._v("目前来看，SparkStreaming 的 Executor 数目调整通过重启应用较为合适，亦或者 Spark Core 的动态资源调整会更加可控。")]),r._v(" "),a("p",[r._v("消费速率通过Backpressure解决。")]),r._v(" "),a("p",[r._v("DataBricks 有一篇文章进行了详细介绍："),a("a",{attrs:{href:"https://www.linkedin.com/pulse/enable-back-pressure-make-your-spark-streaming-production-lan-jiang",target:"_blank",rel:"noopener noreferrer"}},[r._v("Enable Back Pressure To Make Your Spark Streaming Application Production Ready"),a("OutboundLink")],1),r._v("。")])])}),[],!1,null,null,null);e.default=n.exports}}]);