(window.webpackJsonp=window.webpackJsonp||[]).push([[62],{784:function(s,t,a){"use strict";a.r(t);var n=a(70),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"_1-dag-与流水线式计算模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-dag-与流水线式计算模式"}},[s._v("#")]),s._v(" 1. DAG 与流水线式计算模式")]),s._v(" "),a("p",[s._v("Spark 中，内存计算有两层含义：")]),s._v(" "),a("ol",[a("li",[s._v("分布式数据缓存，即对频繁访问数据的缓存操作。")]),s._v(" "),a("li",[a("strong",[s._v("Spark 内部的流水线式计算模式")]),s._v("。")])]),s._v(" "),a("p",[s._v("DAG（Direct Acyclic Graph，有向无环图），在 Spark 的 DAG 中，顶点是一个个 RDD，边则是 RDD 之间通过 dependencies 属性构成的父子关系。")]),s._v(" "),a("p",[s._v("DAG 会根据分布式数据集上调用的算子来进行构建。")]),s._v(" "),a("p",[s._v("Spark 会将 DAG 转化为分布式任务，期间会经历四个步骤：")]),s._v(" "),a("ol",[a("li",[s._v("回溯 DAG 并划分 Stages")]),s._v(" "),a("li",[s._v("在 Stages 中创建"),a("strong",[s._v("分布式任务")])]),s._v(" "),a("li",[s._v("分布式任务的分发")]),s._v(" "),a("li",[s._v("分布式任务的执行")])]),s._v(" "),a("p",[s._v("Spark 的内存计算第二层含义就在 Stages 内部，"),a("strong",[s._v("以 Actions 算子为起点，向前回溯 DAG，以 Shuffle 操作为边界去划分 Stages")]),s._v("。")]),s._v(" "),a("p",[s._v("Spark 的流水线计算模式高效的地方在于："),a("strong",[s._v("同一 Stage 内部，所有算子融合为一个函数，Stage 的输出结果由这个函数一次性作用在输入数据集而产生")]),s._v("。")]),s._v(" "),a("blockquote",[a("p",[s._v("NOTE：对比起 MapReduce 计算引擎，Map 之间使用磁盘交换数据，Map 与 Reducer 之间通过磁盘及网络交换数据；Spark 则是直接在一个 Stage 内将所有函数融合为一个函数一次性作用并在内存中进行计算。")])]),s._v(" "),a("p",[s._v("Stage 是以 Shuffle 为边界，因此 Shuffle 极大降低性能除了 I/O 方面的原因，也有 Stage 方面的原因。")]),s._v(" "),a("h2",{attrs:{id:"_2-调度系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-调度系统"}},[s._v("#")]),s._v(" 2. 调度系统")]),s._v(" "),a("p",[s._v("Spark 的调度系统主要由三个部分组成："),a("strong",[s._v("DAGScheduler、TaskScheduler、SchedulerBackend")]),s._v("。")]),s._v(" "),a("p",[s._v("Spark 的调度过程如下：")]),s._v(" "),a("ol",[a("li",[s._v("DAGScheduler 将 DAG 划分为不同的 Stages；")]),s._v(" "),a("li",[s._v("DAGScheduler 根据 Stage 创建分布式任务 Tasks 和任务组 TaskSet，并交给 TaskScheduler；")]),s._v(" "),a("li",[s._v("SchedulerBackend 获取集群内可用的计算资源；")]),s._v(" "),a("li",[s._v("TaskScheduler 按照优先级策略设置 Task 调度信息，并根据集群可用计算资源，优先提交满足本地性的 Task 到 SchedulerBackend。")]),s._v(" "),a("li",[s._v("SchedulerBackend 根据 Task 信息，分发 Task 到 Executor 执行。")])]),s._v(" "),a("p",[s._v("Spark 调度系统的核心职责是，"),a("strong",[s._v("先将用户构建的 DAG 转化为分布式任务，结合分布式集群资源的可用性，基于调度规则依序把分布式任务分发到执行器")]),s._v("。")]),s._v(" "),a("p",[a("strong",[s._v("DAGScheduler")]),s._v(" 的职责有二：")]),s._v(" "),a("ol",[a("li",[s._v("根据 DAG 划分 Stages；")]),s._v(" "),a("li",[s._v("在 Stage 内创建 Task，这些 Task 囊括了用户指定的数据转换逻辑，并负责将同一 Stage 内的 Task 合并为一个函数。")])]),s._v(" "),a("p",[a("strong",[s._v("SchedulerBackend")]),s._v(" 负责获取集群资源的相关信息，是对资源调度器的封装与抽象，支持 Standalone、YARN 和 Mesos 等，均提供了具体实现。")]),s._v(" "),a("p",[s._v("SchedulerBackend 使用 "),a("strong",[s._v("ExecutorDataMap")]),s._v(" 的数据结构来存储集群资源信息，其中 key 标记了 Executor，value 是一种叫做 "),a("strong",[s._v("ExecutorData")]),s._v(" 的数据结构，ExecutorData 用于封装 Executor 的资源状态，如 RPC 地址、主机地址、可用 CPU 核数和满配 CPU 核数等。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://static001.geekbang.org/resource/image/a7/a9/a7f8d49bbf1f8b0a125ffca87f079aa9.jpg",alt:""}})]),s._v(" "),a("p",[s._v("对内，SchedulerBackend 用 ExecutorData 对 Executor 进行资源画像；")]),s._v(" "),a("p",[s._v("对外，SchedulerBackend 以 "),a("strong",[s._v("WorkerOffer")]),s._v(" 为粒度提供计算资源，WorkerOffer 封装了 Executor ID、主机地址和 CPU 核数，用来表示一份可用于调度任务的空闲资源。")]),s._v(" "),a("p",[s._v("DAGScheduler 生成了需要执行的 Task，SchedulerBackend 提供了可以运行 Task 的集群资源，TaskScheduler 则会基于既定的策略与规则，对 Task 进行一些设置（如本地性、调度优先级等），并提交给 SchedulerBackend，由其根据一定规则将其分发到 Executor 执行。")]),s._v(" "),a("p",[a("img",{attrs:{src:"https://static001.geekbang.org/resource/image/82/yy/82e86e1b3af101100015bcfd81f0f7yy.jpg",alt:""}})]),s._v(" "),a("p",[a("strong",[s._v("TaskScheduler")]),s._v(" 的调度优先级分为 Stage 和 Task 两方面：")]),s._v(" "),a("ul",[a("li",[s._v("对于 Stage 的调度，TaskScheduler 提供了 FIFO（默认） 和 Fair 两种调度方式：\n"),a("ul",[a("li",[a("strong",[s._v("FIFO")]),s._v("：按照 Stage 创建的先后时间进行调度")]),s._v(" "),a("li",[a("strong",[s._v("Fair")]),s._v("：设置多个不同优先级的调度池，将 Stage 与调度池进行关联，从而能够按照指定的优先级策略对 Stage 进行调度。")])])]),s._v(" "),a("li",[s._v("对于 Task 的调度，TaskScheduler 的处理主要包含以下几方面：\n"),a("ul",[a("li",[s._v("TaskScheduler 会根据接收到的 WorkerOffer，优先选择那些满足数据本地性（Process local < Node local < Rack local < Any）的 task 进行分发。")]),s._v(" "),a("li",[s._v("TaskScheduler 根据本地性挑选出待执行的 task 后，会将其序列化后交给 SchedulerBackend，由其分发到 Executor 上执行。")])])])]),s._v(" "),a("p",[s._v("Task 自带调度意愿，通过本地性级别告诉 TaskScheduler 自身偏向于在哪些 Executor 上进行调度。")]),s._v(" "),a("blockquote",[a("p",[s._v("NOTE： TaskScheduler 只有拿到 SchedulerBackend 的 WorkerOffer 后，才能挑选 task 分发过去。")])]),s._v(" "),a("h2",{attrs:{id:"_3-task-优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-task-优化"}},[s._v("#")]),s._v(" 3. task 优化")]),s._v(" "),a("p",[s._v("Spark 的调度系统做了很多优化，在编写 Spark 程序时，需要了解其调度原理，从而写出可以让 Spark 做出更多优化的程序。")]),s._v(" "),a("p",[s._v("考虑此场景：根据传入的字典文件路径加载字典，之后根据传入的 key 值获取对应的值，通常实现如下：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/**\n *实现方式1\n *输入参数：模板文件路径，用户兴趣字符串\n *返回值：用户兴趣字符串对应的索引值\n*/")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//函数定义")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" findIndex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("templatePath"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" interest"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" source "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fromFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("filePath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"UTF-8"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" lines "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getLines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toArray\n\tsource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" searchMap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" lines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zip"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" until lines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toMap\n\tsearchMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getOrElse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("interest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//Dataset中的函数调用")]),s._v("\nfindIndex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("filePath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"体育-篮球-NBA-湖人"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("p",[s._v("这种写法有个问题，在 Spark 调度系统中，会将 "),a("code",[s._v("findIndex()")]),s._v(" 函数传递到各个 Executor 上执行，那么每个 Executor 都会加载一份字典文件，效率十分低下。")]),s._v(" "),a("p",[s._v("改写后的代码如下：")]),s._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/**\n *实现方式2\n *输入参数：模板文件路径，用户兴趣字符串\n *返回值：用户兴趣字符串对应的索引值\n*/")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//函数定义")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" findIndex"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("Int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("filePath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" source "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fromFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("filePath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"UTF-8"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" lines "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" source"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getLines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toArray\n\tsource"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" searchMap "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" lines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("zip"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" until lines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("toMap\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("interest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("=>")]),s._v(" searchMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("getOrElse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("interest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("val")]),s._v(" partFunc "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" findIndex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("filePath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//Dataset中的函数调用")]),s._v("\npartFunc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"体育-篮球-NBA-湖人"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br")])]),a("p",[s._v("改写后，将原来的函数改造为了高阶函数，这样一来，Spark 会先在 driver 端先完成字典文件的加载，再在各个 Executor 上根据 key 值查询字典获取对应的值。")])])}),[],!1,null,null,null);t.default=e.exports}}]);