(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{738:function(a,n,s){"use strict";s.r(n);var e=s(70),t=Object(e.a)({},(function(){var a=this,n=a.$createElement,s=a._self._c||n;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h2",{attrs:{id:"numa-架构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#numa-架构"}},[a._v("#")]),a._v(" NUMA 架构")]),a._v(" "),s("p",[a._v("NUMA （"),s("a",{attrs:{href:"https://en.wikipedia.org/wiki/Non-uniform_memory_access",target:"_blank",rel:"noopener noreferrer"}},[a._v("Non-uniform memory access"),s("OutboundLink")],1),a._v("，非一致性内存访问）架构是近代计算机常见的一种架构。随着 CPU 近年来性能提升速度的逐渐放缓，开始出现通过多个 CPU 共同工作来提升性能的方式，而 NUMA 则是伴随这种方式出现的一种优化方案。")]),a._v(" "),s("h2",{attrs:{id:"_1-硬件角度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-硬件角度"}},[a._v("#")]),a._v(" 1. 硬件角度")]),a._v(" "),s("p",[a._v("从硬件角度来看，如果按照以前的计算机架构，多个 CPU 之间访问同一块内存，会共用一个 bus：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://i2.wp.com/jcole.us/blog/files/uma-architecture.png",alt:"img"}})]),a._v(" "),s("p",[a._v("但是这样一来，bus 就很可能出现性能瓶颈，导致整体性能的降低，因此就出现了 NUMA 架构：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://i2.wp.com/jcole.us/blog/files/numa-architecture.png",alt:"img"}})]),a._v(" "),s("p",[a._v("每个 CPU 都拥有自己的一块 “本地” 内存，其他 CPU 的内存则可以看做是 “远程” 内存。这种架构下，CPU 访问自己的本地内存会有更低的延迟以及更高的性能表现。")]),a._v(" "),s("h2",{attrs:{id:"_2-linux-角度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-linux-角度"}},[a._v("#")]),a._v(" 2. Linux 角度")]),a._v(" "),s("p",[a._v("从 Linux 角度来看，基于这种硬件架构，一个 CPU 可以抽象成一个或者多个 NUMA Node，一个 NUMA Node 可以识别出本地内存以及远端内存。")]),a._v(" "),s("p",[a._v("可以通过 "),s("code",[a._v("numactl -H")]),a._v(" 命令 ，查看不同 numa 节点之间的距离：")]),a._v(" "),s("div",{staticClass:"language-bash line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("node distances:\nnode   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" \n  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(":  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v(" \n  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(":  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("24")]),a._v(" \n  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(":  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" \n  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(":  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("24")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" \n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br")])]),s("h2",{attrs:{id:"_3-numa-存在的一些问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-numa-存在的一些问题"}},[a._v("#")]),a._v(" 3. NUMA 存在的一些问题")]),a._v(" "),s("p",[a._v("NUMA 架构存在的主要问题之一，就是在一个 NUMA Node 的本地内存即将耗尽的时候，旧版本的 Linux 采取的默认策略是 "),s("strong",[a._v("swap/淘汰")]),a._v(" 掉本地内存页，这样对于大内存应用（比如一个应用内存大于一个 NUMA Node 的本地内存）来说，一旦某个后续需要用到那部分内存页，就会出现明显的性能下降。")]),a._v(" "),s("p",[a._v("目前有几个比较主流的方法如下：")]),a._v(" "),s("ul",[s("li",[a._v("使用 "),s("code",[a._v("numactl --interleave=all")]),a._v(" 指定程序运行时随机分配在多个 NUMA Node 上。")]),a._v(" "),s("li",[a._v("设置 "),s("code",[a._v("vm.zone_reclaim_mode=0")]),a._v("，当本地内存不够时优先去远程内存分配，从 RHEL-5.6 开始就将其默认值从 1 修改为 0 了。")]),a._v(" "),s("li",[a._v("使用 numad 自动管理 NUMA 内存分配。")])]),a._v(" "),s("p",[a._v("另一个问题是，如果一个进程反复在不同的 numa node 上转移，那么也会导致原来建立的 cache 无效。")]),a._v(" "),s("h3",{attrs:{id:"_3-1-numactl-interleave-all"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-numactl-interleave-all"}},[a._v("#")]),a._v(" 3.1 numactl --interleave=all")]),a._v(" "),s("p",[s("code",[a._v("numactl --interleave=all")]),a._v(" 咋看之下好像失去了 NUMA 的优势，但是大部分情况下，一个应用可以分为稳定的线程（系统线程）以及经常变化的线程（用户创建的线程），对于稳定的线程来说，固定在一个 NUMA Node 下可以获得最好的性能，而对于随机分配在不同 CPU 下的用户线程来说，随机分配反而可以产生奇效，借用网上的一个性能测试结果：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://gitee.com/zhxuankun/Image/raw/master/ARTS_Tips/20210220163016.png",alt:"img"}})]),a._v(" "),s("p",[a._v("从上面的图可以看出，绝大部分场景下的性能表现，NUMA 默认 < 手动绑定 Numa Node < interleave 方式。因此，大部分场景下，NUMA 的性能瓶颈不在于远程内存访问，而是在于 NUMA 导致的内存页 swap/淘汰。")]),a._v(" "),s("h3",{attrs:{id:"_3-2-numad"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-numad"}},[a._v("#")]),a._v(" 3.2 numad")]),a._v(" "),s("p",[a._v("numad，是属于提供 NUMA 自动内存管理的守护线程，"),s("a",{attrs:{href:"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/performance_tuning_guide/index#sect-Red_Hat_Enterprise_Linux-Performance_Tuning_Guide-Performance_Monitoring_Tools-numad",target:"_blank",rel:"noopener noreferrer"}},[a._v("官方"),s("OutboundLink")],1),a._v("介绍如下：")]),a._v(" "),s("blockquote",[s("p",[a._v("numad is an automatic NUMA affinity management daemon. It monitors NUMA topology and resource usage within a system in order to dynamically improve NUMA resource allocation and management (and therefore system performance). Depending on system workload, numad can provide up to 50 percent improvements in performance benchmarks. It also provides a pre-placement advice service that can be queried by various job management systems to provide assistance with the initial binding of CPU and memory resources for their processes.")])]),a._v(" "),s("p",[a._v("numad 会周期性地地监控 NUMA 的资源使用情况，必要的时候会在 NUMA Node 之间移动进程以求达到最佳性能效果。")]),a._v(" "),s("p",[a._v("numad 主要的受益对象有：")]),a._v(" "),s("ul",[s("li",[a._v("消耗大量系统资源且长时间运行的进程")]),a._v(" "),s("li",[a._v("同时消耗多个 NUMA Node 资源的进程。")])]),a._v(" "),s("p",[a._v("对于那些只运行数分钟，或者只消耗少量资源的进程，numad 并不能带来性能上的提升，此外，那些具有连续性、不可预测的内存访问的系统，比如大内存的数据，也无法从 numad 获得提升。")]),a._v(" "),s("p",[a._v("对于 numad 的使用，可以参照"),s("a",{attrs:{href:"https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/performance_tuning_guide/sect-red_hat_enterprise_linux-performance_tuning_guide-tool_reference-numad",target:"_blank",rel:"noopener noreferrer"}},[a._v("官方文档"),s("OutboundLink")],1),a._v("。")]),a._v(" "),s("h2",{attrs:{id:"_4-使用方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-使用方式"}},[a._v("#")]),a._v(" 4. 使用方式")]),a._v(" "),s("p",[a._v("我们可以很简单的借助 numad 享受到 numa 机制带来的提升，但 numa 机制也不是适用于所有类型的程序，如果服务器需要运行多种类型的程序（比如只消耗少量资源，只运行短暂时间），那么 numad 往往不能为其带来太大的提升，反而可能会带来调度上的开销。")]),a._v(" "),s("p",[a._v("针对上面这种场景，在不适用 numad 方式下，可以使用 numactl 方式指定程序运行的 numa node，同时各个软件（如 JDK、Yarn）也有对 numa 提供了一定程度上的支持。")]),a._v(" "),s("h3",{attrs:{id:"_4-1-numactl-命令行方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-numactl-命令行方式"}},[a._v("#")]),a._v(" 4.1 numactl 命令行方式")]),a._v(" "),s("p",[a._v("numactl 可以指定进程在哪个 numa node 节点上运行，同时指定在哪个 numa node 节点上分配内存，格式如下：")]),a._v(" "),s("div",{staticClass:"language-bash line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("numactl -N "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("-1 -m "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("-1 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("命令"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br")])]),s("p",[a._v("numactl 的参数含义如下：")]),a._v(" "),s("ul",[s("li",[s("code",[a._v("-N 0-1")]),a._v("：指定该进程在 0、1 号 numa node 上运行，也可以单独指定一个 numa node")]),a._v(" "),s("li",[s("code",[a._v("-m 0-1")]),a._v("：指定该进程在 0、1 号 numa node 上分配内存，也可以单独指定一个 numa node")])]),a._v(" "),s("p",[a._v("验证过程如下：")]),a._v(" "),s("div",{staticClass:"language-bash line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 指定休眠进程在 0 号 numa node 上运行")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@dn22 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# nohup numactl -N 0 -m 0 sleep 60 &")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3811")]),a._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 使用 taskset 查看进程所在节点")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@dn22 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# taskset  -cp 3811")]),a._v("\npid "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3811")]),a._v("'s current affinity list: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("-7,16-23  \n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# 可以看到， 0-7，16-23 核心属于 0 号 numa node  ")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@dn22 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# numactl -H")]),a._v("\navailable: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" nodes "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("-1"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nnode "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" cpus: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("16")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("21")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("23")]),a._v("\nnode "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" size: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("130946")]),a._v(" MB\nnode "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" free: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1003")]),a._v(" MB\nnode "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" cpus: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("13")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("15")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("24")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("25")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("26")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("27")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("28")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("29")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("30")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("31")]),a._v("\nnode "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" size: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("131072")]),a._v(" MB\nnode "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" free: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1234")]),a._v(" MB\nnode distances:\nnode   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" \n  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(":  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("21")]),a._v(" \n  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(":  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("21")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" \n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br"),s("span",{staticClass:"line-number"},[a._v("4")]),s("br"),s("span",{staticClass:"line-number"},[a._v("5")]),s("br"),s("span",{staticClass:"line-number"},[a._v("6")]),s("br"),s("span",{staticClass:"line-number"},[a._v("7")]),s("br"),s("span",{staticClass:"line-number"},[a._v("8")]),s("br"),s("span",{staticClass:"line-number"},[a._v("9")]),s("br"),s("span",{staticClass:"line-number"},[a._v("10")]),s("br"),s("span",{staticClass:"line-number"},[a._v("11")]),s("br"),s("span",{staticClass:"line-number"},[a._v("12")]),s("br"),s("span",{staticClass:"line-number"},[a._v("13")]),s("br"),s("span",{staticClass:"line-number"},[a._v("14")]),s("br"),s("span",{staticClass:"line-number"},[a._v("15")]),s("br"),s("span",{staticClass:"line-number"},[a._v("16")]),s("br"),s("span",{staticClass:"line-number"},[a._v("17")]),s("br"),s("span",{staticClass:"line-number"},[a._v("18")]),s("br"),s("span",{staticClass:"line-number"},[a._v("19")]),s("br"),s("span",{staticClass:"line-number"},[a._v("20")]),s("br"),s("span",{staticClass:"line-number"},[a._v("21")]),s("br")])]),s("h3",{attrs:{id:"_4-2-yarn-方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-yarn-方式"}},[a._v("#")]),a._v(" 4.2 Yarn 方式")]),a._v(" "),s("p",[a._v("Yarn 从 3.1.0 版本开始支持 numa 调度，开启方式如下：")]),a._v(" "),s("ol",[s("li",[a._v("设置 "),s("code",[a._v("yarn.nodemanager.numa-awareness.enabled")]),a._v(" 为 true")]),a._v(" "),s("li",[a._v("对 "),s("code",[a._v("yarn.nodemanager.numa-awareness.read-topology")]),a._v(" 进行设置，分两种情况：\n"),s("ul",[s("li",[s("strong",[a._v("true")]),a._v("：Yarn 会自动通过 "),s("code",[a._v("numactl --hardware")]),a._v(" 命令获取机器上的 numa 拓扑结构信息")]),a._v(" "),s("li",[s("strong",[a._v("false")]),a._v("：Yarn 不会自动获取 numa 拓扑结构信息，而是依赖于以下配置获取 numa 拓扑结构信息：\n"),s("ul",[s("li",[s("strong",[a._v("yarn.nodemanager.numa-awareness.node-ids")]),a._v("：指定可用的 numa 节点，即 "),s("code",[a._v("NODE_ID")]),a._v("，多个 numa 节点使用 "),s("code",[a._v(",")]),a._v(" 分隔符隔开，如 "),s("code",[a._v("0,1,2")]),a._v("。")]),a._v(" "),s("li",[s("strong",[a._v("yarn.nodemanager.numa-awareness.<NODE_ID>.memory")]),a._v("：指定各个 numa 节点可用的内存，多个 numa 节点则根据其 "),s("code",[a._v("NODE_ID")]),a._v(" 配置多项")]),a._v(" "),s("li",[s("strong",[a._v("yarn.nodemanager.numa-awareness.<NODE_ID>.cpus")]),a._v("：指定各个 numa 节点可用的 cpu 核数，多个 numa 节点则根据其 "),s("code",[a._v("NODE_ID")]),a._v(" 配置多项")])])])])])]),a._v(" "),s("p",[a._v("为了支持该特性，节点上还需要预先安装 numactl 工具。")]),a._v(" "),s("p",[a._v("该特性是通过 numactl 来读取服务器上的 numa 信息，也支持手动配置，详见 "),s("a",{attrs:{href:"https://issues.apache.org/jira/browse/YARN-5764",target:"_blank",rel:"noopener noreferrer"}},[a._v("NUMA awareness support for launching containers"),s("OutboundLink")],1),a._v("。")]),a._v(" "),s("h3",{attrs:{id:"_4-3-jvm-方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-jvm-方式"}},[a._v("#")]),a._v(" 4.3 JVM 方式")]),a._v(" "),s("p",[a._v("JVM 也提供了对 NUMA 的支持，但对 GC 算法以及 JDK 版本有要求：")]),a._v(" "),s("ul",[s("li",[a._v("ParallelGC 支持 NUMA（JDK 6）")]),a._v(" "),s("li",[a._v("ZGC 支持 NUMA（JDK 11）")]),a._v(" "),s("li",[a._v("G1 GC 在 JDK 14 开始支持 NUMA")])]),a._v(" "),s("p",[a._v("在 JVM 启动参数上添加 "),s("code",[a._v("-XX:+UseNUMA")]),a._v(" 开启 NUMA 感知，这里简述下 ParallelGC 是如何利用 NUMA 的：")]),a._v(" "),s("p",[a._v("JVM 实现了 NUMA 感知分配内存的 allocator，该 allocator 基于一个假说：对于一个对象来说，创建该对象的线程是最有可能会使用该对象的线程。因此该 allocator 主要针对频繁生成新对象的 eden 区域，优先在线程所在的 numa node 上分配对象，以保证该线程后续能以最快的速度去访问对象，其他区域的内存部分则是通过交织的方式，在各个 numa node 上均衡分配。")]),a._v(" "),s("p",[a._v("其余 GC 算法的 numa 感知实现机制可以自行查阅资料。")]),a._v(" "),s("h3",{attrs:{id:"_4-4-api-方式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-api-方式"}},[a._v("#")]),a._v(" 4.4 API 方式")]),a._v(" "),s("p",[a._v("Java 也有一个 "),s("a",{attrs:{href:"https://github.com/OpenHFT/Java-Thread-Affinity",target:"_blank",rel:"noopener noreferrer"}},[a._v("Java-Thread-Affinity"),s("OutboundLink")],1),a._v(" 项目，支持通过 API 方式对线程进行邦核：")]),a._v(" "),s("div",{staticClass:"language-java line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("try")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("AffinityLock")]),a._v(" al "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("AffinityLock")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("acquireLock")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("// do some work while locked to a CPU.")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])]),a._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[a._v("1")]),s("br"),s("span",{staticClass:"line-number"},[a._v("2")]),s("br"),s("span",{staticClass:"line-number"},[a._v("3")]),s("br")])]),s("h2",{attrs:{id:"_5-测试效果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-测试效果"}},[a._v("#")]),a._v(" 5. 测试效果")]),a._v(" "),s("p",[a._v("目前有看到比较好的测试案例：https://indico.cern.ch/event/304944/contributions/1672535/attachments/578723/796898/numa.pdf 。")]),a._v(" "),s("p",[a._v("在自己集群测试中，运行一个 Spark 流式作业，开启 numad 前后对比如下：")]),a._v(" "),s("ul",[s("li",[a._v("开启前：1853.0 h (123.0 h)，GC 占比： 123 / 1853 ~= 5.47%")]),a._v(" "),s("li",[a._v("开启后： 2792.5 h (139.3 h)，GC 占比：139.3 / 2792.5 ~= 4.99%")])]),a._v(" "),s("p",[a._v("集群 CPU 整体利用率变化如下：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://gitee.com/zhxuankun/Image/raw/master/blog/image.png",alt:"img"}})]),a._v(" "),s("p",[a._v("从中可以看出， CPU 峰值 43% 下降到了 37%，CPU 负载也有一定的减轻。")]),a._v(" "),s("p",[a._v("参考：")]),a._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"http://cenalulu.github.io/linux/numa/",target:"_blank",rel:"noopener noreferrer"}},[a._v("NUMA架构的CPU -- 你真的用好了么？"),s("OutboundLink")],1)]),a._v(" "),s("li",[s("a",{attrs:{href:"https://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/",target:"_blank",rel:"noopener noreferrer"}},[a._v("The MySQL “swap insanity” problem and the effects of the NUMA architecture"),s("OutboundLink")],1)]),a._v(" "),s("li",[s("a",{attrs:{href:"https://issues.apache.org/jira/browse/YARN-5764",target:"_blank",rel:"noopener noreferrer"}},[a._v("NUMA awareness support for launching containers"),s("OutboundLink")],1)]),a._v(" "),s("li",[s("a",{attrs:{href:"https://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Java HotSpot™ Virtual Machine Performance Enhancements"),s("OutboundLink")],1)])])])}),[],!1,null,null,null);n.default=t.exports}}]);